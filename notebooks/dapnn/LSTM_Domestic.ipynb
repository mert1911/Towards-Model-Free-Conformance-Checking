{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Event Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38dce5e9ad634b068febcc5637dd80ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>org:role</th>\n",
       "      <th>case:id</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>case:BudgetNumber</th>\n",
       "      <th>case:DeclarationNumber</th>\n",
       "      <th>case:Amount</th>\n",
       "      <th>@@case_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>st_step 86794_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2017-01-09 08:49:50+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 86792</td>\n",
       "      <td>26.851205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>st_step 86793_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration FINAL_APPROVED by SUPERVISOR</td>\n",
       "      <td>2017-01-09 10:27:48+00:00</td>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 86792</td>\n",
       "      <td>26.851205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dd_declaration 86791_19</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Request Payment</td>\n",
       "      <td>2017-01-10 08:34:44+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 86792</td>\n",
       "      <td>26.851205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd_declaration 86791_20</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Payment Handled</td>\n",
       "      <td>2017-01-12 16:31:22+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 86792</td>\n",
       "      <td>26.851205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>st_step 86798_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2017-01-09 09:26:14+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>declaration 86795</td>\n",
       "      <td>declaration 86795</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 86796</td>\n",
       "      <td>182.464172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56432</th>\n",
       "      <td>st_step 138363_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2018-12-29 16:50:14+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 138360</td>\n",
       "      <td>190.404576</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56433</th>\n",
       "      <td>st_step 138361_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration APPROVED by ADMINISTRATION</td>\n",
       "      <td>2018-12-29 16:56:13+00:00</td>\n",
       "      <td>ADMINISTRATION</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 138360</td>\n",
       "      <td>190.404576</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56434</th>\n",
       "      <td>st_step 138362_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration FINAL_APPROVED by SUPERVISOR</td>\n",
       "      <td>2019-01-03 07:55:52+00:00</td>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 138360</td>\n",
       "      <td>190.404576</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56435</th>\n",
       "      <td>dd_declaration 138359_19</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Request Payment</td>\n",
       "      <td>2019-01-08 07:20:28+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 138360</td>\n",
       "      <td>190.404576</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56436</th>\n",
       "      <td>dd_declaration 138359_20</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Payment Handled</td>\n",
       "      <td>2019-01-10 16:31:08+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 138360</td>\n",
       "      <td>190.404576</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56437 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id  org:resource  \\\n",
       "0               st_step 86794_0  STAFF MEMBER   \n",
       "1               st_step 86793_0  STAFF MEMBER   \n",
       "2       dd_declaration 86791_19        SYSTEM   \n",
       "3       dd_declaration 86791_20        SYSTEM   \n",
       "4               st_step 86798_0  STAFF MEMBER   \n",
       "...                         ...           ...   \n",
       "56432          st_step 138363_0  STAFF MEMBER   \n",
       "56433          st_step 138361_0  STAFF MEMBER   \n",
       "56434          st_step 138362_0  STAFF MEMBER   \n",
       "56435  dd_declaration 138359_19        SYSTEM   \n",
       "56436  dd_declaration 138359_20        SYSTEM   \n",
       "\n",
       "                                   concept:name            time:timestamp  \\\n",
       "0             Declaration SUBMITTED by EMPLOYEE 2017-01-09 08:49:50+00:00   \n",
       "1      Declaration FINAL_APPROVED by SUPERVISOR 2017-01-09 10:27:48+00:00   \n",
       "2                               Request Payment 2017-01-10 08:34:44+00:00   \n",
       "3                               Payment Handled 2017-01-12 16:31:22+00:00   \n",
       "4             Declaration SUBMITTED by EMPLOYEE 2017-01-09 09:26:14+00:00   \n",
       "...                                         ...                       ...   \n",
       "56432         Declaration SUBMITTED by EMPLOYEE 2018-12-29 16:50:14+00:00   \n",
       "56433    Declaration APPROVED by ADMINISTRATION 2018-12-29 16:56:13+00:00   \n",
       "56434  Declaration FINAL_APPROVED by SUPERVISOR 2019-01-03 07:55:52+00:00   \n",
       "56435                           Request Payment 2019-01-08 07:20:28+00:00   \n",
       "56436                           Payment Handled 2019-01-10 16:31:08+00:00   \n",
       "\n",
       "             org:role             case:id   case:concept:name  \\\n",
       "0            EMPLOYEE   declaration 86791   declaration 86791   \n",
       "1          SUPERVISOR   declaration 86791   declaration 86791   \n",
       "2           UNDEFINED   declaration 86791   declaration 86791   \n",
       "3           UNDEFINED   declaration 86791   declaration 86791   \n",
       "4            EMPLOYEE   declaration 86795   declaration 86795   \n",
       "...               ...                 ...                 ...   \n",
       "56432        EMPLOYEE  declaration 138359  declaration 138359   \n",
       "56433  ADMINISTRATION  declaration 138359  declaration 138359   \n",
       "56434      SUPERVISOR  declaration 138359  declaration 138359   \n",
       "56435       UNDEFINED  declaration 138359  declaration 138359   \n",
       "56436       UNDEFINED  declaration 138359  declaration 138359   \n",
       "\n",
       "      case:BudgetNumber     case:DeclarationNumber  case:Amount  @@case_index  \n",
       "0          budget 86566   declaration number 86792    26.851205             0  \n",
       "1          budget 86566   declaration number 86792    26.851205             0  \n",
       "2          budget 86566   declaration number 86792    26.851205             0  \n",
       "3          budget 86566   declaration number 86792    26.851205             0  \n",
       "4          budget 86566   declaration number 86796   182.464172             1  \n",
       "...                 ...                        ...          ...           ...  \n",
       "56432      budget 86566  declaration number 138360   190.404576         10499  \n",
       "56433      budget 86566  declaration number 138360   190.404576         10499  \n",
       "56434      budget 86566  declaration number 138360   190.404576         10499  \n",
       "56435      budget 86566  declaration number 138360   190.404576         10499  \n",
       "56436      budget 86566  declaration number 138360   190.404576         10499  \n",
       "\n",
       "[56437 rows x 11 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the XES file\n",
    "    dataframe_log = pm4py.read_xes('../../data/logs/DomesticDeclarations.xes')\n",
    "\n",
    "    # If 'log' is already a DataFrame, add the @@case_index column directly\n",
    "    case_indices = {case_id: idx for idx, case_id in enumerate(dataframe_log['case:concept:name'].unique())}\n",
    "    dataframe_log['@@case_index'] = dataframe_log['case:concept:name'].map(case_indices)\n",
    "    \n",
    "     # Convert the dataframe to event log\n",
    "    log = log_converter.apply(dataframe_log)\n",
    "    \n",
    "dataframe_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The attribute 'id' does not have the same value across all cases.\n",
      "Cases with multiple values for 'id':\n",
      "@@case_index\n",
      "0        4\n",
      "1        5\n",
      "2        5\n",
      "3        4\n",
      "4        4\n",
      "        ..\n",
      "10495    6\n",
      "10496    6\n",
      "10497    5\n",
      "10498    5\n",
      "10499    5\n",
      "Name: id, Length: 10366, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Function to check if an attribute has the same value across all different cases\n",
    "def check_same_value_across_cases(dataframe_log, case_col, attr_col):\n",
    "    # Group by case index and get unique values for the attribute in each case\n",
    "    unique_values_per_case = dataframe_log.groupby(case_col)[attr_col].nunique()\n",
    "    \n",
    "    # Check if any case has more than one unique value for the attribute\n",
    "    cases_with_multiple_values = unique_values_per_case[unique_values_per_case > 1]\n",
    "    \n",
    "    if cases_with_multiple_values.empty:\n",
    "        print(f\"The attribute '{attr_col}' has the same value across all cases.\")\n",
    "    else:\n",
    "        print(f\"The attribute '{attr_col}' does not have the same value across all cases.\")\n",
    "        print(f\"Cases with multiple values for '{attr_col}':\\n{cases_with_multiple_values}\")\n",
    "\n",
    "# Use the function with the example DataFrame\n",
    "check_same_value_across_cases(dataframe_log, '@@case_index', 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop unnessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_log = dataframe_log.drop(columns=['case:id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_log = dataframe_log.drop(columns=['case:concept:name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_log = dataframe_log.drop(columns=['case:BudgetNumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_log = dataframe_log.drop(columns=['case:DeclarationNumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_log = dataframe_log.drop(columns=['case:Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>org:role</th>\n",
       "      <th>@@case_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>st_step 86794_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2017-01-09 08:49:50+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>st_step 86793_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration FINAL_APPROVED by SUPERVISOR</td>\n",
       "      <td>2017-01-09 10:27:48+00:00</td>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dd_declaration 86791_19</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Request Payment</td>\n",
       "      <td>2017-01-10 08:34:44+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd_declaration 86791_20</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Payment Handled</td>\n",
       "      <td>2017-01-12 16:31:22+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>st_step 86798_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2017-01-09 09:26:14+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56432</th>\n",
       "      <td>st_step 138363_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2018-12-29 16:50:14+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56433</th>\n",
       "      <td>st_step 138361_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration APPROVED by ADMINISTRATION</td>\n",
       "      <td>2018-12-29 16:56:13+00:00</td>\n",
       "      <td>ADMINISTRATION</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56434</th>\n",
       "      <td>st_step 138362_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration FINAL_APPROVED by SUPERVISOR</td>\n",
       "      <td>2019-01-03 07:55:52+00:00</td>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56435</th>\n",
       "      <td>dd_declaration 138359_19</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Request Payment</td>\n",
       "      <td>2019-01-08 07:20:28+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56436</th>\n",
       "      <td>dd_declaration 138359_20</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Payment Handled</td>\n",
       "      <td>2019-01-10 16:31:08+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56437 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id  org:resource  \\\n",
       "0               st_step 86794_0  STAFF MEMBER   \n",
       "1               st_step 86793_0  STAFF MEMBER   \n",
       "2       dd_declaration 86791_19        SYSTEM   \n",
       "3       dd_declaration 86791_20        SYSTEM   \n",
       "4               st_step 86798_0  STAFF MEMBER   \n",
       "...                         ...           ...   \n",
       "56432          st_step 138363_0  STAFF MEMBER   \n",
       "56433          st_step 138361_0  STAFF MEMBER   \n",
       "56434          st_step 138362_0  STAFF MEMBER   \n",
       "56435  dd_declaration 138359_19        SYSTEM   \n",
       "56436  dd_declaration 138359_20        SYSTEM   \n",
       "\n",
       "                                   concept:name            time:timestamp  \\\n",
       "0             Declaration SUBMITTED by EMPLOYEE 2017-01-09 08:49:50+00:00   \n",
       "1      Declaration FINAL_APPROVED by SUPERVISOR 2017-01-09 10:27:48+00:00   \n",
       "2                               Request Payment 2017-01-10 08:34:44+00:00   \n",
       "3                               Payment Handled 2017-01-12 16:31:22+00:00   \n",
       "4             Declaration SUBMITTED by EMPLOYEE 2017-01-09 09:26:14+00:00   \n",
       "...                                         ...                       ...   \n",
       "56432         Declaration SUBMITTED by EMPLOYEE 2018-12-29 16:50:14+00:00   \n",
       "56433    Declaration APPROVED by ADMINISTRATION 2018-12-29 16:56:13+00:00   \n",
       "56434  Declaration FINAL_APPROVED by SUPERVISOR 2019-01-03 07:55:52+00:00   \n",
       "56435                           Request Payment 2019-01-08 07:20:28+00:00   \n",
       "56436                           Payment Handled 2019-01-10 16:31:08+00:00   \n",
       "\n",
       "             org:role  @@case_index  \n",
       "0            EMPLOYEE             0  \n",
       "1          SUPERVISOR             0  \n",
       "2           UNDEFINED             0  \n",
       "3           UNDEFINED             0  \n",
       "4            EMPLOYEE             1  \n",
       "...               ...           ...  \n",
       "56432        EMPLOYEE         10499  \n",
       "56433  ADMINISTRATION         10499  \n",
       "56434      SUPERVISOR         10499  \n",
       "56435       UNDEFINED         10499  \n",
       "56436       UNDEFINED         10499  \n",
       "\n",
       "[56437 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Convert to datetime format\n",
    "dataframe_log['time:timestamp'] = pd.to_datetime(dataframe_log['time:timestamp'])\n",
    "\n",
    "# Calculate elapsed time since the start of each case\n",
    "dataframe_log['start_time'] = dataframe_log.groupby('@@case_index')['time:timestamp'].transform('min')\n",
    "dataframe_log['elapsed_time'] = (dataframe_log['time:timestamp'] - dataframe_log['start_time']).dt.total_seconds()\n",
    "\n",
    "# Normalize the elapsed time in minutes\n",
    "scaler = StandardScaler()\n",
    "dataframe_log['standardized_elapsed_time'] = scaler.fit_transform(dataframe_log[['elapsed_time']])\n",
    "\n",
    "dataframe_log = dataframe_log.drop(columns=['start_time'])\n",
    "dataframe_log = dataframe_log.drop(columns=['elapsed_time'])\n",
    "dataframe_log = dataframe_log.drop(columns=['time:timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert Start & End markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to insert start and end markers\n",
    "def add_markers(df):\n",
    "    # Identify unique case indices\n",
    "    case_indices = df['@@case_index'].unique()\n",
    "    \n",
    "    # Prepare a container for new DataFrame rows\n",
    "    new_rows = []\n",
    "    \n",
    "    # Iterate over each case index to add start and end markers\n",
    "    for case_index in case_indices:\n",
    "        # Create a start marker row with all columns except @@case_index set to 'Start'\n",
    "        start_row = {col: 'Start' if col != '@@case_index' else case_index for col in df.columns}\n",
    "        \n",
    "        # Create an end marker row with all columns except @@case_index set to 'End'\n",
    "        end_row = {col: 'End' if col != '@@case_index' else case_index for col in df.columns}\n",
    "        \n",
    "        # Append start row, rows for the current case, and end row\n",
    "        new_rows.append(start_row)\n",
    "        new_rows.extend(df[df['@@case_index'] == case_index].to_dict('records'))\n",
    "        new_rows.append(end_row)\n",
    "    \n",
    "    # Convert the list of rows into a DataFrame\n",
    "    return pd.DataFrame(new_rows)\n",
    "\n",
    "# Apply the function to add start and end markers to the dataframe\n",
    "modified_dataframe = add_markers(dataframe_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>org:role</th>\n",
       "      <th>@@case_index</th>\n",
       "      <th>standardized_elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Start</td>\n",
       "      <td>Start</td>\n",
       "      <td>Start</td>\n",
       "      <td>Start</td>\n",
       "      <td>0</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>st_step 86794_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration SUBMITTED by EMPLOYEE</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.372192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>st_step 86793_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration FINAL_APPROVED by SUPERVISOR</td>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.367752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd_declaration 86791_19</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Request Payment</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.307612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dd_declaration 86791_20</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Payment Handled</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.155482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77432</th>\n",
       "      <td>st_step 138361_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration APPROVED by ADMINISTRATION</td>\n",
       "      <td>ADMINISTRATION</td>\n",
       "      <td>10499</td>\n",
       "      <td>-0.371921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77433</th>\n",
       "      <td>st_step 138362_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration FINAL_APPROVED by SUPERVISOR</td>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>10499</td>\n",
       "      <td>-0.07009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77434</th>\n",
       "      <td>dd_declaration 138359_19</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Request Payment</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>10499</td>\n",
       "      <td>0.254628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77435</th>\n",
       "      <td>dd_declaration 138359_20</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Payment Handled</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>10499</td>\n",
       "      <td>0.410114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77436</th>\n",
       "      <td>End</td>\n",
       "      <td>End</td>\n",
       "      <td>End</td>\n",
       "      <td>End</td>\n",
       "      <td>10499</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77437 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id  org:resource  \\\n",
       "0                         Start         Start   \n",
       "1               st_step 86794_0  STAFF MEMBER   \n",
       "2               st_step 86793_0  STAFF MEMBER   \n",
       "3       dd_declaration 86791_19        SYSTEM   \n",
       "4       dd_declaration 86791_20        SYSTEM   \n",
       "...                         ...           ...   \n",
       "77432          st_step 138361_0  STAFF MEMBER   \n",
       "77433          st_step 138362_0  STAFF MEMBER   \n",
       "77434  dd_declaration 138359_19        SYSTEM   \n",
       "77435  dd_declaration 138359_20        SYSTEM   \n",
       "77436                       End           End   \n",
       "\n",
       "                                   concept:name        org:role  @@case_index  \\\n",
       "0                                         Start           Start             0   \n",
       "1             Declaration SUBMITTED by EMPLOYEE        EMPLOYEE             0   \n",
       "2      Declaration FINAL_APPROVED by SUPERVISOR      SUPERVISOR             0   \n",
       "3                               Request Payment       UNDEFINED             0   \n",
       "4                               Payment Handled       UNDEFINED             0   \n",
       "...                                         ...             ...           ...   \n",
       "77432    Declaration APPROVED by ADMINISTRATION  ADMINISTRATION         10499   \n",
       "77433  Declaration FINAL_APPROVED by SUPERVISOR      SUPERVISOR         10499   \n",
       "77434                           Request Payment       UNDEFINED         10499   \n",
       "77435                           Payment Handled       UNDEFINED         10499   \n",
       "77436                                       End             End         10499   \n",
       "\n",
       "      standardized_elapsed_time  \n",
       "0                         Start  \n",
       "1                     -0.372192  \n",
       "2                     -0.367752  \n",
       "3                     -0.307612  \n",
       "4                     -0.155482  \n",
       "...                         ...  \n",
       "77432                 -0.371921  \n",
       "77433                  -0.07009  \n",
       "77434                  0.254628  \n",
       "77435                  0.410114  \n",
       "77436                       End  \n",
       "\n",
       "[77437 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_dataframe['standardized_elapsed_time'] = modified_dataframe['standardized_elapsed_time'].replace({'Start': 0, 'End': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(modified_dataframe['id'])\n",
    "modified_dataframe['id'] = codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(modified_dataframe['org:resource'])\n",
    "modified_dataframe['org:resource'] = codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(modified_dataframe['concept:name'])\n",
    "modified_dataframe['concept:name'] = codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(modified_dataframe['org:role'])\n",
    "modified_dataframe['org:role'] = codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>org:role</th>\n",
       "      <th>@@case_index</th>\n",
       "      <th>standardized_elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.372192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.367752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.307612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.155482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77432</th>\n",
       "      <td>56435</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>10499</td>\n",
       "      <td>-0.371921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77433</th>\n",
       "      <td>56436</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10499</td>\n",
       "      <td>-0.070090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77434</th>\n",
       "      <td>56437</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10499</td>\n",
       "      <td>0.254628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77435</th>\n",
       "      <td>56438</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10499</td>\n",
       "      <td>0.410114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77436</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10499</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77437 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  org:resource  concept:name  org:role  @@case_index  \\\n",
       "0          0             0             0         0             0   \n",
       "1          1             1             1         1             0   \n",
       "2          2             1             2         2             0   \n",
       "3          3             2             3         3             0   \n",
       "4          4             2             4         3             0   \n",
       "...      ...           ...           ...       ...           ...   \n",
       "77432  56435             1            12         7         10499   \n",
       "77433  56436             1             2         2         10499   \n",
       "77434  56437             2             3         3         10499   \n",
       "77435  56438             2             4         3         10499   \n",
       "77436      5             3             5         4         10499   \n",
       "\n",
       "       standardized_elapsed_time  \n",
       "0                       0.000000  \n",
       "1                      -0.372192  \n",
       "2                      -0.367752  \n",
       "3                      -0.307612  \n",
       "4                      -0.155482  \n",
       "...                          ...  \n",
       "77432                  -0.371921  \n",
       "77433                  -0.070090  \n",
       "77434                   0.254628  \n",
       "77435                   0.410114  \n",
       "77436                   1.000000  \n",
       "\n",
       "[77437 rows x 6 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding for Cases with less then 5 events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the frequency of each unique value in '@@case_index'\n",
    "frequency = modified_dataframe['@@case_index'].value_counts()\n",
    "\n",
    "# Finding the minimum occurrence\n",
    "min_occurrence = frequency.min()\n",
    "\n",
    "min_occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe might have different types, let's create a generic function to add rows\n",
    "def add_rows(group, num_rows, case_index_value):\n",
    "    # For each column, determine the appropriate \"zero\" value (int 0, string '', etc.)\n",
    "    additional_rows = pd.DataFrame({\n",
    "        column: 0 if pd.api.types.is_numeric_dtype(group[column]) else '' for column in group.columns\n",
    "    }, index=range(num_rows))\n",
    "    \n",
    "    # Set the @@case_index column to the current case index value\n",
    "    additional_rows['@@case_index'] = case_index_value\n",
    "    \n",
    "    # Append the additional rows to the group\n",
    "    return pd.concat([group, additional_rows], ignore_index=True)\n",
    "\n",
    "# Function to pad cases with less than 5 events\n",
    "def pad_cases(df):\n",
    "    # Group by @@case_index\n",
    "    groups = df.groupby('@@case_index')\n",
    "    \n",
    "    # Placeholder for modified groups\n",
    "    modified_groups = []\n",
    "    \n",
    "    for name, group in groups:\n",
    "        # Calculate the number of events to add\n",
    "        events_to_add = 5 - len(group)\n",
    "        \n",
    "        if events_to_add > 0:\n",
    "            # Add the required number of rows\n",
    "            group = add_rows(group, events_to_add, name)\n",
    "        \n",
    "        # Append the modified group to the list\n",
    "        modified_groups.append(group)\n",
    "    \n",
    "    # Concatenate all modified groups back into a single DataFrame\n",
    "    return pd.concat(modified_groups, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>org:role</th>\n",
       "      <th>@@case_index</th>\n",
       "      <th>standardized_elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.372192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.367752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.307612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.155482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77705</th>\n",
       "      <td>56435</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>10499</td>\n",
       "      <td>-0.371921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77706</th>\n",
       "      <td>56436</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10499</td>\n",
       "      <td>-0.070090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77707</th>\n",
       "      <td>56437</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10499</td>\n",
       "      <td>0.254628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77708</th>\n",
       "      <td>56438</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10499</td>\n",
       "      <td>0.410114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77709</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10499</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77710 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  org:resource  concept:name  org:role  @@case_index  \\\n",
       "0          0             0             0         0             0   \n",
       "1          1             1             1         1             0   \n",
       "2          2             1             2         2             0   \n",
       "3          3             2             3         3             0   \n",
       "4          4             2             4         3             0   \n",
       "...      ...           ...           ...       ...           ...   \n",
       "77705  56435             1            12         7         10499   \n",
       "77706  56436             1             2         2         10499   \n",
       "77707  56437             2             3         3         10499   \n",
       "77708  56438             2             4         3         10499   \n",
       "77709      5             3             5         4         10499   \n",
       "\n",
       "       standardized_elapsed_time  \n",
       "0                       0.000000  \n",
       "1                      -0.372192  \n",
       "2                      -0.367752  \n",
       "3                      -0.307612  \n",
       "4                      -0.155482  \n",
       "...                          ...  \n",
       "77705                  -0.371921  \n",
       "77706                  -0.070090  \n",
       "77707                   0.254628  \n",
       "77708                   0.410114  \n",
       "77709                   1.000000  \n",
       "\n",
       "[77710 rows x 6 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the padding function\n",
    "modified_dataframe = pad_cases(modified_dataframe)\n",
    "modified_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = modified_dataframe[['id', '@@case_index']]\n",
    "df_resource = modified_dataframe[['org:resource', '@@case_index']]\n",
    "df_activity = modified_dataframe[['concept:name', '@@case_index']]\n",
    "df_role = modified_dataframe[['org:role', '@@case_index']]\n",
    "df_timestamp = modified_dataframe[['standardized_elapsed_time', '@@case_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sliding_windows(df, case_id_column='@@case_index', window_size=5):\n",
    "    windows = []\n",
    "    targets = []\n",
    "    case_indices = []\n",
    "\n",
    "    # Iterate over each unique case\n",
    "    for case_id in df[case_id_column].unique():\n",
    "        # Extract the case\n",
    "        case_data = df[df[case_id_column] == case_id]\n",
    "        \n",
    "        # Convert case_data to a NumPy array and drop the case_id_column\n",
    "        case_data_array = case_data.drop(columns=[case_id_column]).to_numpy()\n",
    "\n",
    "        # Adjusting the condition to correctly reflect window_size without needing an additional +1\n",
    "        # Now it correctly considers window_size as including the target event\n",
    "        if len(case_data_array) >= window_size:\n",
    "            # Adjust the loop to generate sliding windows of size window_size - 1 for the inputs and use the next event as the target\n",
    "            for i in range(len(case_data_array) - window_size + 1):\n",
    "                # window now has window_size - 1 events\n",
    "                window = case_data_array[i:i + window_size - 1]\n",
    "                # The target is the event immediately following the window\n",
    "                target = case_data_array[i + window_size - 1]\n",
    "                windows.append(window)\n",
    "                targets.append(target)\n",
    "                case_indices.append(case_id)  # Store the case_id corresponding to the window\n",
    "\n",
    "    # Convert lists to numpy arrays for easier handling and to ensure they are two-dimensional\n",
    "    windows_array = np.array(windows)\n",
    "    targets_array = np.array(targets)\n",
    "    case_indices_array = np.array(case_indices)\n",
    "    \n",
    "    return windows_array, targets_array, case_indices_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_id, targets_id, case_indices = generate_sliding_windows(df_id)\n",
    "windows_resource, targets_resource, case_indices = generate_sliding_windows(df_resource)\n",
    "windows_activity, targets_activity, case_indices = generate_sliding_windows(df_activity)\n",
    "windows_role, targets_role, case_indices = generate_sliding_windows(df_role)\n",
    "windows_timestamp, targets_timestamp, case_indices = generate_sliding_windows(df_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_resource (InputLayer  [(None, 4)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_activity (InputLayer  [(None, 4)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_role (InputLayer)     [(None, 4)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_timestamp (InputLaye  [(None, 4, 1)]               0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)     (None, 4, 50)                200       ['input_resource[0][0]']      \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)     (None, 4, 50)                950       ['input_activity[0][0]']      \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)     (None, 4, 50)                450       ['input_role[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 4, 1)                 4         ['input_timestamp[0][0]']     \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " lstm_8 (LSTM)               (None, 25)                   7600      ['embedding_6[0][0]']         \n",
      "                                                                                                  \n",
      " lstm_9 (LSTM)               (None, 25)                   7600      ['embedding_7[0][0]']         \n",
      "                                                                                                  \n",
      " lstm_10 (LSTM)              (None, 25)                   7600      ['embedding_8[0][0]']         \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)              (None, 25)                   2700      ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 100)                  0         ['lstm_8[0][0]',              \n",
      " )                                                                   'lstm_9[0][0]',              \n",
      "                                                                     'lstm_10[0][0]',             \n",
      "                                                                     'lstm_11[0][0]']             \n",
      "                                                                                                  \n",
      " output_resource (Dense)     (None, 4)                    404       ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " output_activity (Dense)     (None, 19)                   1919      ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " output_role (Dense)         (None, 9)                    909       ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " output_timestamp (Dense)    (None, 1)                    101       ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30437 (118.89 KB)\n",
      "Trainable params: 30435 (118.89 KB)\n",
      "Non-trainable params: 2 (8.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, Embedding, BatchNormalization\n",
    "\n",
    "# Assuming these values as placeholders, replace them with actual counts from your data\n",
    "num_resources = modified_dataframe['org:resource'].nunique()\n",
    "num_activities = modified_dataframe['concept:name'].nunique()\n",
    "num_roles = modified_dataframe['org:role'].nunique()\n",
    "embedding_dim_resource = 50\n",
    "embedding_dim_activity = 50\n",
    "embedding_dim_role = 50\n",
    "\n",
    "time_steps = 4\n",
    "\n",
    "# Input layers\n",
    "input_resource = Input(shape=(time_steps,), name='input_resource')\n",
    "input_activity = Input(shape=(time_steps,), name='input_activity')\n",
    "input_role = Input(shape=(time_steps,), name='input_role')\n",
    "input_timestamp = Input(shape=(time_steps, 1), name='input_timestamp')\n",
    "\n",
    "# Embedding layers\n",
    "embedding_resource = Embedding(input_dim=num_resources, output_dim=embedding_dim_resource, input_length=time_steps)(input_resource)\n",
    "embedding_activity = Embedding(input_dim=num_activities, output_dim=embedding_dim_activity, input_length=time_steps)(input_activity)\n",
    "embedding_role = Embedding(input_dim=num_roles, output_dim=embedding_dim_role, input_length=time_steps)(input_role)\n",
    "\n",
    "# LSTM layers\n",
    "lstm_resource = LSTM(25, return_sequences=False)(embedding_resource)\n",
    "lstm_activity = LSTM(25, return_sequences=False)(embedding_activity)\n",
    "lstm_role = LSTM(25, return_sequences=False)(embedding_role)\n",
    "\n",
    "# Normalize the numeric input for better performance\n",
    "batch_norm_timestamp = BatchNormalization()(input_timestamp)\n",
    "lstm_timestamp = LSTM(25, return_sequences=False)(batch_norm_timestamp)\n",
    "\n",
    "# Concatenate outputs\n",
    "concatenated = Concatenate(axis=-1)([lstm_resource, lstm_activity, lstm_role, lstm_timestamp])\n",
    "\n",
    "# Output layers for classification\n",
    "output_resource = Dense(num_resources, activation='softmax', name='output_resource')(concatenated)\n",
    "output_activity = Dense(num_activities, activation='softmax', name='output_activity')(concatenated)\n",
    "output_role = Dense(num_roles, activation='softmax', name='output_role')(concatenated)\n",
    "\n",
    "# Additional output layer for the timestamp (regression)\n",
    "output_timestamp = Dense(1, activation='linear', name='output_timestamp')(concatenated)  # For predicting timestamp as a continuous variable\n",
    "\n",
    "# Create and compile the model\n",
    "model = Model(inputs=[input_resource, input_activity, input_role, input_timestamp], \n",
    "              outputs=[output_resource, output_activity, output_role, output_timestamp])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'output_resource': 'categorical_crossentropy',\n",
    "                    'output_activity': 'categorical_crossentropy',\n",
    "                    'output_role': 'categorical_crossentropy',\n",
    "                    'output_timestamp': 'mean_squared_error'},  # Adding MSE loss for the timestamp\n",
    "              metrics={'output_resource': 'accuracy',\n",
    "                       'output_activity': 'accuracy',\n",
    "                       'output_role': 'accuracy',\n",
    "                       'output_timestamp': None})  # Metrics for regression might include MSE, MAE, etc., but it's optional here\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_resource, test_resource, train_targets_resource, test_targets_resource = train_test_split(\n",
    "    windows_resource, targets_resource, test_size=0.3, random_state=42)\n",
    "\n",
    "train_activity, test_activity, train_targets_activity, test_targets_activity = train_test_split(\n",
    "    windows_activity, targets_activity, test_size=0.3, random_state=42)\n",
    "\n",
    "train_role, test_role, train_targets_role, test_targets_role = train_test_split(\n",
    "    windows_role, targets_role, test_size=0.3, random_state=42)\n",
    "\n",
    "train_timestamp, test_timestamp, train_targets_timestamp, test_targets_timestamp = train_test_split(\n",
    "    windows_timestamp, targets_timestamp, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "def cyclic_lr(epoch, lr):\n",
    "    # Example function that modulates LR within a range for each epoch\n",
    "    # Customize this function based on your cyclic learning rate policy\n",
    "    max_lr = 0.01  # Maximum LR\n",
    "    base_lr = 0.001  # Base LR\n",
    "    step_size = 10  # Number of epochs for half a cycle\n",
    "    cycle = np.floor(1 + epoch / (2 * step_size))\n",
    "    x = np.abs(epoch / step_size - 2 * cycle + 1)\n",
    "    lr = base_lr + (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(cyclic_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "391/391 [==============================] - 12s 10ms/step - loss: 2.4117 - output_resource_loss: 0.3163 - output_activity_loss: 0.7747 - output_role_loss: 0.5406 - output_timestamp_loss: 0.7801 - output_resource_accuracy: 0.8953 - output_activity_accuracy: 0.8366 - output_role_accuracy: 0.8381 - val_loss: 0.9082 - val_output_resource_loss: 0.0412 - val_output_activity_loss: 0.1894 - val_output_role_loss: 0.1323 - val_output_timestamp_loss: 0.5452 - val_output_resource_accuracy: 0.9872 - val_output_activity_accuracy: 0.9615 - val_output_role_accuracy: 0.9720 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8686 - output_resource_loss: 0.0332 - output_activity_loss: 0.1155 - output_role_loss: 0.0803 - output_timestamp_loss: 0.6396 - output_resource_accuracy: 0.9896 - output_activity_accuracy: 0.9689 - output_role_accuracy: 0.9760 - val_loss: 0.6705 - val_output_resource_loss: 0.0287 - val_output_activity_loss: 0.0914 - val_output_role_loss: 0.0619 - val_output_timestamp_loss: 0.4885 - val_output_resource_accuracy: 0.9911 - val_output_activity_accuracy: 0.9706 - val_output_role_accuracy: 0.9760 - lr: 0.0019\n",
      "Epoch 3/25\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7388 - output_resource_loss: 0.0281 - output_activity_loss: 0.0822 - output_role_loss: 0.0561 - output_timestamp_loss: 0.5725 - output_resource_accuracy: 0.9901 - output_activity_accuracy: 0.9729 - output_role_accuracy: 0.9782 - val_loss: 0.6098 - val_output_resource_loss: 0.0252 - val_output_activity_loss: 0.0788 - val_output_role_loss: 0.0505 - val_output_timestamp_loss: 0.4553 - val_output_resource_accuracy: 0.9911 - val_output_activity_accuracy: 0.9734 - val_output_role_accuracy: 0.9789 - lr: 0.0028\n",
      "Epoch 4/25\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.7263 - output_resource_loss: 0.0276 - output_activity_loss: 0.0757 - output_role_loss: 0.0506 - output_timestamp_loss: 0.5723 - output_resource_accuracy: 0.9903 - output_activity_accuracy: 0.9731 - output_role_accuracy: 0.9782 - val_loss: 0.6058 - val_output_resource_loss: 0.0248 - val_output_activity_loss: 0.0743 - val_output_role_loss: 0.0473 - val_output_timestamp_loss: 0.4593 - val_output_resource_accuracy: 0.9911 - val_output_activity_accuracy: 0.9697 - val_output_role_accuracy: 0.9760 - lr: 0.0037\n",
      "Epoch 5/25\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.6951 - output_resource_loss: 0.0274 - output_activity_loss: 0.0728 - output_role_loss: 0.0482 - output_timestamp_loss: 0.5467 - output_resource_accuracy: 0.9902 - output_activity_accuracy: 0.9735 - output_role_accuracy: 0.9789 - val_loss: 0.6448 - val_output_resource_loss: 0.0257 - val_output_activity_loss: 0.0730 - val_output_role_loss: 0.0482 - val_output_timestamp_loss: 0.4979 - val_output_resource_accuracy: 0.9909 - val_output_activity_accuracy: 0.9752 - val_output_role_accuracy: 0.9805 - lr: 0.0046\n",
      "Epoch 6/25\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7178 - output_resource_loss: 0.0269 - output_activity_loss: 0.0708 - output_role_loss: 0.0469 - output_timestamp_loss: 0.5733 - output_resource_accuracy: 0.9902 - output_activity_accuracy: 0.9748 - output_role_accuracy: 0.9802 - val_loss: 0.6389 - val_output_resource_loss: 0.0248 - val_output_activity_loss: 0.0749 - val_output_role_loss: 0.0489 - val_output_timestamp_loss: 0.4902 - val_output_resource_accuracy: 0.9910 - val_output_activity_accuracy: 0.9700 - val_output_role_accuracy: 0.9764 - lr: 0.0055\n",
      "Epoch 7/25\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6905 - output_resource_loss: 0.0271 - output_activity_loss: 0.0708 - output_role_loss: 0.0473 - output_timestamp_loss: 0.5453 - output_resource_accuracy: 0.9900 - output_activity_accuracy: 0.9735 - output_role_accuracy: 0.9792 - val_loss: 0.6195 - val_output_resource_loss: 0.0245 - val_output_activity_loss: 0.0708 - val_output_role_loss: 0.0446 - val_output_timestamp_loss: 0.4796 - val_output_resource_accuracy: 0.9910 - val_output_activity_accuracy: 0.9754 - val_output_role_accuracy: 0.9810 - lr: 0.0064\n",
      "Epoch 8/25\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6769 - output_resource_loss: 0.0271 - output_activity_loss: 0.0708 - output_role_loss: 0.0468 - output_timestamp_loss: 0.5322 - output_resource_accuracy: 0.9901 - output_activity_accuracy: 0.9733 - output_role_accuracy: 0.9791 - val_loss: 0.6226 - val_output_resource_loss: 0.0255 - val_output_activity_loss: 0.0723 - val_output_role_loss: 0.0457 - val_output_timestamp_loss: 0.4791 - val_output_resource_accuracy: 0.9907 - val_output_activity_accuracy: 0.9750 - val_output_role_accuracy: 0.9800 - lr: 0.0073\n",
      "Epoch 9/25\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6978 - output_resource_loss: 0.0270 - output_activity_loss: 0.0708 - output_role_loss: 0.0469 - output_timestamp_loss: 0.5530 - output_resource_accuracy: 0.9898 - output_activity_accuracy: 0.9734 - output_role_accuracy: 0.9791 - val_loss: 0.6186 - val_output_resource_loss: 0.0255 - val_output_activity_loss: 0.0721 - val_output_role_loss: 0.0462 - val_output_timestamp_loss: 0.4748 - val_output_resource_accuracy: 0.9910 - val_output_activity_accuracy: 0.9749 - val_output_role_accuracy: 0.9805 - lr: 0.0082\n",
      "Epoch 10/25\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.7035 - output_resource_loss: 0.0272 - output_activity_loss: 0.0702 - output_role_loss: 0.0465 - output_timestamp_loss: 0.5595 - output_resource_accuracy: 0.9898 - output_activity_accuracy: 0.9738 - output_role_accuracy: 0.9795 - val_loss: 0.5869 - val_output_resource_loss: 0.0255 - val_output_activity_loss: 0.0726 - val_output_role_loss: 0.0472 - val_output_timestamp_loss: 0.4416 - val_output_resource_accuracy: 0.9910 - val_output_activity_accuracy: 0.9702 - val_output_role_accuracy: 0.9762 - lr: 0.0091\n",
      "Epoch 11/25\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6728 - output_resource_loss: 0.0269 - output_activity_loss: 0.0695 - output_role_loss: 0.0465 - output_timestamp_loss: 0.5298 - output_resource_accuracy: 0.9899 - output_activity_accuracy: 0.9740 - output_role_accuracy: 0.9797 - val_loss: 0.5896 - val_output_resource_loss: 0.0257 - val_output_activity_loss: 0.0707 - val_output_role_loss: 0.0451 - val_output_timestamp_loss: 0.4481 - val_output_resource_accuracy: 0.9911 - val_output_activity_accuracy: 0.9753 - val_output_role_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 12/25\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6608 - output_resource_loss: 0.0267 - output_activity_loss: 0.0692 - output_role_loss: 0.0458 - output_timestamp_loss: 0.5192 - output_resource_accuracy: 0.9900 - output_activity_accuracy: 0.9745 - output_role_accuracy: 0.9796 - val_loss: 0.6144 - val_output_resource_loss: 0.0293 - val_output_activity_loss: 0.0710 - val_output_role_loss: 0.0462 - val_output_timestamp_loss: 0.4678 - val_output_resource_accuracy: 0.9891 - val_output_activity_accuracy: 0.9750 - val_output_role_accuracy: 0.9793 - lr: 0.0091\n",
      "Epoch 13/25\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6404 - output_resource_loss: 0.0267 - output_activity_loss: 0.0682 - output_role_loss: 0.0452 - output_timestamp_loss: 0.5003 - output_resource_accuracy: 0.9899 - output_activity_accuracy: 0.9738 - output_role_accuracy: 0.9794 - val_loss: 0.5706 - val_output_resource_loss: 0.0259 - val_output_activity_loss: 0.0728 - val_output_role_loss: 0.0488 - val_output_timestamp_loss: 0.4232 - val_output_resource_accuracy: 0.9909 - val_output_activity_accuracy: 0.9701 - val_output_role_accuracy: 0.9757 - lr: 0.0082\n",
      "Epoch 14/25\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6033 - output_resource_loss: 0.0262 - output_activity_loss: 0.0675 - output_role_loss: 0.0448 - output_timestamp_loss: 0.4649 - output_resource_accuracy: 0.9902 - output_activity_accuracy: 0.9744 - output_role_accuracy: 0.9798 - val_loss: 0.6428 - val_output_resource_loss: 0.0260 - val_output_activity_loss: 0.0721 - val_output_role_loss: 0.0477 - val_output_timestamp_loss: 0.4969 - val_output_resource_accuracy: 0.9909 - val_output_activity_accuracy: 0.9727 - val_output_role_accuracy: 0.9772 - lr: 0.0073\n",
      "Epoch 15/25\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6056 - output_resource_loss: 0.0258 - output_activity_loss: 0.0670 - output_role_loss: 0.0443 - output_timestamp_loss: 0.4686 - output_resource_accuracy: 0.9904 - output_activity_accuracy: 0.9751 - output_role_accuracy: 0.9802 - val_loss: 0.5998 - val_output_resource_loss: 0.0262 - val_output_activity_loss: 0.0717 - val_output_role_loss: 0.0466 - val_output_timestamp_loss: 0.4552 - val_output_resource_accuracy: 0.9910 - val_output_activity_accuracy: 0.9748 - val_output_role_accuracy: 0.9805 - lr: 0.0064\n",
      "Epoch 16/25\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5695 - output_resource_loss: 0.0254 - output_activity_loss: 0.0660 - output_role_loss: 0.0436 - output_timestamp_loss: 0.4345 - output_resource_accuracy: 0.9903 - output_activity_accuracy: 0.9749 - output_role_accuracy: 0.9803 - val_loss: 0.6732 - val_output_resource_loss: 0.0255 - val_output_activity_loss: 0.0703 - val_output_role_loss: 0.0451 - val_output_timestamp_loss: 0.5323 - val_output_resource_accuracy: 0.9911 - val_output_activity_accuracy: 0.9755 - val_output_role_accuracy: 0.9809 - lr: 0.0055\n",
      "Epoch 17/25\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.5839 - output_resource_loss: 0.0253 - output_activity_loss: 0.0656 - output_role_loss: 0.0432 - output_timestamp_loss: 0.4499 - output_resource_accuracy: 0.9905 - output_activity_accuracy: 0.9755 - output_role_accuracy: 0.9808 - val_loss: 0.6944 - val_output_resource_loss: 0.0258 - val_output_activity_loss: 0.0701 - val_output_role_loss: 0.0448 - val_output_timestamp_loss: 0.5537 - val_output_resource_accuracy: 0.9911 - val_output_activity_accuracy: 0.9755 - val_output_role_accuracy: 0.9811 - lr: 0.0046\n",
      "Epoch 18/25\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.5840 - output_resource_loss: 0.0249 - output_activity_loss: 0.0643 - output_role_loss: 0.0426 - output_timestamp_loss: 0.4521 - output_resource_accuracy: 0.9905 - output_activity_accuracy: 0.9758 - output_role_accuracy: 0.9810 - val_loss: 0.6590 - val_output_resource_loss: 0.0264 - val_output_activity_loss: 0.0699 - val_output_role_loss: 0.0450 - val_output_timestamp_loss: 0.5178 - val_output_resource_accuracy: 0.9911 - val_output_activity_accuracy: 0.9757 - val_output_role_accuracy: 0.9812 - lr: 0.0037\n",
      "Epoch 19/25\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.5420 - output_resource_loss: 0.0249 - output_activity_loss: 0.0644 - output_role_loss: 0.0424 - output_timestamp_loss: 0.4103 - output_resource_accuracy: 0.9904 - output_activity_accuracy: 0.9758 - output_role_accuracy: 0.9812 - val_loss: 0.7063 - val_output_resource_loss: 0.0255 - val_output_activity_loss: 0.0699 - val_output_role_loss: 0.0442 - val_output_timestamp_loss: 0.5667 - val_output_resource_accuracy: 0.9911 - val_output_activity_accuracy: 0.9757 - val_output_role_accuracy: 0.9812 - lr: 0.0028\n",
      "Epoch 20/25\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.5562 - output_resource_loss: 0.0247 - output_activity_loss: 0.0638 - output_role_loss: 0.0421 - output_timestamp_loss: 0.4255 - output_resource_accuracy: 0.9905 - output_activity_accuracy: 0.9758 - output_role_accuracy: 0.9812 - val_loss: 0.6682 - val_output_resource_loss: 0.0256 - val_output_activity_loss: 0.0686 - val_output_role_loss: 0.0443 - val_output_timestamp_loss: 0.5297 - val_output_resource_accuracy: 0.9911 - val_output_activity_accuracy: 0.9754 - val_output_role_accuracy: 0.9809 - lr: 0.0019\n",
      "Epoch 21/25\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.5358 - output_resource_loss: 0.0245 - output_activity_loss: 0.0631 - output_role_loss: 0.0417 - output_timestamp_loss: 0.4065 - output_resource_accuracy: 0.9905 - output_activity_accuracy: 0.9760 - output_role_accuracy: 0.9814 - val_loss: 0.7153 - val_output_resource_loss: 0.0255 - val_output_activity_loss: 0.0684 - val_output_role_loss: 0.0439 - val_output_timestamp_loss: 0.5775 - val_output_resource_accuracy: 0.9911 - val_output_activity_accuracy: 0.9759 - val_output_role_accuracy: 0.9814 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.5431 - output_resource_loss: 0.0247 - output_activity_loss: 0.0633 - output_role_loss: 0.0419 - output_timestamp_loss: 0.4131 - output_resource_accuracy: 0.9905 - output_activity_accuracy: 0.9764 - output_role_accuracy: 0.9817 - val_loss: 0.6942 - val_output_resource_loss: 0.0257 - val_output_activity_loss: 0.0689 - val_output_role_loss: 0.0442 - val_output_timestamp_loss: 0.5554 - val_output_resource_accuracy: 0.9911 - val_output_activity_accuracy: 0.9756 - val_output_role_accuracy: 0.9810 - lr: 0.0019\n",
      "Epoch 23/25\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5383 - output_resource_loss: 0.0248 - output_activity_loss: 0.0640 - output_role_loss: 0.0422 - output_timestamp_loss: 0.4074 - output_resource_accuracy: 0.9905 - output_activity_accuracy: 0.9759 - output_role_accuracy: 0.9815 - val_loss: 0.6736 - val_output_resource_loss: 0.0259 - val_output_activity_loss: 0.0696 - val_output_role_loss: 0.0448 - val_output_timestamp_loss: 0.5334 - val_output_resource_accuracy: 0.9911 - val_output_activity_accuracy: 0.9755 - val_output_role_accuracy: 0.9807 - lr: 0.0028\n",
      "Epoch 24/25\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.5707 - output_resource_loss: 0.0249 - output_activity_loss: 0.0646 - output_role_loss: 0.0426 - output_timestamp_loss: 0.4386 - output_resource_accuracy: 0.9904 - output_activity_accuracy: 0.9757 - output_role_accuracy: 0.9812 - val_loss: 0.6428 - val_output_resource_loss: 0.0258 - val_output_activity_loss: 0.0694 - val_output_role_loss: 0.0450 - val_output_timestamp_loss: 0.5026 - val_output_resource_accuracy: 0.9910 - val_output_activity_accuracy: 0.9755 - val_output_role_accuracy: 0.9807 - lr: 0.0037\n",
      "Epoch 25/25\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5570 - output_resource_loss: 0.0253 - output_activity_loss: 0.0658 - output_role_loss: 0.0435 - output_timestamp_loss: 0.4224 - output_resource_accuracy: 0.9904 - output_activity_accuracy: 0.9754 - output_role_accuracy: 0.9806 - val_loss: 0.7849 - val_output_resource_loss: 0.0272 - val_output_activity_loss: 0.0713 - val_output_role_loss: 0.0466 - val_output_timestamp_loss: 0.6398 - val_output_resource_accuracy: 0.9912 - val_output_activity_accuracy: 0.9750 - val_output_role_accuracy: 0.9798 - lr: 0.0046\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_targets_resource_cat = to_categorical(train_targets_resource, num_classes=num_resources)\n",
    "test_targets_resource_cat = to_categorical(test_targets_resource, num_classes=num_resources)\n",
    "\n",
    "train_targets_activity_cat = to_categorical(train_targets_activity, num_classes=num_activities)\n",
    "test_targets_activity_cat = to_categorical(test_targets_activity, num_classes=num_activities)\n",
    "\n",
    "train_targets_role_cat = to_categorical(train_targets_role, num_classes=num_roles)\n",
    "test_targets_role_cat = to_categorical(test_targets_role, num_classes=num_roles)\n",
    "\n",
    "# Assuming 'timestamp' is a target to be predicted in a regression context,\n",
    "# and thus doesn't require conversion to categorical. \n",
    "# Ensure `train_targets_timestamp` and `test_targets_timestamp` are properly scaled if needed.\n",
    "\n",
    "# Adjusting the `model.fit` call to include the new attributes\n",
    "history = model.fit([train_resource, train_activity, train_role, train_timestamp], \n",
    "                    [train_targets_resource_cat, train_targets_activity_cat, train_targets_role_cat, train_targets_timestamp],\n",
    "                    epochs=25,\n",
    "                    batch_size=64,\n",
    "                    validation_data=([test_resource, test_activity, test_role, test_timestamp], \n",
    "                                     [test_targets_resource_cat, test_targets_activity_cat, test_targets_role_cat, test_targets_timestamp]),\n",
    "                    verbose=1,\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 1s 3ms/step - loss: 0.7849 - output_resource_loss: 0.0272 - output_activity_loss: 0.0713 - output_role_loss: 0.0466 - output_timestamp_loss: 0.6398 - output_resource_accuracy: 0.9912 - output_activity_accuracy: 0.9750 - output_role_accuracy: 0.9798\n",
      "[0.7848706841468811, 0.027200503274798393, 0.07126368582248688, 0.04657338932156563, 0.6398330926895142, 0.9912256002426147, 0.9749836921691895, 0.9798375964164734]\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(\n",
    "    [test_resource, test_activity, test_role, test_timestamp],\n",
    "    [test_targets_resource_cat, test_targets_activity_cat, test_targets_role_cat, test_targets_timestamp]\n",
    ")\n",
    "\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model to an H5 file\n",
    "model.save('dapnn_domestic.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Score Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116/1116 [==============================] - 5s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for all inputs\n",
    "predictions = model.predict([windows_resource, windows_activity, windows_role, windows_timestamp])\n",
    "\n",
    "# Assuming your model is set to predict id, resource, activity, and role categories\n",
    "# Extract predictions for categorical attributes (softmax probabilities)\n",
    "predictions_resource = predictions[0] # Resource predictions\n",
    "predictions_activity = predictions[1] # Activity predictions\n",
    "predictions_role = predictions[2]     # Role predictions\n",
    "\n",
    "# If you had added 'timestamp' as a target to be predicted, you would extract its predictions like so:\n",
    "predictions_timestamp = predictions[3]  # Assuming 'timestamp' is a regression target and the model is adjusted accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def compute_anomaly_scores(predictions, actuals):\n",
    "    # For categorical predictions, convert actuals to one-hot for comparison\n",
    "    actuals_one_hot = to_categorical(actuals, num_classes=predictions.shape[-1])\n",
    "    \n",
    "    max_predictions = np.max(predictions, axis=-1)\n",
    "    actual_predictions = np.sum(predictions * actuals_one_hot, axis=-1)  # Extract the probability of the actual class\n",
    "    \n",
    "    anomaly_scores = (max_predictions - actual_predictions) / max_predictions\n",
    "    \n",
    "    return anomaly_scores\n",
    "\n",
    "# Assuming targets_id, targets_resource, targets_activity, targets_role are the true values for these attributes\n",
    "anomaly_scores_resource = compute_anomaly_scores(predictions_resource, targets_resource)\n",
    "anomaly_scores_activity = compute_anomaly_scores(predictions_activity, targets_activity)\n",
    "anomaly_scores_role = compute_anomaly_scores(predictions_role, targets_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_anomaly_scores_continuous(predictions, actuals, normalization_factor):\n",
    "    \"\"\"\n",
    "    Compute anomaly scores for continuous attributes.\n",
    "    \n",
    "    Parameters:\n",
    "    - predictions: numpy array of predicted values.\n",
    "    - actuals: numpy array of actual values.\n",
    "    - normalization_factor: normalization factor (e.g., standard deviation of the attribute).\n",
    "    \n",
    "    Returns:\n",
    "    - numpy array of anomaly scores.\n",
    "    \"\"\"\n",
    "    # Calculate absolute differences\n",
    "    differences = np.abs(predictions - actuals)\n",
    "    \n",
    "    # Normalize the differences\n",
    "    anomaly_scores = differences / normalization_factor\n",
    "    \n",
    "    return anomaly_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_factor = np.std(targets_timestamp)       # Example normalization factor (standard deviation)\n",
    "anomaly_scores_timestamp = compute_anomaly_scores_continuous(predictions_timestamp, targets_timestamp, normalization_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def classify_cases(anomaly_scores_resource, anomaly_scores_activity, anomaly_scores_timestamp, anomaly_scores_role,  threshold=0.98):\n",
    "    # Ensure all inputs are numpy arrays of the same shape\n",
    "    anomaly_scores_resource = np.array(anomaly_scores_resource).flatten()\n",
    "    anomaly_scores_activity = np.array(anomaly_scores_activity).flatten()\n",
    "    anomaly_scores_timestamp = np.array(anomaly_scores_timestamp).flatten()\n",
    "    anomaly_scores_role = np.array(anomaly_scores_role).flatten()\n",
    "\n",
    "\n",
    "    # Check if all arrays have the same length\n",
    "    if not (len(anomaly_scores_resource) == len(anomaly_scores_activity) == len(anomaly_scores_timestamp == len(anomaly_scores_role))):\n",
    "        raise ValueError(\"All input anomaly scores must have the same length.\")\n",
    "\n",
    "    # Find the maximum anomaly score across all attributes for each case\n",
    "    max_scores = np.maximum.reduce([anomaly_scores_resource, anomaly_scores_activity, anomaly_scores_timestamp, anomaly_scores_role])\n",
    "\n",
    "    # Classify cases as anomalous if the maximum anomaly score exceeds the threshold\n",
    "    anomalous_cases = max_scores > threshold\n",
    "    \n",
    "    return anomalous_cases\n",
    "\n",
    "# Now use the anomaly scores for resource, activity, and timestamp in the classification\n",
    "anomalous_cases = classify_cases(anomaly_scores_resource, anomaly_scores_activity, anomaly_scores_timestamp, anomaly_scores_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def classify_cases(anomaly_scores_activity,  threshold=0.98):\n",
    "    # Ensure all inputs are numpy arrays of the same shape\n",
    "    anomaly_scores_activity = np.array(anomaly_scores_activity).flatten()\n",
    "\n",
    "    # Find the maximum anomaly score across all attributes for each case\n",
    "    max_scores = np.maximum.reduce([anomaly_scores_activity])\n",
    "\n",
    "    # Classify cases as anomalous if the maximum anomaly score exceeds the threshold\n",
    "    anomalous_cases = max_scores > threshold\n",
    "    \n",
    "    return anomalous_cases\n",
    "\n",
    "# Now use the anomaly scores for resource, activity, and timestamp in the classification\n",
    "anomalous_cases = classify_cases(anomaly_scores_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True: anomaly, False: no anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35705</th>\n",
       "      <td>10498</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35706</th>\n",
       "      <td>10498</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35707</th>\n",
       "      <td>10499</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35708</th>\n",
       "      <td>10499</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35709</th>\n",
       "      <td>10499</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35710 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        case  predicted\n",
       "0          0      False\n",
       "1          0      False\n",
       "2          1      False\n",
       "3          1      False\n",
       "4          1      False\n",
       "...      ...        ...\n",
       "35705  10498      False\n",
       "35706  10498      False\n",
       "35707  10499      False\n",
       "35708  10499      False\n",
       "35709  10499      False\n",
       "\n",
       "[35710 rows x 2 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from the case_indices_array corresponding to case_resource\n",
    "mapping = pd.DataFrame({'case': case_indices})\n",
    "mapping['predicted'] = anomalous_cases\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case\n",
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "10495    False\n",
       "10496    False\n",
       "10497    False\n",
       "10498    False\n",
       "10499    False\n",
       "Name: predicted, Length: 10500, dtype: bool"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_prediction = mapping.groupby('case')['predicted'].any()\n",
    "case_prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking):\n",
    "    from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments\n",
    "    from pm4py.algo.conformance.alignments.petri_net import variants\n",
    "    from pm4py.objects.petri_net.utils import align_utils\n",
    "    max_events=0\n",
    "    for trace in log:\n",
    "        counter=0\n",
    "        for event in trace:\n",
    "            counter+=1\n",
    "        if counter > max_events:\n",
    "            max_events=counter\n",
    "    parameters={}\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_SYNC_COST_FUNCTION] = list(map(lambda i: .1*i, range(max_events*2)))\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_TRACE_COST_FUNCTION]=list(map(lambda i: align_utils.STD_MODEL_LOG_MOVE_COST-.1*i, range(max_events*2)))\n",
    "    aligned_traces = alignments.apply_log(log, net, initial_marking, final_marking, variant=variants.state_equation_a_star, parameters=parameters)\n",
    "    return aligned_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a293e83b732544879a3a9c42401bdfd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/model/Model_ DomesticDeclarations.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_traces = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conformance_status_by_fitness(aligned_traces):\n",
    "    conformance_status = []\n",
    "    for alignment in aligned_traces:\n",
    "        fitness = alignment['fitness']\n",
    "        # If the fitness is 1.0, the trace is conforming\n",
    "        if fitness == 1.0:\n",
    "            conformance_status.append(1)\n",
    "        else:\n",
    "            conformance_status.append(0)\n",
    "    return conformance_status\n",
    "\n",
    "# Get the conformance status list from the aligned traces\n",
    "conformance = extract_conformance_status_by_fitness(aligned_traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conformity</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10495</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10497</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10499</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       conformity  predicted\n",
       "0               0          1\n",
       "1               0          1\n",
       "2               0          1\n",
       "3               0          1\n",
       "4               0          1\n",
       "...           ...        ...\n",
       "10495           1          1\n",
       "10496           1          1\n",
       "10497           1          1\n",
       "10498           1          1\n",
       "10499           1          1\n",
       "\n",
       "[10500 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = pd.DataFrame({'conformity': conformance})\n",
    "ground_truth['predicted'] = case_prediction\n",
    "\n",
    "# Convert False to 0 and True to 1\n",
    "ground_truth['predicted'] = [int(value) for value in ground_truth['predicted']]\n",
    "ground_truth['predicted'] = 1 - ground_truth['predicted']\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating TP, TN, FP, FN\n",
    "TP = ((ground_truth['conformity'] == 1) & (ground_truth['predicted'] == 1)).sum()\n",
    "TN = ((ground_truth['conformity'] == 0) & (ground_truth['predicted'] == 0)).sum()\n",
    "FP = ((ground_truth['conformity'] == 0) & (ground_truth['predicted'] == 1)).sum()\n",
    "FN = ((ground_truth['conformity'] == 1) & (ground_truth['predicted'] == 0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.702\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.824\n"
     ]
    }
   ],
   "source": [
    "# Calculate f1\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "print(f\"F1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev (Non Conform Traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.957\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision for Dev\n",
    "precision = TN / (TN + FN)\n",
    "print(f\"Precision: {precision:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.021\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall for Dev\n",
    "recall = TN / (TN + FP)\n",
    "print(f\"Recall: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Dev (Conform Traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.701\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision for No Dev\n",
    "precision = TP / (TP + FP)\n",
    "print(f\"Precision: {precision:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall for No Dev\n",
    "recall = TP / (TP + FN)\n",
    "print(f\"Recall: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5103030133514903"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Assuming ground_truth is your DataFrame\n",
    "# Make sure 'conformity' contains actual labels (0 or 1)\n",
    "# and 'predicted' contains predicted probabilities or scores\n",
    "auc_roc = roc_auc_score(ground_truth['conformity'], ground_truth['predicted'])\n",
    "auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
