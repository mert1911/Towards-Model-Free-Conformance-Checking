{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Event Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a446e9435a24276a1ccd44939c7dbed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>org:role</th>\n",
       "      <th>case:Rfp_id</th>\n",
       "      <th>case:Project</th>\n",
       "      <th>case:Task</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>case:OrganizationalEntity</th>\n",
       "      <th>case:Cost Type</th>\n",
       "      <th>case:RequestedAmount</th>\n",
       "      <th>case:Activity</th>\n",
       "      <th>case:RfpNumber</th>\n",
       "      <th>@@case_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>st_step 148220_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Request For Payment SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2017-01-09 08:17:18+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>request for payment 148214</td>\n",
       "      <td>project 148216</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>request for payment 148214</td>\n",
       "      <td>organizational unit 65463</td>\n",
       "      <td>0</td>\n",
       "      <td>34.336343</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>request for payment number 148215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>st_step 148221_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Request For Payment FINAL_APPROVED by SUPERVISOR</td>\n",
       "      <td>2017-01-09 08:18:00+00:00</td>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>request for payment 148214</td>\n",
       "      <td>project 148216</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>request for payment 148214</td>\n",
       "      <td>organizational unit 65463</td>\n",
       "      <td>0</td>\n",
       "      <td>34.336343</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>request for payment number 148215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>st_step 148222_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Request For Payment REJECTED by MISSING</td>\n",
       "      <td>2017-01-10 11:42:32+00:00</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>request for payment 148214</td>\n",
       "      <td>project 148216</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>request for payment 148214</td>\n",
       "      <td>organizational unit 65463</td>\n",
       "      <td>0</td>\n",
       "      <td>34.336343</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>request for payment number 148215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>st_step 148219_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Request For Payment SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2017-03-03 08:51:13+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>request for payment 148214</td>\n",
       "      <td>project 148216</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>request for payment 148214</td>\n",
       "      <td>organizational unit 65463</td>\n",
       "      <td>0</td>\n",
       "      <td>34.336343</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>request for payment number 148215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>st_step 148218_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Request For Payment APPROVED by PRE_APPROVER</td>\n",
       "      <td>2017-03-03 08:51:42+00:00</td>\n",
       "      <td>PRE_APPROVER</td>\n",
       "      <td>request for payment 148214</td>\n",
       "      <td>project 148216</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>request for payment 148214</td>\n",
       "      <td>organizational unit 65463</td>\n",
       "      <td>0</td>\n",
       "      <td>34.336343</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>request for payment number 148215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36791</th>\n",
       "      <td>st_step 185004_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Request For Payment APPROVED by ADMINISTRATION</td>\n",
       "      <td>2018-12-29 11:35:02+00:00</td>\n",
       "      <td>ADMINISTRATION</td>\n",
       "      <td>request for payment 185000</td>\n",
       "      <td>project 147860</td>\n",
       "      <td>task 152704</td>\n",
       "      <td>request for payment 185000</td>\n",
       "      <td>organizational unit 65468</td>\n",
       "      <td>0</td>\n",
       "      <td>15.409660</td>\n",
       "      <td>activity 505</td>\n",
       "      <td>request for payment number 185001</td>\n",
       "      <td>6885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36792</th>\n",
       "      <td>st_step 185003_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Request For Payment APPROVED by BUDGET OWNER</td>\n",
       "      <td>2019-01-03 08:27:20+00:00</td>\n",
       "      <td>BUDGET OWNER</td>\n",
       "      <td>request for payment 185000</td>\n",
       "      <td>project 147860</td>\n",
       "      <td>task 152704</td>\n",
       "      <td>request for payment 185000</td>\n",
       "      <td>organizational unit 65468</td>\n",
       "      <td>0</td>\n",
       "      <td>15.409660</td>\n",
       "      <td>activity 505</td>\n",
       "      <td>request for payment number 185001</td>\n",
       "      <td>6885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36793</th>\n",
       "      <td>st_step 185005_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Request For Payment FINAL_APPROVED by SUPERVISOR</td>\n",
       "      <td>2019-01-08 08:00:39+00:00</td>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>request for payment 185000</td>\n",
       "      <td>project 147860</td>\n",
       "      <td>task 152704</td>\n",
       "      <td>request for payment 185000</td>\n",
       "      <td>organizational unit 65468</td>\n",
       "      <td>0</td>\n",
       "      <td>15.409660</td>\n",
       "      <td>activity 505</td>\n",
       "      <td>request for payment number 185001</td>\n",
       "      <td>6885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36794</th>\n",
       "      <td>rp_request for payment 185000_15</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Request Payment</td>\n",
       "      <td>2019-01-08 08:29:14+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>request for payment 185000</td>\n",
       "      <td>project 147860</td>\n",
       "      <td>task 152704</td>\n",
       "      <td>request for payment 185000</td>\n",
       "      <td>organizational unit 65468</td>\n",
       "      <td>0</td>\n",
       "      <td>15.409660</td>\n",
       "      <td>activity 505</td>\n",
       "      <td>request for payment number 185001</td>\n",
       "      <td>6885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36795</th>\n",
       "      <td>rp_request for payment 185000_16</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Payment Handled</td>\n",
       "      <td>2019-01-10 16:31:09+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>request for payment 185000</td>\n",
       "      <td>project 147860</td>\n",
       "      <td>task 152704</td>\n",
       "      <td>request for payment 185000</td>\n",
       "      <td>organizational unit 65468</td>\n",
       "      <td>0</td>\n",
       "      <td>15.409660</td>\n",
       "      <td>activity 505</td>\n",
       "      <td>request for payment number 185001</td>\n",
       "      <td>6885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36796 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  org:resource  \\\n",
       "0                      st_step 148220_0  STAFF MEMBER   \n",
       "1                      st_step 148221_0  STAFF MEMBER   \n",
       "2                      st_step 148222_0  STAFF MEMBER   \n",
       "3                      st_step 148219_0  STAFF MEMBER   \n",
       "4                      st_step 148218_0  STAFF MEMBER   \n",
       "...                                 ...           ...   \n",
       "36791                  st_step 185004_0  STAFF MEMBER   \n",
       "36792                  st_step 185003_0  STAFF MEMBER   \n",
       "36793                  st_step 185005_0  STAFF MEMBER   \n",
       "36794  rp_request for payment 185000_15        SYSTEM   \n",
       "36795  rp_request for payment 185000_16        SYSTEM   \n",
       "\n",
       "                                           concept:name  \\\n",
       "0             Request For Payment SUBMITTED by EMPLOYEE   \n",
       "1      Request For Payment FINAL_APPROVED by SUPERVISOR   \n",
       "2               Request For Payment REJECTED by MISSING   \n",
       "3             Request For Payment SUBMITTED by EMPLOYEE   \n",
       "4          Request For Payment APPROVED by PRE_APPROVER   \n",
       "...                                                 ...   \n",
       "36791    Request For Payment APPROVED by ADMINISTRATION   \n",
       "36792      Request For Payment APPROVED by BUDGET OWNER   \n",
       "36793  Request For Payment FINAL_APPROVED by SUPERVISOR   \n",
       "36794                                   Request Payment   \n",
       "36795                                   Payment Handled   \n",
       "\n",
       "                 time:timestamp        org:role                 case:Rfp_id  \\\n",
       "0     2017-01-09 08:17:18+00:00        EMPLOYEE  request for payment 148214   \n",
       "1     2017-01-09 08:18:00+00:00      SUPERVISOR  request for payment 148214   \n",
       "2     2017-01-10 11:42:32+00:00         MISSING  request for payment 148214   \n",
       "3     2017-03-03 08:51:13+00:00        EMPLOYEE  request for payment 148214   \n",
       "4     2017-03-03 08:51:42+00:00    PRE_APPROVER  request for payment 148214   \n",
       "...                         ...             ...                         ...   \n",
       "36791 2018-12-29 11:35:02+00:00  ADMINISTRATION  request for payment 185000   \n",
       "36792 2019-01-03 08:27:20+00:00    BUDGET OWNER  request for payment 185000   \n",
       "36793 2019-01-08 08:00:39+00:00      SUPERVISOR  request for payment 185000   \n",
       "36794 2019-01-08 08:29:14+00:00       UNDEFINED  request for payment 185000   \n",
       "36795 2019-01-10 16:31:09+00:00       UNDEFINED  request for payment 185000   \n",
       "\n",
       "         case:Project    case:Task           case:concept:name  \\\n",
       "0      project 148216      UNKNOWN  request for payment 148214   \n",
       "1      project 148216      UNKNOWN  request for payment 148214   \n",
       "2      project 148216      UNKNOWN  request for payment 148214   \n",
       "3      project 148216      UNKNOWN  request for payment 148214   \n",
       "4      project 148216      UNKNOWN  request for payment 148214   \n",
       "...               ...          ...                         ...   \n",
       "36791  project 147860  task 152704  request for payment 185000   \n",
       "36792  project 147860  task 152704  request for payment 185000   \n",
       "36793  project 147860  task 152704  request for payment 185000   \n",
       "36794  project 147860  task 152704  request for payment 185000   \n",
       "36795  project 147860  task 152704  request for payment 185000   \n",
       "\n",
       "       case:OrganizationalEntity  case:Cost Type  case:RequestedAmount  \\\n",
       "0      organizational unit 65463               0             34.336343   \n",
       "1      organizational unit 65463               0             34.336343   \n",
       "2      organizational unit 65463               0             34.336343   \n",
       "3      organizational unit 65463               0             34.336343   \n",
       "4      organizational unit 65463               0             34.336343   \n",
       "...                          ...             ...                   ...   \n",
       "36791  organizational unit 65468               0             15.409660   \n",
       "36792  organizational unit 65468               0             15.409660   \n",
       "36793  organizational unit 65468               0             15.409660   \n",
       "36794  organizational unit 65468               0             15.409660   \n",
       "36795  organizational unit 65468               0             15.409660   \n",
       "\n",
       "      case:Activity                     case:RfpNumber  @@case_index  \n",
       "0           UNKNOWN  request for payment number 148215             0  \n",
       "1           UNKNOWN  request for payment number 148215             0  \n",
       "2           UNKNOWN  request for payment number 148215             0  \n",
       "3           UNKNOWN  request for payment number 148215             0  \n",
       "4           UNKNOWN  request for payment number 148215             0  \n",
       "...             ...                                ...           ...  \n",
       "36791  activity 505  request for payment number 185001          6885  \n",
       "36792  activity 505  request for payment number 185001          6885  \n",
       "36793  activity 505  request for payment number 185001          6885  \n",
       "36794  activity 505  request for payment number 185001          6885  \n",
       "36795  activity 505  request for payment number 185001          6885  \n",
       "\n",
       "[36796 rows x 15 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the XES file\n",
    "    dataframe_log = pm4py.read_xes('../../data/logs/RequestForPayment.xes')\n",
    "\n",
    "    # If 'log' is already a DataFrame, add the @@case_index column directly\n",
    "    case_indices = {case_id: idx for idx, case_id in enumerate(dataframe_log['case:concept:name'].unique())}\n",
    "    dataframe_log['@@case_index'] = dataframe_log['case:concept:name'].map(case_indices)\n",
    "    \n",
    "     # Convert the dataframe to event log\n",
    "    log = log_converter.apply(dataframe_log)\n",
    "    \n",
    "dataframe_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(dataframe_log['concept:name'])\n",
    "dataframe_log['concept:name'] = codes + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activity = dataframe_log[['concept:name', '@@case_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def generate_prefix_windows(df, case_id_column='@@case_index', max_len=None):\n",
    "    windows = []\n",
    "    targets = []\n",
    "    case_indices = []\n",
    "    \n",
    "    for case_id in df[case_id_column].unique():\n",
    "        case_data = df[df[case_id_column] == case_id].drop(columns=[case_id_column]).to_numpy()\n",
    "        \n",
    "        # Optional: Make sure to sort the case data if there's an implicit order (e.g., by timestamps)\n",
    "        # case_data = case_data.sort_values(by='timestamp_column').to_numpy()  # Uncomment and adjust if needed\n",
    "        \n",
    "        for i in range(1, len(case_data)):\n",
    "            window = case_data[:i]\n",
    "            target = case_data[i]\n",
    "            windows.append(window)\n",
    "            targets.append(target)\n",
    "            case_indices.append(case_id)\n",
    "    \n",
    "    if max_len is None:\n",
    "        max_len = max(len(window) for window in windows)\n",
    "    \n",
    "    # Pad sequences\n",
    "    windows_padded = pad_sequences(windows, maxlen=max_len, padding='post', dtype='float32')\n",
    "    \n",
    "    # Convert targets to numpy array\n",
    "    targets_array = np.array(targets, dtype='float32')\n",
    "    case_indices_array = np.array(case_indices)\n",
    "    \n",
    "    return windows_padded, targets_array, case_indices_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_activity, targets_activity, case_indices = generate_prefix_windows(df_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separate Inputs for Each Attribute\n",
    "- Each attribute is passed through an embedding layer\n",
    "- Each attribute has its corresponding GRU encoder\n",
    "- Selective Concatenation: After encoding, the outputs of these GRU layers are concatenated. However, this concatenation is selective, meaning it is structured in a way that prepares the data for effective synthesis without leaking information from the future (next event attributes)\n",
    "- Decoder GRUs: Integrated Decoding: Post-concatenation, the combined attributes are processed through decoder GRU layers. These layers are tasked with integrating the data from different attributes and preparing it for final prediction. This step is where BINet v3 distinguishes itself by effectively using the interdependencies between different attributes to enhance prediction accuracy.\n",
    "- Output Layer: Softmax Output for Each Attribute: For each attribute of the next event, a softmax layer predicts a probability distribution over all possible values. This allows the model to output the most likely next event and its attributes based on the learned dependencies and the history encoded by the GRUs.\n",
    "- E: maximum case length\n",
    "- We train BINet with a GRU size of 2E (two times the maximum case length)\n",
    "- on mini batches of size 500 for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the @@case_index column and count the rows in each group\n",
    "case_lengths = dataframe_log.groupby('@@case_index').size()\n",
    "\n",
    "# Find the maximum value among the case lengths\n",
    "E = case_lengths.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " activity_input (InputLayer  [(None, None)]            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activity_embedding (Embedd  (None, None, 50)          1000      \n",
      " ing)                                                            \n",
      "                                                                 \n",
      " activity_encoder (GRU)      (None, 40)                11040     \n",
      "                                                                 \n",
      " bn_activity (BatchNormaliz  (None, 40)                160       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40)                0         \n",
      "                                                                 \n",
      " output_activity (Dense)     (None, 20)                820       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13020 (50.86 KB)\n",
      "Trainable params: 12940 (50.55 KB)\n",
      "Non-trainable params: 80 (320.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Embedding, Dense, Dropout, BatchNormalization\n",
    "\n",
    "def create_binetv3_for_activity(num_activities, embedding_dim, gru_units, dropout_rate):\n",
    "    # Input layers for activity attribute\n",
    "    input_activity = Input(shape=(None,), name='activity_input')\n",
    "\n",
    "    # Embedding layer for activity attribute\n",
    "    embedding_activity = Embedding(input_dim=num_activities + 1, output_dim=embedding_dim, mask_zero=True, name='activity_embedding')(input_activity)\n",
    "\n",
    "    # Encoder GRU with Batch Normalization for activity\n",
    "    encoded_activity = GRU(units=gru_units, return_sequences=False, name='activity_encoder')(embedding_activity)\n",
    "    bn_activity = BatchNormalization(name='bn_activity')(encoded_activity)\n",
    "\n",
    "    # Dropout layer\n",
    "    dropout_layer = Dropout(rate=dropout_rate, name='dropout')(bn_activity)\n",
    "\n",
    "    # Output layer for predicting the next activity\n",
    "    output_activity = Dense(num_activities + 1, activation='softmax', name='output_activity')(dropout_layer)\n",
    "\n",
    "    # Building the model\n",
    "    model = Model(inputs=input_activity, outputs=output_activity)\n",
    "    model.compile(\n",
    "        optimizer='adam', \n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Parameters\n",
    "gru_units = int(2 * E) \n",
    "num_activities = dataframe_log['concept:name'].max()\n",
    "embedding_dim = 50\n",
    "dropout_rate = 0.2\n",
    "model = create_binetv3_for_activity(num_activities, embedding_dim, gru_units, dropout_rate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_activity, test_activity, train_targets_activity, test_targets_activity = train_test_split(\n",
    "    windows_activity, targets_activity, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_targets_activity_cat = to_categorical(train_targets_activity, num_classes=num_activities + 1)\n",
    "test_targets_activity_cat = to_categorical(test_targets_activity, num_classes=num_activities + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 7s 79ms/step - loss: 1.5749 - accuracy: 0.6814 - val_loss: 2.6668 - val_accuracy: 0.6595\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5442 - accuracy: 0.8506 - val_loss: 2.4321 - val_accuracy: 0.6898\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4617 - accuracy: 0.8527 - val_loss: 2.2299 - val_accuracy: 0.8442\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4420 - accuracy: 0.8534 - val_loss: 2.0119 - val_accuracy: 0.8461\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4348 - accuracy: 0.8536 - val_loss: 1.7767 - val_accuracy: 0.8461\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4260 - accuracy: 0.8546 - val_loss: 1.5162 - val_accuracy: 0.8461\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4219 - accuracy: 0.8550 - val_loss: 1.2488 - val_accuracy: 0.8461\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4171 - accuracy: 0.8553 - val_loss: 1.0023 - val_accuracy: 0.8462\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4169 - accuracy: 0.8552 - val_loss: 0.7912 - val_accuracy: 0.8461\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4110 - accuracy: 0.8569 - val_loss: 0.6327 - val_accuracy: 0.8462\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4100 - accuracy: 0.8575 - val_loss: 0.5326 - val_accuracy: 0.8469\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4095 - accuracy: 0.8569 - val_loss: 0.4789 - val_accuracy: 0.8482\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4084 - accuracy: 0.8581 - val_loss: 0.4429 - val_accuracy: 0.8473\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4070 - accuracy: 0.8587 - val_loss: 0.4291 - val_accuracy: 0.8480\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4041 - accuracy: 0.8582 - val_loss: 0.4232 - val_accuracy: 0.8473\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4025 - accuracy: 0.8581 - val_loss: 0.4201 - val_accuracy: 0.8482\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4043 - accuracy: 0.8580 - val_loss: 0.4186 - val_accuracy: 0.8480\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4008 - accuracy: 0.8594 - val_loss: 0.4185 - val_accuracy: 0.8479\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.4000 - accuracy: 0.8594 - val_loss: 0.4168 - val_accuracy: 0.8480\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.4028 - accuracy: 0.8580 - val_loss: 0.4178 - val_accuracy: 0.8479\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_activity,  # Only the activity input\n",
    "    train_targets_activity_cat,  # Only the activity targets\n",
    "    validation_data=(test_activity, test_targets_activity_cat),  # Only the activity input and targets for validation\n",
    "    epochs=20,\n",
    "    batch_size=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8479\n",
      "Validation Loss: 0.41779589653015137, Validation Accuracy: 0.8478769659996033\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "results = model.evaluate(\n",
    "    test_activity,  # Only the activity input\n",
    "    test_targets_activity_cat,  # Only the activity targets\n",
    "    batch_size=64\n",
    ")\n",
    "print(f\"Validation Loss: {results[0]}, Validation Accuracy: {results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model to an H5 file\n",
    "model.save('RfP.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Score Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each event attribute, BINet's softmax layer outputs a probability distribution over possible values\n",
    "- The anomaly score for a specific attribute value v is calculated by summing all the probabilities from the softmax output that are greater than the probability assigned to v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NOTE: Do not include ID because no learning through GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935/935 [==============================] - 3s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for all inputs\n",
    "predictions_activity = model.predict([windows_activity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_anomaly_scores(predictions, targets):\n",
    "    scores = []\n",
    "    # Loop through each example in the predictions\n",
    "    for i in range(predictions.shape[0]):\n",
    "        actual_prob = predictions[i, targets[i]]  # Extract the probability of the true class using target index\n",
    "        # Calculate anomaly score as sum of probabilities greater than the probability of the actual value\n",
    "        anomaly_score = np.sum(predictions[i][predictions[i] > actual_prob])\n",
    "        scores.append(anomaly_score)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_scores_activity = calculate_anomaly_scores(predictions_activity, targets_activity.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert missing scores for cases with less than 2 Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>score_activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.855848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.954231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.725297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29905</th>\n",
       "      <td>6885</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29906</th>\n",
       "      <td>6885</td>\n",
       "      <td>0.636433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29907</th>\n",
       "      <td>6885</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29908</th>\n",
       "      <td>6885</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29909</th>\n",
       "      <td>6885</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29910 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       case  score_activity\n",
       "0         0        0.855848\n",
       "1         0        0.954231\n",
       "2         0        0.000000\n",
       "3         0        0.725297\n",
       "4         0        0.000000\n",
       "...     ...             ...\n",
       "29905  6885        0.000000\n",
       "29906  6885        0.636433\n",
       "29907  6885        0.000000\n",
       "29908  6885        0.000000\n",
       "29909  6885        0.000000\n",
       "\n",
       "[29910 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the case_indices_array corresponding to case_resource\n",
    "score = pd.DataFrame({'case': case_indices})\n",
    "score['score_activity'] = anomaly_scores_activity\n",
    "\n",
    "score['case'] = score['case'].astype(int)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: [179, 181, 188, 354, 387, 450, 529, 545, 601, 765, 835, 974, 1020, 1202, 1273, 1299, 1301, 1324, 1329, 1347, 1390, 1431, 1578, 1601, 1636, 1895, 2022, 2091, 2151, 2152, 2226, 2367, 2466, 2712, 2897, 2983, 3041, 3297, 3440, 3478, 3573, 3652, 3659, 3865, 3960, 4064, 4235, 4279, 4389, 4638, 4865]\n",
      "Does the 'case' column contain all values between 0 and 4999? False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def contains_all_values(df, column, end):\n",
    "\n",
    "    # Generate the set of all values in the specified range\n",
    "    required_values = set(range(0, end + 1))\n",
    "    \n",
    "    # Get the unique values in the specified column\n",
    "    column_values = set(df[column].unique())\n",
    "    \n",
    "    # Find missing values\n",
    "    missing_values = required_values - column_values\n",
    "    \n",
    "    # Print missing values if any\n",
    "    if missing_values:\n",
    "        print(f\"Missing values: {sorted(missing_values)}\")\n",
    "    \n",
    "    # Check if all required values are in the column values\n",
    "    return required_values.issubset(column_values)\n",
    "\n",
    "end = 4999\n",
    "\n",
    "result = contains_all_values(score, 'case', end)\n",
    "print(f\"Does the 'case' column contain all values between 0 and {end}? {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>score_activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.855848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.954231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.725297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29977</th>\n",
       "      <td>6885</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29978</th>\n",
       "      <td>6885</td>\n",
       "      <td>0.636433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29979</th>\n",
       "      <td>6885</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29980</th>\n",
       "      <td>6885</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29981</th>\n",
       "      <td>6885</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29982 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       case  score_activity\n",
       "0         0        0.855848\n",
       "1         0        0.954231\n",
       "2         0        0.000000\n",
       "3         0        0.725297\n",
       "4         0        0.000000\n",
       "...     ...             ...\n",
       "29977  6885        0.000000\n",
       "29978  6885        0.636433\n",
       "29979  6885        0.000000\n",
       "29980  6885        0.000000\n",
       "29981  6885        0.000000\n",
       "\n",
       "[29982 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the full range of values\n",
    "full_range = set(range(6886))\n",
    "\n",
    "# Get the existing 'case' values\n",
    "existing_cases = set(score['case'])\n",
    "\n",
    "# Identify missing values\n",
    "missing_cases = full_range - existing_cases\n",
    "\n",
    "# Create a DataFrame for missing values\n",
    "missing_df = pd.DataFrame({'case': list(missing_cases)})\n",
    "\n",
    "# Add other columns with value 1\n",
    "for col in score.columns:\n",
    "    if col != 'case':\n",
    "        missing_df[col] = 1\n",
    "\n",
    "# Concatenate the original DataFrame with the missing values DataFrame\n",
    "updated_score = pd.concat([score, missing_df])\n",
    "\n",
    "# Sort the DataFrame by 'case'\n",
    "updated_score = updated_score.sort_values(by='case').reset_index(drop=True)\n",
    "\n",
    "updated_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_scores_activity = updated_score['score_activity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold (lowest plateau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_anomaly_ratio(scores, threshold):\n",
    "    \"\"\"\n",
    "    Calculate the anomaly ratio for a given threshold.\n",
    "    \"\"\"\n",
    "    return np.mean(scores > threshold)\n",
    "\n",
    "def find_plateaus(scores, epsilon=1e-4, min_plateau_length=10):\n",
    "    \"\"\"\n",
    "    Identify the lowest plateau in the anomaly ratio function and calculate the mean-centered threshold.\n",
    "    \"\"\"\n",
    "    scores = np.array(scores)  # Convert scores to a NumPy array\n",
    "    sorted_scores = np.sort(scores)\n",
    "    \n",
    "    # Remove duplicate values\n",
    "    unique_thresholds, unique_indices = np.unique(sorted_scores, return_index=True)\n",
    "    anomaly_ratios = np.array([calculate_anomaly_ratio(scores, t) for t in unique_thresholds])\n",
    "    \n",
    "    # Calculate first and second derivatives\n",
    "    first_derivatives = np.diff(anomaly_ratios) / np.diff(unique_thresholds)\n",
    "    second_derivatives = np.diff(first_derivatives) / np.diff(unique_thresholds[:-1])\n",
    "    \n",
    "    # Identify plateaus where the first derivative is close to zero\n",
    "    plateau_indices = np.where(np.abs(first_derivatives) < epsilon)[0]\n",
    "    \n",
    "    # Group consecutive indices to identify continuous plateaus\n",
    "    grouped_plateaus = np.split(plateau_indices, np.where(np.diff(plateau_indices) != 1)[0] + 1)\n",
    "    \n",
    "    # Filter plateaus based on minimum length\n",
    "    long_plateaus = [g for g in grouped_plateaus if len(g) >= min_plateau_length]\n",
    "    \n",
    "    if long_plateaus:\n",
    "        # Take the first long plateau and find the mean threshold in this plateau\n",
    "        first_plateau = long_plateaus[0]\n",
    "        plateau_thresholds = unique_thresholds[first_plateau]\n",
    "        return np.mean(plateau_thresholds)\n",
    "    else:\n",
    "        # If no plateau is found, return a default value, e.g., the 90th percentile\n",
    "        percentile_90 = np.percentile(sorted_scores, 90)\n",
    "        if percentile_90 == 1.0:\n",
    "            return 0.4\n",
    "        else:\n",
    "            return percentile_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_activity = find_plateaus(anomaly_scores_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.855848\n",
       "1        0.954231\n",
       "2        0.000000\n",
       "3        0.725297\n",
       "4        0.000000\n",
       "           ...   \n",
       "29977    0.000000\n",
       "29978    0.636433\n",
       "29979    0.000000\n",
       "29980    0.000000\n",
       "29981    0.000000\n",
       "Name: score_activity, Length: 29982, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_scores_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6364331245422363"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(anomaly_scores, threshold):\n",
    "    labels = [1 if score > threshold else 0 for score in anomaly_scores]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect anomalies based on the calculated anomaly scores and thresholds\n",
    "labels_activity = detect_anomalies(anomaly_scores_activity, threshold_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_indices = updated_score['case']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>predicted_activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29977</th>\n",
       "      <td>6885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29978</th>\n",
       "      <td>6885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29979</th>\n",
       "      <td>6885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29980</th>\n",
       "      <td>6885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29981</th>\n",
       "      <td>6885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29982 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       case  predicted_activity\n",
       "0         0                   1\n",
       "1         0                   1\n",
       "2         0                   0\n",
       "3         0                   1\n",
       "4         0                   0\n",
       "...     ...                 ...\n",
       "29977  6885                   0\n",
       "29978  6885                   0\n",
       "29979  6885                   0\n",
       "29980  6885                   0\n",
       "29981  6885                   0\n",
       "\n",
       "[29982 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the case_indices_array corresponding to case_resource\n",
    "mapping = pd.DataFrame({'case': case_indices})\n",
    "mapping['predicted_activity'] = labels_activity\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case\n",
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "        ...  \n",
       "6881    False\n",
       "6882    False\n",
       "6883    False\n",
       "6884    False\n",
       "6885    False\n",
       "Length: 6886, dtype: bool"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a boolean DataFrame where each value is True if the value is 1\n",
    "contains_one = (mapping[['predicted_activity']] == 1)\n",
    "\n",
    "# Group by 'case' and check if there's at least one 'True' in any of the columns\n",
    "case_prediction = contains_one.groupby(mapping['case']).any().any(axis=1)\n",
    "case_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking):\n",
    "    from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments\n",
    "    from pm4py.algo.conformance.alignments.petri_net import variants\n",
    "    from pm4py.objects.petri_net.utils import align_utils\n",
    "    max_events=0\n",
    "    for trace in log:\n",
    "        counter=0\n",
    "        for event in trace:\n",
    "            counter+=1\n",
    "        if counter > max_events:\n",
    "            max_events=counter\n",
    "    parameters={}\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_SYNC_COST_FUNCTION] = list(map(lambda i: .1*i, range(max_events*2)))\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_TRACE_COST_FUNCTION]=list(map(lambda i: align_utils.STD_MODEL_LOG_MOVE_COST-.1*i, range(max_events*2)))\n",
    "    aligned_traces = alignments.apply_log(log, net, initial_marking, final_marking, variant=variants.state_equation_a_star, parameters=parameters)\n",
    "    return aligned_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fe93a7ab654443acdcc16b80c3ae8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/model/Model_RequestForPayment.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_traces = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conformance_status_by_fitness(aligned_traces):\n",
    "    conformance_status = []\n",
    "    for alignment in aligned_traces:\n",
    "        fitness = alignment['fitness']\n",
    "        # If the fitness is 1.0, the trace is conforming\n",
    "        if fitness == 1.0:\n",
    "            conformance_status.append(0)\n",
    "        else:\n",
    "            conformance_status.append(1)\n",
    "    return conformance_status\n",
    "\n",
    "# Get the conformance status list from the aligned traces\n",
    "conformance = extract_conformance_status_by_fitness(aligned_traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conformity</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6881</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6882</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6883</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6884</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6885</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6886 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      conformity  predicted\n",
       "0              1          1\n",
       "1              1          1\n",
       "2              1          1\n",
       "3              1          1\n",
       "4              1          1\n",
       "...          ...        ...\n",
       "6881           0          0\n",
       "6882           0          0\n",
       "6883           0          0\n",
       "6884           0          0\n",
       "6885           0          0\n",
       "\n",
       "[6886 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = pd.DataFrame({'conformity': conformance})\n",
    "ground_truth['predicted'] = case_prediction\n",
    "\n",
    "# Convert False to 0 and True to 1\n",
    "ground_truth['predicted'] = [int(value) for value in ground_truth['predicted']]\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating TP, TN, FP, FN\n",
    "TP = ((ground_truth['conformity'] == 1) & (ground_truth['predicted'] == 1)).sum()\n",
    "TN = ((ground_truth['conformity'] == 0) & (ground_truth['predicted'] == 0)).sum()\n",
    "FP = ((ground_truth['conformity'] == 0) & (ground_truth['predicted'] == 1)).sum()\n",
    "FN = ((ground_truth['conformity'] == 1) & (ground_truth['predicted'] == 0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Dev: 0.80\n"
     ]
    }
   ],
   "source": [
    "precision_dev = TP / (TP + FP)\n",
    "print(f\"Precision Dev: {precision_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Dev: 1.00\n"
     ]
    }
   ],
   "source": [
    "recall_dev = TP / (TP + FN)\n",
    "print(f\"Recall Dev: {recall_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision No Dev: 1.00\n"
     ]
    }
   ],
   "source": [
    "precision_no_dev = TN / (TN + FN)\n",
    "print(f\"Precision No Dev: {precision_no_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall No Dev: 0.92\n"
     ]
    }
   ],
   "source": [
    "recall_no_dev = TN / (TN + FP)\n",
    "print(f\"Recall No Dev: {recall_no_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_roc = roc_auc_score(ground_truth['conformity'], ground_truth['predicted'])\n",
    "print(f\"AUC-ROC: {auc_roc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
