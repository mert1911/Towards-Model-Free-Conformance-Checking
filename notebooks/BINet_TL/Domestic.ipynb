{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Event Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pm4py/util/dt_parsing/parser.py:76: UserWarning: ISO8601 strings are not fully supported with strpfromiso for Python versions below 3.11\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f024be79c3456da2b796a48115a2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>org:role</th>\n",
       "      <th>case:id</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>case:BudgetNumber</th>\n",
       "      <th>case:DeclarationNumber</th>\n",
       "      <th>case:Amount</th>\n",
       "      <th>@@case_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>st_step 86794_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2017-01-09 08:49:50+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 86792</td>\n",
       "      <td>26.851205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>st_step 86793_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration FINAL_APPROVED by SUPERVISOR</td>\n",
       "      <td>2017-01-09 10:27:48+00:00</td>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 86792</td>\n",
       "      <td>26.851205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dd_declaration 86791_19</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Request Payment</td>\n",
       "      <td>2017-01-10 08:34:44+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 86792</td>\n",
       "      <td>26.851205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd_declaration 86791_20</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Payment Handled</td>\n",
       "      <td>2017-01-12 16:31:22+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 86792</td>\n",
       "      <td>26.851205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>st_step 86798_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2017-01-09 09:26:14+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>declaration 86795</td>\n",
       "      <td>declaration 86795</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 86796</td>\n",
       "      <td>182.464172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56432</th>\n",
       "      <td>st_step 138363_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2018-12-29 16:50:14+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 138360</td>\n",
       "      <td>190.404576</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56433</th>\n",
       "      <td>st_step 138361_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration APPROVED by ADMINISTRATION</td>\n",
       "      <td>2018-12-29 16:56:13+00:00</td>\n",
       "      <td>ADMINISTRATION</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 138360</td>\n",
       "      <td>190.404576</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56434</th>\n",
       "      <td>st_step 138362_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration FINAL_APPROVED by SUPERVISOR</td>\n",
       "      <td>2019-01-03 07:55:52+00:00</td>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 138360</td>\n",
       "      <td>190.404576</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56435</th>\n",
       "      <td>dd_declaration 138359_19</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Request Payment</td>\n",
       "      <td>2019-01-08 07:20:28+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 138360</td>\n",
       "      <td>190.404576</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56436</th>\n",
       "      <td>dd_declaration 138359_20</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Payment Handled</td>\n",
       "      <td>2019-01-10 16:31:08+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 138360</td>\n",
       "      <td>190.404576</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56437 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id  org:resource  \\\n",
       "0               st_step 86794_0  STAFF MEMBER   \n",
       "1               st_step 86793_0  STAFF MEMBER   \n",
       "2       dd_declaration 86791_19        SYSTEM   \n",
       "3       dd_declaration 86791_20        SYSTEM   \n",
       "4               st_step 86798_0  STAFF MEMBER   \n",
       "...                         ...           ...   \n",
       "56432          st_step 138363_0  STAFF MEMBER   \n",
       "56433          st_step 138361_0  STAFF MEMBER   \n",
       "56434          st_step 138362_0  STAFF MEMBER   \n",
       "56435  dd_declaration 138359_19        SYSTEM   \n",
       "56436  dd_declaration 138359_20        SYSTEM   \n",
       "\n",
       "                                   concept:name            time:timestamp  \\\n",
       "0             Declaration SUBMITTED by EMPLOYEE 2017-01-09 08:49:50+00:00   \n",
       "1      Declaration FINAL_APPROVED by SUPERVISOR 2017-01-09 10:27:48+00:00   \n",
       "2                               Request Payment 2017-01-10 08:34:44+00:00   \n",
       "3                               Payment Handled 2017-01-12 16:31:22+00:00   \n",
       "4             Declaration SUBMITTED by EMPLOYEE 2017-01-09 09:26:14+00:00   \n",
       "...                                         ...                       ...   \n",
       "56432         Declaration SUBMITTED by EMPLOYEE 2018-12-29 16:50:14+00:00   \n",
       "56433    Declaration APPROVED by ADMINISTRATION 2018-12-29 16:56:13+00:00   \n",
       "56434  Declaration FINAL_APPROVED by SUPERVISOR 2019-01-03 07:55:52+00:00   \n",
       "56435                           Request Payment 2019-01-08 07:20:28+00:00   \n",
       "56436                           Payment Handled 2019-01-10 16:31:08+00:00   \n",
       "\n",
       "             org:role             case:id   case:concept:name  \\\n",
       "0            EMPLOYEE   declaration 86791   declaration 86791   \n",
       "1          SUPERVISOR   declaration 86791   declaration 86791   \n",
       "2           UNDEFINED   declaration 86791   declaration 86791   \n",
       "3           UNDEFINED   declaration 86791   declaration 86791   \n",
       "4            EMPLOYEE   declaration 86795   declaration 86795   \n",
       "...               ...                 ...                 ...   \n",
       "56432        EMPLOYEE  declaration 138359  declaration 138359   \n",
       "56433  ADMINISTRATION  declaration 138359  declaration 138359   \n",
       "56434      SUPERVISOR  declaration 138359  declaration 138359   \n",
       "56435       UNDEFINED  declaration 138359  declaration 138359   \n",
       "56436       UNDEFINED  declaration 138359  declaration 138359   \n",
       "\n",
       "      case:BudgetNumber     case:DeclarationNumber  case:Amount  @@case_index  \n",
       "0          budget 86566   declaration number 86792    26.851205             0  \n",
       "1          budget 86566   declaration number 86792    26.851205             0  \n",
       "2          budget 86566   declaration number 86792    26.851205             0  \n",
       "3          budget 86566   declaration number 86792    26.851205             0  \n",
       "4          budget 86566   declaration number 86796   182.464172             1  \n",
       "...                 ...                        ...          ...           ...  \n",
       "56432      budget 86566  declaration number 138360   190.404576         10499  \n",
       "56433      budget 86566  declaration number 138360   190.404576         10499  \n",
       "56434      budget 86566  declaration number 138360   190.404576         10499  \n",
       "56435      budget 86566  declaration number 138360   190.404576         10499  \n",
       "56436      budget 86566  declaration number 138360   190.404576         10499  \n",
       "\n",
       "[56437 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the XES file\n",
    "    dataframe_log = pm4py.read_xes('../../data/logs/DomesticDeclarations.xes')\n",
    "\n",
    "    # If 'log' is already a DataFrame, add the @@case_index column directly\n",
    "    case_indices = {case_id: idx for idx, case_id in enumerate(dataframe_log['case:concept:name'].unique())}\n",
    "    dataframe_log['@@case_index'] = dataframe_log['case:concept:name'].map(case_indices)\n",
    "    \n",
    "     # Convert the dataframe to event log\n",
    "    log = log_converter.apply(dataframe_log)\n",
    "    \n",
    "dataframe_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(dataframe_log['concept:name'])\n",
    "dataframe_log['concept:name'] = codes + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activity = dataframe_log[['concept:name', '@@case_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sliding_windows(df, case_id_column='@@case_index', window_size=5):\n",
    "    windows = []\n",
    "    targets = []\n",
    "    case_indices = []\n",
    "\n",
    "    # Iterate over each unique case\n",
    "    for case_id in df[case_id_column].unique():\n",
    "        # Extract the case\n",
    "        case_data = df[df[case_id_column] == case_id]\n",
    "        \n",
    "        # Convert case_data to a NumPy array and drop the case_id_column\n",
    "        case_data_array = case_data.drop(columns=[case_id_column]).to_numpy()\n",
    "\n",
    "        # Adjusting the condition to correctly reflect window_size without needing an additional +1\n",
    "        # Now it correctly considers window_size as including the target event\n",
    "        if len(case_data_array) >= window_size:\n",
    "            # Adjust the loop to generate sliding windows of size window_size - 1 for the inputs and use the next event as the target\n",
    "            for i in range(len(case_data_array) - window_size + 1):\n",
    "                # window now has window_size - 1 events\n",
    "                window = case_data_array[i:i + window_size - 1]\n",
    "                # The target is the event immediately following the window\n",
    "                target = case_data_array[i + window_size - 1]\n",
    "                windows.append(window)\n",
    "                targets.append(target)\n",
    "                case_indices.append(case_id)  # Store the case_id corresponding to the window\n",
    "\n",
    "    # Convert lists to numpy arrays for easier handling and to ensure they are two-dimensional\n",
    "    windows_array = np.array(windows)\n",
    "    targets_array = np.array(targets)\n",
    "    case_indices_array = np.array(case_indices)\n",
    "    \n",
    "    return windows_array, targets_array, case_indices_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_activity, targets_activity, case_indices = generate_sliding_windows(df_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separate Inputs for Each Attribute\n",
    "- Each attribute is passed through an embedding layer\n",
    "- Each attribute has its corresponding GRU encoder\n",
    "- Selective Concatenation: After encoding, the outputs of these GRU layers are concatenated. However, this concatenation is selective, meaning it is structured in a way that prepares the data for effective synthesis without leaking information from the future (next event attributes)\n",
    "- Decoder GRUs: Integrated Decoding: Post-concatenation, the combined attributes are processed through decoder GRU layers. These layers are tasked with integrating the data from different attributes and preparing it for final prediction. This step is where BINet v3 distinguishes itself by effectively using the interdependencies between different attributes to enhance prediction accuracy.\n",
    "- Output Layer: Softmax Output for Each Attribute: For each attribute of the next event, a softmax layer predicts a probability distribution over all possible values. This allows the model to output the most likely next event and its attributes based on the learned dependencies and the history encoded by the GRUs.\n",
    "- E: maximum case length\n",
    "- We train BINet with a GRU size of 2E (two times the maximum case length)\n",
    "- on mini batches of size 500 for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the @@case_index column and count the rows in each group\n",
    "case_lengths = dataframe_log.groupby('@@case_index').size()\n",
    "\n",
    "# Find the maximum value among the case lengths\n",
    "E = case_lengths.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 20:21:57.715408: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " activity_input (InputLayer  [(None, None)]            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activity_embedding (Embedd  (None, None, 50)          900       \n",
      " ing)                                                            \n",
      "                                                                 \n",
      " activity_encoder (GRU)      (None, 48)                14400     \n",
      "                                                                 \n",
      " bn_activity (BatchNormaliz  (None, 48)                192       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48)                0         \n",
      "                                                                 \n",
      " output_activity (Dense)     (None, 18)                882       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16374 (63.96 KB)\n",
      "Trainable params: 16278 (63.59 KB)\n",
      "Non-trainable params: 96 (384.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Embedding, Dense, Dropout, BatchNormalization\n",
    "\n",
    "def create_binetv3_for_activity(num_activities, embedding_dim, gru_units, dropout_rate):\n",
    "    # Input layers for activity attribute\n",
    "    input_activity = Input(shape=(None,), name='activity_input')\n",
    "\n",
    "    # Embedding layer for activity attribute\n",
    "    embedding_activity = Embedding(input_dim=num_activities + 1, output_dim=embedding_dim, mask_zero=True, name='activity_embedding')(input_activity)\n",
    "\n",
    "    # Encoder GRU with Batch Normalization for activity\n",
    "    encoded_activity = GRU(units=gru_units, return_sequences=False, name='activity_encoder')(embedding_activity)\n",
    "    bn_activity = BatchNormalization(name='bn_activity')(encoded_activity)\n",
    "\n",
    "    # Dropout layer\n",
    "    dropout_layer = Dropout(rate=dropout_rate, name='dropout')(bn_activity)\n",
    "\n",
    "    # Output layer for predicting the next activity\n",
    "    output_activity = Dense(num_activities + 1, activation='softmax', name='output_activity')(dropout_layer)\n",
    "\n",
    "    # Building the model\n",
    "    model = Model(inputs=input_activity, outputs=output_activity)\n",
    "    model.compile(\n",
    "        optimizer='adam', \n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Parameters\n",
    "gru_units = int(2 * E) \n",
    "num_activities = dataframe_log['concept:name'].max()\n",
    "embedding_dim = 50\n",
    "dropout_rate = 0.2\n",
    "model = create_binetv3_for_activity(num_activities, embedding_dim, gru_units, dropout_rate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_activity, test_activity, train_targets_activity, test_targets_activity = train_test_split(\n",
    "    windows_activity, targets_activity, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_targets_activity_cat = to_categorical(train_targets_activity, num_classes=num_activities + 1)\n",
    "test_targets_activity_cat = to_categorical(test_targets_activity, num_classes=num_activities + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "22/22 [==============================] - 19s 310ms/step - loss: 1.7609 - accuracy: 0.7918 - val_loss: 2.6434 - val_accuracy: 0.8769\n",
      "Epoch 2/20\n",
      "22/22 [==============================] - 1s 43ms/step - loss: 0.5122 - accuracy: 0.9194 - val_loss: 2.3824 - val_accuracy: 0.9012\n",
      "Epoch 3/20\n",
      "22/22 [==============================] - 1s 44ms/step - loss: 0.2771 - accuracy: 0.9390 - val_loss: 2.2546 - val_accuracy: 0.9016\n",
      "Epoch 4/20\n",
      "22/22 [==============================] - 1s 44ms/step - loss: 0.2000 - accuracy: 0.9486 - val_loss: 2.1890 - val_accuracy: 0.9018\n",
      "Epoch 5/20\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.1651 - accuracy: 0.9544 - val_loss: 2.1287 - val_accuracy: 0.9032\n",
      "Epoch 6/20\n",
      "22/22 [==============================] - 1s 44ms/step - loss: 0.1441 - accuracy: 0.9571 - val_loss: 2.0287 - val_accuracy: 0.9032\n",
      "Epoch 7/20\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.1362 - accuracy: 0.9575 - val_loss: 1.9227 - val_accuracy: 0.9319\n",
      "Epoch 8/20\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.1266 - accuracy: 0.9586 - val_loss: 1.7373 - val_accuracy: 0.9319\n",
      "Epoch 9/20\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.1230 - accuracy: 0.9591 - val_loss: 1.5858 - val_accuracy: 0.9328\n",
      "Epoch 10/20\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.1173 - accuracy: 0.9606 - val_loss: 1.4574 - val_accuracy: 0.9359\n",
      "Epoch 11/20\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 0.1114 - accuracy: 0.9613 - val_loss: 1.2741 - val_accuracy: 0.9357\n",
      "Epoch 12/20\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.1093 - accuracy: 0.9606 - val_loss: 1.1296 - val_accuracy: 0.9357\n",
      "Epoch 13/20\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.1076 - accuracy: 0.9607 - val_loss: 0.9646 - val_accuracy: 0.9416\n",
      "Epoch 14/20\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.1035 - accuracy: 0.9612 - val_loss: 0.8959 - val_accuracy: 0.9414\n",
      "Epoch 15/20\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.1016 - accuracy: 0.9636 - val_loss: 0.7503 - val_accuracy: 0.9352\n",
      "Epoch 16/20\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 0.1013 - accuracy: 0.9631 - val_loss: 0.6480 - val_accuracy: 0.9425\n",
      "Epoch 17/20\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 0.1000 - accuracy: 0.9634 - val_loss: 0.5264 - val_accuracy: 0.9436\n",
      "Epoch 18/20\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.1002 - accuracy: 0.9629 - val_loss: 0.3467 - val_accuracy: 0.9436\n",
      "Epoch 19/20\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 0.0965 - accuracy: 0.9657 - val_loss: 0.3000 - val_accuracy: 0.9436\n",
      "Epoch 20/20\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 0.0950 - accuracy: 0.9653 - val_loss: 0.2337 - val_accuracy: 0.9434\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_activity,  # Only the activity input\n",
    "    train_targets_activity_cat,  # Only the activity targets\n",
    "    validation_data=(test_activity, test_targets_activity_cat),  # Only the activity input and targets for validation\n",
    "    epochs=20,\n",
    "    batch_size=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 1s 9ms/step - loss: 0.2337 - accuracy: 0.9434\n",
      "Validation Loss: 0.23366592824459076, Validation Accuracy: 0.9434003829956055\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "results = model.evaluate(\n",
    "    test_activity,  # Only the activity input\n",
    "    test_targets_activity_cat,  # Only the activity targets\n",
    "    batch_size=64\n",
    ")\n",
    "print(f\"Validation Loss: {results[0]}, Validation Accuracy: {results[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Score Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each event attribute, BINet's softmax layer outputs a probability distribution over possible values\n",
    "- The anomaly score for a specific attribute value v is calculated by summing all the probabilities from the softmax output that are greater than the probability assigned to v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472/472 [==============================] - 8s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_activity = model.predict([windows_activity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_anomaly_scores(predictions, targets):\n",
    "    scores = []\n",
    "    # Loop through each example in the predictions\n",
    "    for i in range(predictions.shape[0]):\n",
    "        actual_prob = predictions[i, targets[i]]  # Extract the probability of the true class using target index\n",
    "        # Calculate anomaly score as sum of probabilities greater than the probability of the actual value\n",
    "        anomaly_score = np.sum(predictions[i][predictions[i] > actual_prob])\n",
    "        scores.append(anomaly_score)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate anomaly scores for each attribute type\n",
    "anomaly_scores_activity = calculate_anomaly_scores(predictions_activity, targets_activity.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert missing scores for cases with less than 2 Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>score_activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15070</th>\n",
       "      <td>10496</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15071</th>\n",
       "      <td>10496</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15072</th>\n",
       "      <td>10497</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15073</th>\n",
       "      <td>10498</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15074</th>\n",
       "      <td>10499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15075 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        case  score_activity\n",
       "0          1             0.0\n",
       "1          2             0.0\n",
       "2          6             0.0\n",
       "3          6             0.0\n",
       "4          6             0.0\n",
       "...      ...             ...\n",
       "15070  10496             0.0\n",
       "15071  10496             0.0\n",
       "15072  10497             0.0\n",
       "15073  10498             0.0\n",
       "15074  10499             0.0\n",
       "\n",
       "[15075 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the case_indices_array corresponding to case_resource\n",
    "score = pd.DataFrame({'case': case_indices})\n",
    "score['score_activity'] = anomaly_scores_activity\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: [3, 4, 5, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 66, 67, 70, 71, 72, 73, 74, 75, 77, 79, 80, 81, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 112, 113, 114, 115, 116, 118, 120, 121, 122, 125, 126, 127, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 142, 143, 144, 145, 146, 149, 150, 152, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 185, 186, 187, 188, 189, 190, 191, 192, 194, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 218, 221, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 243, 245, 246, 248, 249, 250, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 279, 280, 281, 282, 283, 284, 286, 288, 289, 290, 291, 292, 293, 294, 297, 298, 302, 304, 305, 306, 307, 308, 309, 310, 311, 313, 316, 318, 325, 326, 328, 332, 333, 334, 335, 342, 346, 348, 350, 355, 356, 360, 362, 363, 368, 369, 370, 372, 376, 378, 380, 382, 383, 385, 386, 388, 395, 396, 400, 401, 402, 403, 404, 405, 406, 407, 412, 413, 414, 415, 416, 417, 419, 420, 423, 424, 426, 427, 428, 429, 430, 431, 433, 437, 438, 440, 441, 442, 443, 447, 448, 449, 451, 452, 453, 456, 457, 459, 461, 462, 463, 464, 465, 466, 467, 469, 470, 471, 473, 474, 475, 476, 477, 478, 480, 481, 482, 484, 485, 486, 487, 488, 492, 493, 495, 496, 499, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 531, 532, 533, 534, 535, 538, 540, 542, 543, 544, 546, 549, 550, 551, 552, 554, 555, 557, 560, 561, 564, 567, 568, 569, 570, 571, 572, 573, 575, 577, 578, 581, 582, 583, 584, 585, 586, 587, 591, 592, 594, 595, 596, 597, 599, 600, 601, 602, 603, 604, 606, 607, 608, 609, 611, 612, 613, 614, 615, 616, 617, 618, 622, 625, 626, 628, 629, 630, 632, 637, 644, 646, 647, 649, 650, 651, 652, 653, 654, 655, 657, 658, 661, 662, 663, 664, 665, 667, 670, 671, 672, 676, 677, 679, 680, 681, 688, 690, 691, 694, 695, 696, 697, 699, 700, 702, 703, 706, 709, 713, 715, 719, 720, 722, 724, 727, 729, 730, 732, 735, 736, 737, 738, 739, 742, 743, 744, 745, 747, 749, 750, 751, 753, 754, 755, 759, 760, 761, 762, 763, 764, 766, 767, 768, 771, 775, 777, 778, 780, 781, 783, 784, 785, 787, 788, 789, 790, 792, 793, 794, 795, 796, 797, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 829, 830, 832, 833, 834, 836, 837, 839, 840, 841, 842, 843, 846, 847, 848, 849, 850, 851, 853, 854, 856, 857, 858, 859, 860, 861, 862, 863, 869, 870, 872, 873, 875, 878, 882, 886, 887, 894, 896, 897, 898, 900, 902, 908, 910, 911, 914, 915, 916, 917, 918, 919, 921, 922, 923, 926, 928, 930, 933, 935, 936, 938, 946, 949, 950, 951, 952, 956, 957, 960, 961, 963, 964, 967, 968, 969, 970, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 1000, 1001, 1002, 1010, 1011, 1012, 1014, 1015, 1017, 1018, 1019, 1022, 1025, 1026, 1027, 1028, 1030, 1034, 1035, 1039, 1040, 1042, 1043, 1044, 1047, 1050, 1051, 1052, 1053, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1065, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1085, 1086, 1089, 1090, 1091, 1092, 1094, 1095, 1096, 1097, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1109, 1110, 1111, 1112, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1124, 1125, 1126, 1127, 1130, 1133, 1134, 1135, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1148, 1149, 1153, 1154, 1156, 1157, 1159, 1160, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1172, 1173, 1174, 1175, 1176, 1180, 1181, 1182, 1184, 1185, 1189, 1190, 1191, 1192, 1196, 1200, 1201, 1208, 1209, 1210, 1213, 1214, 1215, 1216, 1219, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1238, 1239, 1240, 1241, 1244, 1245, 1247, 1248, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1261, 1262, 1263, 1264, 1266, 1267, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1283, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1305, 1306, 1307, 1310, 1315, 1316, 1317, 1319, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1340, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1351, 1353, 1354, 1355, 1356, 1357, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1369, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1380, 1382, 1383, 1384, 1385, 1386, 1387, 1389, 1390, 1391, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1413, 1414, 1415, 1416, 1417, 1418, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1429, 1430, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1443, 1444, 1445, 1446, 1449, 1450, 1451, 1452, 1453, 1454, 1456, 1457, 1458, 1460, 1461, 1463, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1476, 1477, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1492, 1493, 1494, 1495, 1496, 1497, 1499, 1501, 1504, 1505, 1507, 1508, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1524, 1528, 1529, 1530, 1531, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1548, 1549, 1550, 1552, 1554, 1556, 1563, 1564, 1565, 1566, 1567, 1569, 1570, 1572, 1573, 1575, 1576, 1577, 1579, 1583, 1584, 1586, 1587, 1588, 1590, 1592, 1593, 1597, 1602, 1605, 1609, 1610, 1611, 1613, 1614, 1615, 1621, 1623, 1626, 1631, 1633, 1634, 1637, 1638, 1639, 1643, 1644, 1646, 1648, 1649, 1650, 1652, 1653, 1654, 1655, 1656, 1658, 1659, 1669, 1670, 1672, 1676, 1679, 1680, 1681, 1684, 1685, 1686, 1687, 1689, 1690, 1691, 1693, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1703, 1704, 1705, 1706, 1707, 1712, 1713, 1715, 1718, 1720, 1721, 1722, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1732, 1736, 1737, 1738, 1739, 1741, 1742, 1743, 1744, 1745, 1746, 1750, 1751, 1756, 1762, 1764, 1765, 1767, 1768, 1769, 1770, 1772, 1773, 1775, 1776, 1777, 1778, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1803, 1804, 1807, 1808, 1809, 1810, 1811, 1815, 1817, 1818, 1819, 1820, 1823, 1824, 1825, 1828, 1829, 1830, 1831, 1832, 1833, 1836, 1837, 1839, 1840, 1841, 1843, 1844, 1845, 1848, 1849, 1850, 1851, 1852, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1870, 1871, 1872, 1873, 1874, 1875, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1886, 1888, 1889, 1890, 1892, 1894, 1895, 1896, 1897, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1928, 1929, 1930, 1931, 1932, 1934, 1935, 1936, 1939, 1941, 1942, 1944, 1945, 1950, 1951, 1952, 1953, 1955, 1960, 1961, 1962, 1963, 1964, 1966, 1968, 1969, 1970, 1971, 1973, 1975, 1976, 1977, 1978, 1980, 1981, 1982, 1985, 1986, 1988, 1990, 1991, 1992, 1993, 1994, 1995, 1998, 1999, 2000, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2015, 2017, 2018, 2019, 2020, 2021, 2022, 2029, 2031, 2032, 2033, 2034, 2037, 2038, 2039, 2043, 2046, 2047, 2048, 2049, 2052, 2053, 2054, 2055, 2056, 2062, 2063, 2064, 2065, 2066, 2067, 2069, 2071, 2072, 2074, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2087, 2088, 2090, 2092, 2093, 2095, 2096, 2101, 2102, 2103, 2105, 2106, 2107, 2108, 2110, 2111, 2112, 2113, 2114, 2116, 2117, 2124, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2141, 2142, 2143, 2145, 2146, 2147, 2148, 2151, 2152, 2153, 2154, 2155, 2156, 2160, 2161, 2162, 2169, 2170, 2172, 2173, 2174, 2176, 2177, 2179, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2201, 2202, 2203, 2207, 2208, 2209, 2211, 2216, 2218, 2219, 2226, 2228, 2229, 2230, 2231, 2232, 2234, 2236, 2238, 2239, 2241, 2287, 2288, 2301, 2306, 2323, 2335, 2372, 2382, 2402, 2405, 2406, 2409, 2428, 2442, 2449, 2453, 2462, 2464, 2546, 2564, 2611, 2617, 2635, 2677, 2728, 2747, 2763, 2816, 2829, 2831, 2872, 2886, 2887, 2916, 2975, 2990, 2991, 2992, 2993, 2994, 2996, 3021, 3102, 3187, 3206, 3259, 3260, 3309, 3348, 3356, 3436, 3446, 3504, 3576, 3585, 3598, 3665, 3668, 3718, 3719, 3725, 3751, 3814, 3815, 3839, 3919, 3924, 3925, 3970, 3994, 3995, 4073, 4136, 4182, 4226, 4353, 4355, 4376, 4391, 4392, 4405, 4420, 4456, 4473, 4548, 4564, 4731, 4732, 4762, 4766, 4767, 4782, 4805, 4876, 4886, 4887, 4909, 4916, 4919, 4945, 4983, 5030, 5086, 5147, 5176, 5242, 5335, 5340, 5369, 5469, 5475, 5536, 5540, 5595, 5607, 5643, 5652, 5684, 5687, 5689, 5703, 5735, 5815, 5842, 5847, 5849, 5900, 5911, 5926, 5938, 5945, 5982, 5988, 6011, 6134, 6170, 6178, 6181, 6220, 6225, 6232, 6238, 6292, 6330, 6397, 6411, 6419, 6448, 6450, 6482, 6484, 6490, 6499, 6514, 6529, 6538, 6568, 6571, 6598, 6626, 6652, 6653, 6654, 6724, 6814, 6829, 6831, 6866, 6961, 7029, 7089, 7091, 7135, 7156, 7214, 7233, 7240, 7270, 7294, 7322, 7338, 7345, 7346, 7350, 7428, 7431, 7448, 7452, 7463, 7468, 7469, 7498, 7504, 7519, 7574, 7577, 7579, 7597, 7600, 7613, 7714, 7796, 7802, 7890, 7913, 7917, 7982, 7992, 8014, 8022, 8066, 8067, 8068, 8069, 8096, 8102, 8103, 8112, 8149, 8150, 8161, 8166, 8171, 8229, 8232, 8233, 8243, 8278, 8281, 8297, 8299, 8300, 8318, 8346, 8447, 8451, 8479, 8489, 8531, 8549, 8640, 8661, 8669, 8670, 8693, 8767, 8797, 8803, 8825, 8856, 8857, 8858, 8944, 8960, 9071, 9072, 9086, 9092, 9110, 9190, 9202, 9205, 9240, 9254, 9313, 9315, 9345, 9346, 9349, 9358, 9372, 9382, 9383, 9423, 9438, 9439, 9444, 9459, 9483, 9488, 9536, 9561, 9596, 9597, 9617, 9619, 9642, 9722, 9750, 9768, 9778, 9815, 9901, 9902, 9903, 9920, 9932, 9933, 9957, 9987, 10001, 10018, 10093, 10095, 10107, 10170, 10178, 10180, 10251, 10252, 10293, 10300, 10302, 10333, 10337, 10353, 10368, 10395, 10396, 10420, 10429, 10437, 10439, 10444]\n",
      "Does the 'case' column contain all values between 0 and 10499? False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def contains_all_values(df, column, end):\n",
    "\n",
    "    # Generate the set of all values in the specified range\n",
    "    required_values = set(range(1, end))\n",
    "    \n",
    "    # Get the unique values in the specified column\n",
    "    column_values = set(df[column].unique())\n",
    "    \n",
    "    # Find missing values\n",
    "    missing_values = required_values - column_values\n",
    "    \n",
    "    # Print missing values if any\n",
    "    if missing_values:\n",
    "        print(f\"Missing values: {sorted(missing_values)}\")\n",
    "    \n",
    "    # Check if all required values are in the column values\n",
    "    return required_values.issubset(column_values)\n",
    "\n",
    "end = 10499\n",
    "\n",
    "result = contains_all_values(score, 'case', end)\n",
    "print(f\"Does the 'case' column contain all values between 0 and {end}? {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>score_activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16879</th>\n",
       "      <td>10496</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16880</th>\n",
       "      <td>10496</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16881</th>\n",
       "      <td>10497</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16882</th>\n",
       "      <td>10498</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16883</th>\n",
       "      <td>10499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16884 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        case  score_activity\n",
       "0          0             1.0\n",
       "1          1             0.0\n",
       "2          2             0.0\n",
       "3          3             1.0\n",
       "4          4             1.0\n",
       "...      ...             ...\n",
       "16879  10496             0.0\n",
       "16880  10496             0.0\n",
       "16881  10497             0.0\n",
       "16882  10498             0.0\n",
       "16883  10499             0.0\n",
       "\n",
       "[16884 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the full range of values\n",
    "full_range = set(range(10500))\n",
    "\n",
    "# Get the existing 'case' values\n",
    "existing_cases = set(score['case'])\n",
    "\n",
    "# Identify missing values\n",
    "missing_cases = full_range - existing_cases\n",
    "\n",
    "# Create a DataFrame for missing values\n",
    "missing_df = pd.DataFrame({'case': list(missing_cases)})\n",
    "\n",
    "# Add other columns with value 1\n",
    "for col in score.columns:\n",
    "    if col != 'case':\n",
    "        missing_df[col] = 1\n",
    "\n",
    "# Concatenate the original DataFrame with the missing values DataFrame\n",
    "updated_score = pd.concat([score, missing_df])\n",
    "\n",
    "# Sort the DataFrame by 'case'\n",
    "updated_score = updated_score.sort_values(by='case').reset_index(drop=True)\n",
    "\n",
    "updated_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_scores_activity = updated_score['score_activity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold (lowest plateau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_anomaly_ratio(scores, threshold):\n",
    "    \"\"\"\n",
    "    Calculate the anomaly ratio for a given threshold.\n",
    "    \"\"\"\n",
    "    return np.mean(scores > threshold)\n",
    "\n",
    "def find_plateaus(scores, epsilon=1e-4, min_plateau_length=10):\n",
    "    \"\"\"\n",
    "    Identify the lowest plateau in the anomaly ratio function and calculate the mean-centered threshold.\n",
    "    \"\"\"\n",
    "    scores = np.array(scores)  # Convert scores to a NumPy array\n",
    "    sorted_scores = np.sort(scores)\n",
    "    \n",
    "    # Remove duplicate values\n",
    "    unique_thresholds, unique_indices = np.unique(sorted_scores, return_index=True)\n",
    "    anomaly_ratios = np.array([calculate_anomaly_ratio(scores, t) for t in unique_thresholds])\n",
    "    \n",
    "    # Calculate first and second derivatives\n",
    "    first_derivatives = np.diff(anomaly_ratios) / np.diff(unique_thresholds)\n",
    "    second_derivatives = np.diff(first_derivatives) / np.diff(unique_thresholds[:-1])\n",
    "    \n",
    "    # Identify plateaus where the first derivative is close to zero\n",
    "    plateau_indices = np.where(np.abs(first_derivatives) < epsilon)[0]\n",
    "    \n",
    "    # Group consecutive indices to identify continuous plateaus\n",
    "    grouped_plateaus = np.split(plateau_indices, np.where(np.diff(plateau_indices) != 1)[0] + 1)\n",
    "    \n",
    "    # Filter plateaus based on minimum length\n",
    "    long_plateaus = [g for g in grouped_plateaus if len(g) >= min_plateau_length]\n",
    "    \n",
    "    if long_plateaus:\n",
    "        # Take the first long plateau and find the mean threshold in this plateau\n",
    "        first_plateau = long_plateaus[0]\n",
    "        plateau_thresholds = unique_thresholds[first_plateau]\n",
    "        return np.mean(plateau_thresholds)\n",
    "    else:\n",
    "        # If no plateau is found, return a default value, e.g., the 90th percentile\n",
    "        percentile_90 = np.percentile(sorted_scores, 90)\n",
    "        if percentile_90 == 1.0:\n",
    "            return 0.4\n",
    "        else:\n",
    "            return percentile_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_activity = find_plateaus(anomaly_scores_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(anomaly_scores, threshold):\n",
    "    labels = [1 if score > threshold else 0 for score in anomaly_scores]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect anomalies based on the calculated anomaly scores and thresholds\n",
    "labels_activity = detect_anomalies(anomaly_scores_activity, threshold_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_indices = updated_score['case']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>predicted_activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16879</th>\n",
       "      <td>10496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16880</th>\n",
       "      <td>10496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16881</th>\n",
       "      <td>10497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16882</th>\n",
       "      <td>10498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16883</th>\n",
       "      <td>10499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16884 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        case  predicted_activity\n",
       "0          0                   1\n",
       "1          1                   0\n",
       "2          2                   0\n",
       "3          3                   1\n",
       "4          4                   1\n",
       "...      ...                 ...\n",
       "16879  10496                   0\n",
       "16880  10496                   0\n",
       "16881  10497                   0\n",
       "16882  10498                   0\n",
       "16883  10499                   0\n",
       "\n",
       "[16884 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the case_indices_array corresponding to case_resource\n",
    "mapping = pd.DataFrame({'case': case_indices})\n",
    "mapping['predicted_activity'] = labels_activity\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case\n",
       "0         True\n",
       "1        False\n",
       "2        False\n",
       "3         True\n",
       "4         True\n",
       "         ...  \n",
       "10495    False\n",
       "10496    False\n",
       "10497    False\n",
       "10498    False\n",
       "10499    False\n",
       "Length: 10500, dtype: bool"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a boolean DataFrame where each value is True if the value is 1\n",
    "contains_one = (mapping[['predicted_activity']] == 1)\n",
    "\n",
    "# Group by 'case' and check if there's at least one 'True' in any of the columns\n",
    "case_prediction = contains_one.groupby(mapping['case']).any().any(axis=1)\n",
    "case_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking):\n",
    "    from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments\n",
    "    from pm4py.algo.conformance.alignments.petri_net import variants\n",
    "    from pm4py.objects.petri_net.utils import align_utils\n",
    "    max_events=0\n",
    "    for trace in log:\n",
    "        counter=0\n",
    "        for event in trace:\n",
    "            counter+=1\n",
    "        if counter > max_events:\n",
    "            max_events=counter\n",
    "    parameters={}\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_SYNC_COST_FUNCTION] = list(map(lambda i: .1*i, range(max_events*2)))\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_TRACE_COST_FUNCTION]=list(map(lambda i: align_utils.STD_MODEL_LOG_MOVE_COST-.1*i, range(max_events*2)))\n",
    "    aligned_traces = alignments.apply_log(log, net, initial_marking, final_marking, variant=variants.state_equation_a_star, parameters=parameters)\n",
    "    return aligned_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0129f05af7ab409e9817583e1237dc0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/model/Model_ DomesticDeclarations.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_traces = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conformance_status_by_fitness(aligned_traces):\n",
    "    conformance_status = []\n",
    "    for alignment in aligned_traces:\n",
    "        fitness = alignment['fitness']\n",
    "        # If the fitness is 1.0, the trace is conforming\n",
    "        if fitness == 1.0:\n",
    "            conformance_status.append(0)\n",
    "        else:\n",
    "            conformance_status.append(1)\n",
    "    return conformance_status\n",
    "\n",
    "# Get the conformance status list from the aligned traces\n",
    "conformance = extract_conformance_status_by_fitness(aligned_traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conformity</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       conformity  predicted\n",
       "0               1          1\n",
       "1               1          0\n",
       "2               1          0\n",
       "3               1          1\n",
       "4               1          1\n",
       "...           ...        ...\n",
       "10495           0          0\n",
       "10496           0          0\n",
       "10497           0          0\n",
       "10498           0          0\n",
       "10499           0          0\n",
       "\n",
       "[10500 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = pd.DataFrame({'conformity': conformance})\n",
    "ground_truth['predicted'] = case_prediction\n",
    "\n",
    "# Convert False to 0 and True to 1\n",
    "ground_truth['predicted'] = [int(value) for value in ground_truth['predicted']]\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating TP, TN, FP, FN\n",
    "TP = ((ground_truth['conformity'] == 1) & (ground_truth['predicted'] == 1)).sum()\n",
    "TN = ((ground_truth['conformity'] == 0) & (ground_truth['predicted'] == 0)).sum()\n",
    "FP = ((ground_truth['conformity'] == 0) & (ground_truth['predicted'] == 1)).sum()\n",
    "FN = ((ground_truth['conformity'] == 1) & (ground_truth['predicted'] == 0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Dev: 0.91\n"
     ]
    }
   ],
   "source": [
    "precision_dev = TP / (TP + FP)\n",
    "print(f\"Precision Dev: {precision_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Dev: 0.69\n"
     ]
    }
   ],
   "source": [
    "recall_dev = TP / (TP + FN)\n",
    "print(f\"Recall Dev: {recall_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision No Dev: 0.88\n"
     ]
    }
   ],
   "source": [
    "precision_no_dev = TN / (TN + FN)\n",
    "print(f\"Precision No Dev: {precision_no_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall No Dev: 0.97\n"
     ]
    }
   ],
   "source": [
    "recall_no_dev = TN / (TN + FP)\n",
    "print(f\"Recall No Dev: {recall_no_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_roc = roc_auc_score(ground_truth['conformity'], ground_truth['predicted'])\n",
    "print(f\"AUC-ROC: {auc_roc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
