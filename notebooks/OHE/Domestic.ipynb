{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f1af5c",
   "metadata": {},
   "source": [
    "# Import Event Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cab9ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 10500/10500 [00:59<00:00, 176.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>org:role</th>\n",
       "      <th>case:id</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>case:BudgetNumber</th>\n",
       "      <th>case:DeclarationNumber</th>\n",
       "      <th>case:Amount</th>\n",
       "      <th>@@case_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>st_step 86794_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2017-01-09 09:49:50+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 86792</td>\n",
       "      <td>26.851205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>st_step 86793_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration FINAL_APPROVED by SUPERVISOR</td>\n",
       "      <td>2017-01-09 11:27:48+00:00</td>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 86792</td>\n",
       "      <td>26.851205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dd_declaration 86791_19</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Request Payment</td>\n",
       "      <td>2017-01-10 09:34:44+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 86792</td>\n",
       "      <td>26.851205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd_declaration 86791_20</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Payment Handled</td>\n",
       "      <td>2017-01-12 17:31:22+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>declaration 86791</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 86792</td>\n",
       "      <td>26.851205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>st_step 86798_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2017-01-09 10:26:14+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>declaration 86795</td>\n",
       "      <td>declaration 86795</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 86796</td>\n",
       "      <td>182.464172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56432</th>\n",
       "      <td>st_step 138363_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2018-12-29 17:50:14+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 138360</td>\n",
       "      <td>190.404576</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56433</th>\n",
       "      <td>st_step 138361_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration APPROVED by ADMINISTRATION</td>\n",
       "      <td>2018-12-29 17:56:13+00:00</td>\n",
       "      <td>ADMINISTRATION</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 138360</td>\n",
       "      <td>190.404576</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56434</th>\n",
       "      <td>st_step 138362_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration FINAL_APPROVED by SUPERVISOR</td>\n",
       "      <td>2019-01-03 08:55:52+00:00</td>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 138360</td>\n",
       "      <td>190.404576</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56435</th>\n",
       "      <td>dd_declaration 138359_19</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Request Payment</td>\n",
       "      <td>2019-01-08 08:20:28+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 138360</td>\n",
       "      <td>190.404576</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56436</th>\n",
       "      <td>dd_declaration 138359_20</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>Payment Handled</td>\n",
       "      <td>2019-01-10 17:31:08+00:00</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>declaration 138359</td>\n",
       "      <td>budget 86566</td>\n",
       "      <td>declaration number 138360</td>\n",
       "      <td>190.404576</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56437 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id  org:resource  \\\n",
       "0               st_step 86794_0  STAFF MEMBER   \n",
       "1               st_step 86793_0  STAFF MEMBER   \n",
       "2       dd_declaration 86791_19        SYSTEM   \n",
       "3       dd_declaration 86791_20        SYSTEM   \n",
       "4               st_step 86798_0  STAFF MEMBER   \n",
       "...                         ...           ...   \n",
       "56432          st_step 138363_0  STAFF MEMBER   \n",
       "56433          st_step 138361_0  STAFF MEMBER   \n",
       "56434          st_step 138362_0  STAFF MEMBER   \n",
       "56435  dd_declaration 138359_19        SYSTEM   \n",
       "56436  dd_declaration 138359_20        SYSTEM   \n",
       "\n",
       "                                   concept:name            time:timestamp  \\\n",
       "0             Declaration SUBMITTED by EMPLOYEE 2017-01-09 09:49:50+00:00   \n",
       "1      Declaration FINAL_APPROVED by SUPERVISOR 2017-01-09 11:27:48+00:00   \n",
       "2                               Request Payment 2017-01-10 09:34:44+00:00   \n",
       "3                               Payment Handled 2017-01-12 17:31:22+00:00   \n",
       "4             Declaration SUBMITTED by EMPLOYEE 2017-01-09 10:26:14+00:00   \n",
       "...                                         ...                       ...   \n",
       "56432         Declaration SUBMITTED by EMPLOYEE 2018-12-29 17:50:14+00:00   \n",
       "56433    Declaration APPROVED by ADMINISTRATION 2018-12-29 17:56:13+00:00   \n",
       "56434  Declaration FINAL_APPROVED by SUPERVISOR 2019-01-03 08:55:52+00:00   \n",
       "56435                           Request Payment 2019-01-08 08:20:28+00:00   \n",
       "56436                           Payment Handled 2019-01-10 17:31:08+00:00   \n",
       "\n",
       "             org:role             case:id   case:concept:name  \\\n",
       "0            EMPLOYEE   declaration 86791   declaration 86791   \n",
       "1          SUPERVISOR   declaration 86791   declaration 86791   \n",
       "2           UNDEFINED   declaration 86791   declaration 86791   \n",
       "3           UNDEFINED   declaration 86791   declaration 86791   \n",
       "4            EMPLOYEE   declaration 86795   declaration 86795   \n",
       "...               ...                 ...                 ...   \n",
       "56432        EMPLOYEE  declaration 138359  declaration 138359   \n",
       "56433  ADMINISTRATION  declaration 138359  declaration 138359   \n",
       "56434      SUPERVISOR  declaration 138359  declaration 138359   \n",
       "56435       UNDEFINED  declaration 138359  declaration 138359   \n",
       "56436       UNDEFINED  declaration 138359  declaration 138359   \n",
       "\n",
       "      case:BudgetNumber     case:DeclarationNumber  case:Amount  @@case_index  \n",
       "0          budget 86566   declaration number 86792    26.851205             0  \n",
       "1          budget 86566   declaration number 86792    26.851205             0  \n",
       "2          budget 86566   declaration number 86792    26.851205             0  \n",
       "3          budget 86566   declaration number 86792    26.851205             0  \n",
       "4          budget 86566   declaration number 86796   182.464172             1  \n",
       "...                 ...                        ...          ...           ...  \n",
       "56432      budget 86566  declaration number 138360   190.404576         10499  \n",
       "56433      budget 86566  declaration number 138360   190.404576         10499  \n",
       "56434      budget 86566  declaration number 138360   190.404576         10499  \n",
       "56435      budget 86566  declaration number 138360   190.404576         10499  \n",
       "56436      budget 86566  declaration number 138360   190.404576         10499  \n",
       "\n",
       "[56437 rows x 11 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the XES file\n",
    "    dataframe_log = pm4py.read_xes('../../data/logs/DomesticDeclarations.xes')\n",
    "\n",
    "    # If 'log' is already a DataFrame, add the @@case_index column directly\n",
    "    case_indices = {case_id: idx for idx, case_id in enumerate(dataframe_log['case:concept:name'].unique())}\n",
    "    dataframe_log['@@case_index'] = dataframe_log['case:concept:name'].map(case_indices)\n",
    "    \n",
    "     # Convert the dataframe to event log\n",
    "    log = log_converter.apply(dataframe_log)\n",
    "    \n",
    "dataframe_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f005cd",
   "metadata": {},
   "source": [
    "## Ground Truth Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "078e5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking):\n",
    "    from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments\n",
    "    from pm4py.algo.conformance.alignments.petri_net import variants\n",
    "    from pm4py.objects.petri_net.utils import align_utils\n",
    "    max_events=0\n",
    "    for trace in log:\n",
    "        counter=0\n",
    "        for event in trace:\n",
    "            counter+=1\n",
    "        if counter > max_events:\n",
    "            max_events=counter\n",
    "    parameters={}\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_SYNC_COST_FUNCTION] = list(map(lambda i: .1*i, range(max_events*2)))\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_TRACE_COST_FUNCTION]=list(map(lambda i: align_utils.STD_MODEL_LOG_MOVE_COST-.1*i, range(max_events*2)))\n",
    "    aligned_traces = alignments.apply_log(log, net, initial_marking, final_marking, variant=variants.state_equation_a_star, parameters=parameters)\n",
    "    return aligned_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52630eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aligning log, completed variants :: 100%|██████████| 99/99 [00:11<00:00,  8.69it/s]\n"
     ]
    }
   ],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/model/Model_ DomesticDeclarations.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_traces = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59abf41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conform: 0\n",
    "# deviating: 1\n",
    "\n",
    "def extract_conformance_status_by_fitness(aligned_traces):\n",
    "    conformance_status = []\n",
    "    for alignment in aligned_traces:\n",
    "        fitness = alignment['fitness']\n",
    "        # If the fitness is 1.0, the trace is conforming\n",
    "        if fitness == 1.0:\n",
    "            conformance_status.append(0)\n",
    "        else:\n",
    "            conformance_status.append(1)\n",
    "    return conformance_status\n",
    "\n",
    "# Get the conformance status list from the aligned traces\n",
    "conformance = extract_conformance_status_by_fitness(aligned_traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e37f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = pd.DataFrame(conformance, columns=['actual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabfabf8",
   "metadata": {},
   "source": [
    "## 1. Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bff3b68",
   "metadata": {},
   "source": [
    "### 1.1 Encoding Event Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "157dbb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Step 1: One-Hot Encoding of Activities\n",
    "mlb = MultiLabelBinarizer()\n",
    "traces = dataframe_log.groupby('@@case_index')['concept:name'].apply(list)\n",
    "one_hot_encoded = mlb.fit_transform(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f0daa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding = np.array(one_hot_encoded.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dc8a50",
   "metadata": {},
   "source": [
    "### 2.1 Encoding Input Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0029315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Group by case_index and concatenate the activities to form traces\n",
    "dataframe_log['trace'] = dataframe_log.groupby('@@case_index')['concept:name'].transform(lambda x: ', '.join(x))\n",
    "\n",
    "# Step 3: Count occurrences of each unique trace\n",
    "trace_counts = dataframe_log['trace'].value_counts()\n",
    "\n",
    "# Step 4: Convert to DataFrame and sort by occurrences\n",
    "trace_counts_df = trace_counts.reset_index()\n",
    "trace_counts_df.columns = ['Trace', 'Count']\n",
    "trace_counts_df = trace_counts_df.sort_values(by='Count', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b7016de",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for i in range(15):\n",
    "    trace = trace_counts_df.iloc[i]['Trace']\n",
    "    traces.append([event.strip() for event in trace.split(',')])\n",
    "\n",
    "# Now you have the traces stored in the list 'traces'\n",
    "trace1, trace2, trace3, trace4, trace5, trace6, trace7, trace8, trace9, trace10, trace11, trace12, trace13, trace14, trace15 = traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee60b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = dataframe_log.groupby('@@case_index')['concept:name'].apply(list).reset_index(name='trace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3fc4290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_happy_trace(row_trace):\n",
    "    predefined_traces = [trace1, trace2, trace8]\n",
    "    for trace in predefined_traces:\n",
    "        if row_trace == trace:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e286ba1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@@case_index</th>\n",
       "      <th>trace</th>\n",
       "      <th>happy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Declaration SUBMITTED by EMPLOYEE, Declaratio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Declaration SUBMITTED by EMPLOYEE, Declaratio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Declaration SUBMITTED by EMPLOYEE, Declaratio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[Declaration SUBMITTED by EMPLOYEE, Declaratio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[Declaration SUBMITTED by EMPLOYEE, Declaratio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10495</th>\n",
       "      <td>10495</td>\n",
       "      <td>[Declaration SUBMITTED by EMPLOYEE, Declaratio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>10496</td>\n",
       "      <td>[Declaration SUBMITTED by EMPLOYEE, Declaratio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10497</th>\n",
       "      <td>10497</td>\n",
       "      <td>[Declaration SUBMITTED by EMPLOYEE, Declaratio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>10498</td>\n",
       "      <td>[Declaration SUBMITTED by EMPLOYEE, Declaratio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10499</th>\n",
       "      <td>10499</td>\n",
       "      <td>[Declaration SUBMITTED by EMPLOYEE, Declaratio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       @@case_index                                              trace  happy\n",
       "0                 0  [Declaration SUBMITTED by EMPLOYEE, Declaratio...      0\n",
       "1                 1  [Declaration SUBMITTED by EMPLOYEE, Declaratio...      0\n",
       "2                 2  [Declaration SUBMITTED by EMPLOYEE, Declaratio...      0\n",
       "3                 3  [Declaration SUBMITTED by EMPLOYEE, Declaratio...      0\n",
       "4                 4  [Declaration SUBMITTED by EMPLOYEE, Declaratio...      0\n",
       "...             ...                                                ...    ...\n",
       "10495         10495  [Declaration SUBMITTED by EMPLOYEE, Declaratio...      1\n",
       "10496         10496  [Declaration SUBMITTED by EMPLOYEE, Declaratio...      1\n",
       "10497         10497  [Declaration SUBMITTED by EMPLOYEE, Declaratio...      1\n",
       "10498         10498  [Declaration SUBMITTED by EMPLOYEE, Declaratio...      1\n",
       "10499         10499  [Declaration SUBMITTED by EMPLOYEE, Declaratio...      1\n",
       "\n",
       "[10500 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped['happy'] = grouped['trace'].apply(is_happy_trace)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9521ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of the happy traces in the results dataframe\n",
    "happy_trace_indices = grouped[grouped['happy'] == 1].index.tolist()\n",
    "\n",
    "# Extract the corresponding coordinates from the trace_representations array\n",
    "happy_trace_coordinates = one_hot_encoding[happy_trace_indices]\n",
    "\n",
    "# Extract unique coordinates\n",
    "unique_happy_trace_coordinates = np.unique(happy_trace_coordinates, axis=0)\n",
    "\n",
    "# Assuming the size of unique_happy_trace_coordinates is 3\n",
    "#happy_trace1, happy_trace2, happy_trace3 = unique_happy_trace_coordinates\n",
    "happy_trace1, happy_trace2, happy_trace3 = unique_happy_trace_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601190ba",
   "metadata": {},
   "source": [
    "## 2. Binary Conformance Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3a8bc5",
   "metadata": {},
   "source": [
    "### 2.1 Distance Measurement (between Event Log Traces and Input Traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce6f9e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Calculate the distances to each of the happy traces for every trace representation\n",
    "distances_to_happy_traces = []\n",
    "\n",
    "for trace_representation in one_hot_encoding:\n",
    "    distances = [\n",
    "        euclidean(trace_representation, happy_trace1),\n",
    "        euclidean(trace_representation, happy_trace2),\n",
    "        euclidean(trace_representation, happy_trace3)\n",
    "    ]\n",
    "    distances_to_happy_traces.append(distances)\n",
    "\n",
    "# Calculate the average distance to the happy traces for each trace representation\n",
    "avg_distances = [np.mean(distances) for distances in distances_to_happy_traces]\n",
    "\n",
    "# Save the distances in a variable\n",
    "avg_distances_var = np.array(avg_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a508bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification['distance'] = avg_distances_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba7067",
   "metadata": {},
   "source": [
    "### 2.2 Binary Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "364bd017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mert2/anaconda3/envs/jp/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Assuming 'results' is your original DataFrame and contains a 'distance' column\n",
    "all_distances = classification['distance'].values.reshape(-1, 1)\n",
    "\n",
    "# Apply k-means clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(all_distances)\n",
    "\n",
    "# Get the cluster centers\n",
    "cluster_centers = kmeans.cluster_centers_.flatten()\n",
    "\n",
    "# Determine which cluster has the smaller and larger distances\n",
    "small_cluster_label = np.argmin(cluster_centers)\n",
    "large_cluster_label = np.argmax(cluster_centers)\n",
    "\n",
    "# Assign predicted labels based on cluster assignment\n",
    "predicted_labels = np.where(kmeans.labels_ == small_cluster_label, 0, 1)\n",
    "classification['predicted'] = predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f1a80",
   "metadata": {},
   "source": [
    "### 2.3 Evaluation (Binary Conformance Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4fd070e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating TP, TN, FP, FN\n",
    "TP = ((classification['actual'] == 1) & (classification['predicted'] == 1)).sum()\n",
    "TN = ((classification['actual'] == 0) & (classification['predicted'] == 0)).sum()\n",
    "FP = ((classification['actual'] == 0) & (classification['predicted'] == 1)).sum()\n",
    "FN = ((classification['actual'] == 1) & (classification['predicted'] == 0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "080d128e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Dev: 0.94\n"
     ]
    }
   ],
   "source": [
    "precision_dev = TP / (TP + FP)\n",
    "print(f\"Precision Dev: {precision_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e7e5ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Dev: 1.00\n"
     ]
    }
   ],
   "source": [
    "recall_dev = TP / (TP + FN)\n",
    "print(f\"Recall Dev: {recall_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97c78fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision No Dev: 1.00\n"
     ]
    }
   ],
   "source": [
    "precision_no_dev = TN / (TN + FN)\n",
    "print(f\"Precision No Dev: {precision_no_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c2eef82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall No Dev: 0.97\n"
     ]
    }
   ],
   "source": [
    "recall_no_dev = TN / (TN + FP)\n",
    "print(f\"Recall No Dev: {recall_no_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c9fff3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_roc = roc_auc_score(classification['actual'], classification['predicted'])\n",
    "print(f\"AUC-ROC: {auc_roc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c266c8",
   "metadata": {},
   "source": [
    "## 3. Conformance Diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622018f5",
   "metadata": {},
   "source": [
    "### 3.1 identify closest input trace for each event log trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9881ba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aligning log, completed variants :: 100%|██████████| 99/99 [00:04<00:00, 23.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# INPUT TRACE 1\n",
    "\n",
    "\n",
    "\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/input_traces/domestic_trace1.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_input_trace1 = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42adfef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aligning log, completed variants :: 100%|██████████| 99/99 [00:05<00:00, 17.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# INPUT TRACE 2\n",
    "\n",
    "\n",
    "\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/input_traces/domestic_trace2.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_input_trace2 = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82d225d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aligning log, completed variants :: 100%|██████████| 99/99 [00:03<00:00, 25.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# INPUT TRACE 3\n",
    "\n",
    "\n",
    "\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/input_traces/domestic_trace8.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_input_trace3 = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3b774",
   "metadata": {},
   "source": [
    "### 3.2 Generate alignments based on closest input traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0be7b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Euclidean distance\n",
    "def euclidean_distance(arr1, arr2):\n",
    "    return np.linalg.norm(arr1 - arr2)\n",
    "\n",
    "# Prepare a list to store the results\n",
    "distance = []\n",
    "\n",
    "# Iterate through each subarray in one_hot_encoding\n",
    "for subarray in one_hot_encoding:\n",
    "    dist_to_trace1 = euclidean_distance(subarray, happy_trace1)\n",
    "    dist_to_trace2 = euclidean_distance(subarray, happy_trace2)\n",
    "    dist_to_trace3 = euclidean_distance(subarray, happy_trace3)\n",
    "    \n",
    "    distances = [dist_to_trace1, dist_to_trace2, dist_to_trace3]\n",
    "    closest_trace_index = np.argmin(distances)\n",
    "    closest_trace = f'trace_{closest_trace_index + 1}'\n",
    "    \n",
    "    distance.append({\n",
    "        'Distance to Trace 1': dist_to_trace1,\n",
    "        'Distance to Trace 2': dist_to_trace2,\n",
    "        'Distance to Trace 3': dist_to_trace3,\n",
    "        'Closest Trace': closest_trace\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "closest_distance = pd.DataFrame(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4bc92d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the merged list\n",
    "aligned_input_trace = []\n",
    "\n",
    "# Iterate through each row of the fitness dataframe\n",
    "for index, row in closest_distance.iterrows():\n",
    "    closest_trace = row['Closest Trace']\n",
    "    \n",
    "    # Append the corresponding alignment to the merged list based on the closest trace\n",
    "    if closest_trace == 'trace_1':\n",
    "        aligned_input_trace.append(aligned_input_trace1[index])\n",
    "    elif closest_trace == 'trace_2':\n",
    "        aligned_input_trace.append(aligned_input_trace2[index])\n",
    "    elif closest_trace == 'trace_3':\n",
    "        aligned_input_trace.append(aligned_input_trace3[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17ed3d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract fitness values\n",
    "aligned_traces_fitness = [trace['fitness'] for trace in aligned_traces]\n",
    "aligned_input_traces_fitness = [trace['fitness'] for trace in aligned_input_trace]\n",
    "\n",
    "# Create DataFrame\n",
    "df_fitness = pd.DataFrame({\n",
    "    'ground_truth_fit': aligned_traces_fitness,\n",
    "    'predicted_fit': aligned_input_traces_fitness\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6725ed8d",
   "metadata": {},
   "source": [
    "### 3.3 Evaluation (Conformance Diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aaa3901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indices where 'predicted' column has value 1\n",
    "indices_to_keep = classification[classification['predicted'] == 1].index.tolist()\n",
    "\n",
    "# Filter the lists to keep only the indices where 'predicted' is 1\n",
    "aligned_input_trace = [aligned_input_trace[i] for i in indices_to_keep]\n",
    "aligned_traces = [aligned_traces[i] for i in indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4280009e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Log Moves): 0.3247\n",
      "Recall (Log Moves): 0.8704\n",
      "\n",
      "Precision (Model Moves): 0.3462\n",
      "Recall (Model Moves): 0.8731\n"
     ]
    }
   ],
   "source": [
    "# Function to extract log and model moves excluding (None, >>) and (>>, None)\n",
    "def extract_moves(alignment):\n",
    "    log_moves = [move for move in alignment if move[1] == '>>' and move[0] is not None]\n",
    "    model_moves = [move for move in alignment if move[0] == '>>' and move[1] is not None]\n",
    "    return log_moves, model_moves\n",
    "\n",
    "# Initialize counts for moves\n",
    "total_log_moves = 0\n",
    "total_no_log_moves = 0\n",
    "total_model_moves = 0\n",
    "total_no_model_moves = 0\n",
    "\n",
    "# Initialize counts for TP, FP, FN, TN\n",
    "tp_log_moves = 0\n",
    "fp_log_moves = 0\n",
    "fn_log_moves = 0\n",
    "tn_log_moves = 0\n",
    "\n",
    "tp_model_moves = 0\n",
    "fp_model_moves = 0\n",
    "fn_model_moves = 0\n",
    "tn_model_moves = 0\n",
    "\n",
    "# Iterate through aligned traces and count moves\n",
    "for i, aligned_trace in enumerate(aligned_traces):\n",
    "    log_moves_gt, model_moves_gt = extract_moves(aligned_trace['alignment'])\n",
    "    total_log_moves += len(log_moves_gt)\n",
    "    total_no_log_moves += sum(1 for move in aligned_trace['alignment'] if move[1] != '>>' or move[0] is None)\n",
    "    total_model_moves += len(model_moves_gt)\n",
    "    total_no_model_moves += sum(1 for move in aligned_trace['alignment'] if move[0] != '>>' or move[1] is None)\n",
    "    \n",
    "    if i < len(aligned_input_trace):\n",
    "        log_moves_input, model_moves_input = extract_moves(aligned_input_trace[i]['alignment'])\n",
    "        \n",
    "        # Calculate TP, FP, FN, TN for log moves\n",
    "        tp_log_moves += sum(1 for move in log_moves_gt if move in log_moves_input)\n",
    "        fn_log_moves += sum(1 for move in log_moves_gt if move not in log_moves_input)\n",
    "        fp_log_moves += sum(1 for move in log_moves_input if move not in log_moves_gt)\n",
    "        tn_log_moves += sum(1 for move in aligned_trace['alignment'] if move not in log_moves_gt and move not in log_moves_input and move[1] != '>>' and move[0] != '>>')\n",
    "        \n",
    "        # Calculate TP, FP, FN, TN for model moves\n",
    "        tp_model_moves += sum(1 for move in model_moves_gt if move in model_moves_input)\n",
    "        fn_model_moves += sum(1 for move in model_moves_gt if move not in model_moves_input)\n",
    "        fp_model_moves += sum(1 for move in model_moves_input if move not in model_moves_gt)\n",
    "        tn_model_moves += sum(1 for move in aligned_trace['alignment'] if move not in model_moves_gt and move not in model_moves_input and move[1] != '>>' and move[0] != '>>')\n",
    "\n",
    "# Calculate recall, precision, F1 score for log moves\n",
    "recall_log_moves = tp_log_moves / (tp_log_moves + fn_log_moves) if (tp_log_moves + fn_log_moves) > 0 else 0\n",
    "precision_log_moves = tp_log_moves / (tp_log_moves + fp_log_moves) if (tp_log_moves + fp_log_moves) > 0 else 0\n",
    "f1_score_log_moves = 2 * (precision_log_moves * recall_log_moves) / (precision_log_moves + recall_log_moves) if (precision_log_moves + recall_log_moves) > 0 else 0\n",
    "\n",
    "# Calculate recall, precision, F1 score for model moves\n",
    "recall_model_moves = tp_model_moves / (tp_model_moves + fn_model_moves) if (tp_model_moves + fn_model_moves) > 0 else 0\n",
    "precision_model_moves = tp_model_moves / (tp_model_moves + fp_model_moves) if (tp_model_moves + fp_model_moves) > 0 else 0\n",
    "f1_score_model_moves = 2 * (precision_model_moves * recall_model_moves) / (precision_model_moves + recall_model_moves) if (precision_model_moves + recall_model_moves) > 0 else 0\n",
    "\n",
    "# Calculate dataset balance for log moves\n",
    "log_move_percentage = (total_log_moves / (total_log_moves + total_no_log_moves)) * 100 if (total_log_moves + total_no_log_moves) > 0 else 0\n",
    "no_log_move_percentage = (total_no_log_moves / (total_log_moves + total_no_log_moves)) * 100 if (total_log_moves + total_no_log_moves) > 0 else 0\n",
    "\n",
    "# Calculate dataset balance for model moves\n",
    "model_move_percentage = (total_model_moves / (total_model_moves + total_no_model_moves)) * 100 if (total_model_moves + total_no_model_moves) > 0 else 0\n",
    "no_model_move_percentage = (total_no_model_moves / (total_model_moves + total_no_model_moves)) * 100 if (total_model_moves + total_no_model_moves) > 0 else 0\n",
    "\n",
    "# Print results for log moves\n",
    "print(f\"Precision (Log Moves): {precision_log_moves:.4f}\")\n",
    "print(f\"Recall (Log Moves): {recall_log_moves:.4f}\")\n",
    "print(\"\")\n",
    "\n",
    "# Print results for model moves\n",
    "print(f\"Precision (Model Moves): {precision_model_moves:.4f}\")\n",
    "print(f\"Recall (Model Moves): {recall_model_moves:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a01e87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the other dataframe using the indices_to_keep\n",
    "df_fitness = df_fitness.loc[indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4422a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error (MSE) is: 0.0025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(df_fitness['ground_truth_fit'], df_fitness['predicted_fit'])\n",
    "\n",
    "# Print the MSE restricted to 4 decimal places\n",
    "print(f\"The Mean Squared Error (MSE) is: {mse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
