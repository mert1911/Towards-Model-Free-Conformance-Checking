{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f1af5c",
   "metadata": {},
   "source": [
    "# Import Event Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab9ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s_/ch_w_j2d0sqf6dbdc0_224m40000gq/T/ipykernel_8805/670060893.py:14: DeprecatedWarning: format_dataframe is deprecated as of 2.3.0 and will be removed in 3.0.0. the format_dataframe function does not need application anymore.\n",
      "  dataframe_log = pm4py.format_dataframe(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the CSV file\n",
    "    dataframe_log = pd.read_csv('../../data/logs/BPIC12_Log_onlyO.csv', sep=',')\n",
    "\n",
    "    # Drop the first column without knowing its name\n",
    "    dataframe_log = dataframe_log.drop(dataframe_log.columns[0], axis=1)\n",
    "\n",
    "    # Format the dataframe\n",
    "    dataframe_log = pm4py.format_dataframe(\n",
    "        dataframe_log,\n",
    "        case_id='case:concept:name',\n",
    "        activity_key='concept:name',\n",
    "        timestamp_key='time:timestamp'\n",
    "    )\n",
    "\n",
    "    # Convert the dataframe to event log\n",
    "    log = log_converter.apply(dataframe_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba199329",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157dbb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Step 1: One-Hot Encoding of Activities\n",
    "mlb = MultiLabelBinarizer()\n",
    "traces = dataframe_log.groupby('@@case_index')['concept:name'].apply(list)\n",
    "one_hot_encoded = mlb.fit_transform(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f0daa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding = np.array(one_hot_encoded.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2171bf1e",
   "metadata": {},
   "source": [
    "# Input Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0029315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Group by case_index and concatenate the activities to form traces\n",
    "dataframe_log['trace'] = dataframe_log.groupby('@@case_index')['concept:name'].transform(lambda x: ', '.join(x))\n",
    "\n",
    "# Step 3: Count occurrences of each unique trace\n",
    "trace_counts = dataframe_log['trace'].value_counts()\n",
    "\n",
    "# Step 4: Convert to DataFrame and sort by occurrences\n",
    "trace_counts_df = trace_counts.reset_index()\n",
    "trace_counts_df.columns = ['Trace', 'Count']\n",
    "trace_counts_df = trace_counts_df.sort_values(by='Count', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b7016de",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_traces = trace_counts_df.head(20)\n",
    "\n",
    "trace1 = top_3_traces.iloc[0]['Trace']\n",
    "trace1 = [event.strip() for event in trace1.split(',')]\n",
    "\n",
    "trace2 = top_3_traces.iloc[1]['Trace']\n",
    "trace2 = [event.strip() for event in trace2.split(',')]\n",
    "\n",
    "trace3 = top_3_traces.iloc[2]['Trace']\n",
    "trace3 = [event.strip() for event in trace3.split(',')]\n",
    "\n",
    "trace4 = top_3_traces.iloc[3]['Trace']\n",
    "trace4 = [event.strip() for event in trace4.split(',')]\n",
    "\n",
    "trace5 = top_3_traces.iloc[4]['Trace']\n",
    "trace5 = [event.strip() for event in trace5.split(',')]\n",
    "\n",
    "trace6 = top_3_traces.iloc[5]['Trace']\n",
    "trace6 = [event.strip() for event in trace6.split(',')]\n",
    "\n",
    "trace7 = top_3_traces.iloc[6]['Trace']\n",
    "trace7 = [event.strip() for event in trace7.split(',')]\n",
    "\n",
    "trace8 = top_3_traces.iloc[7]['Trace']\n",
    "trace8 = [event.strip() for event in trace8.split(',')]\n",
    "\n",
    "trace9 = top_3_traces.iloc[8]['Trace']\n",
    "trace9 = [event.strip() for event in trace9.split(',')]\n",
    "\n",
    "trace10 = top_3_traces.iloc[9]['Trace']\n",
    "trace10 = [event.strip() for event in trace10.split(',')]\n",
    "\n",
    "trace11 = top_3_traces.iloc[10]['Trace']\n",
    "trace11 = [event.strip() for event in trace11.split(',')]\n",
    "\n",
    "trace12 = top_3_traces.iloc[11]['Trace']\n",
    "trace12 = [event.strip() for event in trace12.split(',')]\n",
    "\n",
    "trace13 = top_3_traces.iloc[12]['Trace']\n",
    "trace13 = [event.strip() for event in trace13.split(',')]\n",
    "\n",
    "trace14 = top_3_traces.iloc[13]['Trace']\n",
    "trace14 = [event.strip() for event in trace14.split(',')]\n",
    "\n",
    "trace15 = top_3_traces.iloc[14]['Trace']\n",
    "trace15 = [event.strip() for event in trace15.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee60b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = dataframe_log.groupby('@@case_index')['concept:name'].apply(list).reset_index(name='trace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3fc4290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_happy_trace(row_trace):\n",
    "    predefined_traces = [trace1, trace13, trace3]\n",
    "    for trace in predefined_traces:\n",
    "        if row_trace == trace:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e286ba1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@@case_index</th>\n",
       "      <th>trace</th>\n",
       "      <th>happy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK, O...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK, O...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>5010</td>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>5011</td>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>5012</td>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK, O...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>5013</td>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>5014</td>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5015 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      @@case_index                                              trace  happy\n",
       "0                0  [O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK, O...      1\n",
       "1                1  [O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...      0\n",
       "2                2  [O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...      0\n",
       "3                3  [O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK, O...      1\n",
       "4                4  [O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...      0\n",
       "...            ...                                                ...    ...\n",
       "5010          5010       [O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK]      0\n",
       "5011          5011                    [O_SELECTED, O_CREATED, O_SENT]      0\n",
       "5012          5012  [O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK, O...      1\n",
       "5013          5013  [O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...      0\n",
       "5014          5014                    [O_SELECTED, O_CREATED, O_SENT]      0\n",
       "\n",
       "[5015 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped['happy'] = grouped['trace'].apply(is_happy_trace)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9521ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of the happy traces in the results dataframe\n",
    "happy_trace_indices = grouped[grouped['happy'] == 1].index.tolist()\n",
    "\n",
    "# Extract the corresponding coordinates from the trace_representations array\n",
    "happy_trace_coordinates = one_hot_encoding[happy_trace_indices]\n",
    "\n",
    "# Extract unique coordinates\n",
    "unique_happy_trace_coordinates = np.unique(happy_trace_coordinates, axis=0)\n",
    "\n",
    "# Assuming the size of unique_happy_trace_coordinates is 3\n",
    "#happy_trace1, happy_trace2, happy_trace3 = unique_happy_trace_coordinates\n",
    "happy_trace1, happy_trace2, happy_trace3 = unique_happy_trace_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb704ff",
   "metadata": {},
   "source": [
    "# Distance Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce6f9e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Calculate the distances to each of the happy traces for every trace representation\n",
    "distances_to_happy_traces = []\n",
    "\n",
    "for trace_representation in one_hot_encoding:\n",
    "    distances = [\n",
    "        euclidean(trace_representation, happy_trace1),\n",
    "        euclidean(trace_representation, happy_trace2),\n",
    "        euclidean(trace_representation, happy_trace3)\n",
    "    ]\n",
    "    distances_to_happy_traces.append(distances)\n",
    "\n",
    "# Calculate the average distance to the happy traces for each trace representation\n",
    "avg_distances = [np.mean(distances) for distances in distances_to_happy_traces]\n",
    "\n",
    "# Save the distances in a variable\n",
    "avg_distances_var = np.array(avg_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419acf27",
   "metadata": {},
   "source": [
    "# Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad7a799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking):\n",
    "    from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments\n",
    "    from pm4py.algo.conformance.alignments.petri_net import variants\n",
    "    from pm4py.objects.petri_net.utils import align_utils\n",
    "    max_events=0\n",
    "    for trace in log:\n",
    "        counter=0\n",
    "        for event in trace:\n",
    "            counter+=1\n",
    "        if counter > max_events:\n",
    "            max_events=counter\n",
    "    parameters={}\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_SYNC_COST_FUNCTION] = list(map(lambda i: .1*i, range(max_events*2)))\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_TRACE_COST_FUNCTION]=list(map(lambda i: align_utils.STD_MODEL_LOG_MOVE_COST-.1*i, range(max_events*2)))\n",
    "    aligned_traces = alignments.apply_log(log, net, initial_marking, final_marking, variant=variants.state_equation_a_star, parameters=parameters)\n",
    "    return aligned_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75901bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0939e5f03a44dcfa69f72ecd0249573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/model/Model_O.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_traces = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74f22d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conformance_status_by_fitness(aligned_traces):\n",
    "    conformance_status = []\n",
    "    for alignment in aligned_traces:\n",
    "        fitness = alignment['fitness']\n",
    "        # If the fitness is 1.0, the trace is conforming\n",
    "        if fitness == 1.0:\n",
    "            conformance_status.append(0)\n",
    "        else:\n",
    "            conformance_status.append(1)\n",
    "    return conformance_status\n",
    "\n",
    "# Get the conformance status list from the aligned traces\n",
    "conformance = extract_conformance_status_by_fitness(aligned_traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5041b2f3",
   "metadata": {},
   "source": [
    "# Results overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6648d6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace</th>\n",
       "      <th>actual</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK, O...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.244017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.244017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK, O...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.244017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK, O...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>[O_SELECTED, O_CREATED, O_SENT]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5015 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  trace  actual  distance\n",
       "0     [O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK, O...       0  0.942809\n",
       "1     [O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...       1  1.244017\n",
       "2     [O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...       1  1.244017\n",
       "3     [O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK, O...       0  0.942809\n",
       "4     [O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...       1  1.244017\n",
       "...                                                 ...     ...       ...\n",
       "5010       [O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK]       1  1.000000\n",
       "5011                    [O_SELECTED, O_CREATED, O_SENT]       1  1.414214\n",
       "5012  [O_SELECTED, O_CREATED, O_SENT, O_SENT_BACK, O...       0  0.942809\n",
       "5013  [O_SELECTED, O_CREATED, O_SENT, O_SELECTED, O_...       1  0.942809\n",
       "5014                    [O_SELECTED, O_CREATED, O_SENT]       1  1.414214\n",
       "\n",
       "[5015 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grouped['trace'])\n",
    "\n",
    "conformity_array = conformance\n",
    "results['actual'] = conformity_array\n",
    "\n",
    "results['distance'] = avg_distances_var\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba7067",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "364bd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Filter the DataFrame into conforming and non-conforming subsets\n",
    "conforming_distances = results[results['actual'] == 1]['distance']\n",
    "non_conforming_distances = results[results['actual'] == 0]['distance']\n",
    "\n",
    "# Determine common bin edges\n",
    "min_distance = min(results['distance'])\n",
    "max_distance = max(results['distance'])\n",
    "bin_edges = np.linspace(min_distance, max_distance, num=30)\n",
    "\n",
    "# Combine the data and reshape for k-means\n",
    "all_distances = results['distance']\n",
    "all_distances = np.array(all_distances)\n",
    "all_distances_reshaped = all_distances.reshape(-1, 1)\n",
    "\n",
    "# Apply k-means clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(all_distances_reshaped)\n",
    "kmeans_labels = kmeans.labels_\n",
    "\n",
    "# Find the threshold as the average of the two cluster centers\n",
    "threshold_value = np.mean(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "365270d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'classification' is a DataFrame and 'threshold_value' is already defined\n",
    "results['predicted'] = results['distance'].apply(lambda x: 1 if x > threshold_value else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55ca1252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating TP, TN, FP, FN\n",
    "TP = ((results['actual'] == 1) & (results['predicted'] == 1)).sum()\n",
    "TN = ((results['actual'] == 0) & (results['predicted'] == 0)).sum()\n",
    "FP = ((results['actual'] == 0) & (results['predicted'] == 1)).sum()\n",
    "FN = ((results['actual'] == 1) & (results['predicted'] == 0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52973f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Dev: 1.00\n"
     ]
    }
   ],
   "source": [
    "precision_dev = TP / (TP + FP)\n",
    "print(f\"Precision Dev: {precision_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c27fee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Dev: 0.94\n"
     ]
    }
   ],
   "source": [
    "recall_dev = TP / (TP + FN)\n",
    "print(f\"Recall Dev: {recall_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55902440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision No Dev: 0.93\n"
     ]
    }
   ],
   "source": [
    "precision_no_dev = TN / (TN + FN)\n",
    "print(f\"Precision No Dev: {precision_no_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2261cee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall No Dev: 1.00\n"
     ]
    }
   ],
   "source": [
    "recall_no_dev = TN / (TN + FP)\n",
    "print(f\"Recall No Dev: {recall_no_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dca7ba90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_roc = roc_auc_score(results['actual'], results['predicted'])\n",
    "print(f\"AUC-ROC: {auc_roc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938800f4",
   "metadata": {},
   "source": [
    "# Deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b45d08",
   "metadata": {},
   "source": [
    "### a) identify closest trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d91e4ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e591abe1d34963a02ce72d224812f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# INPUT TRACE 1\n",
    "\n",
    "\n",
    "\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/input_traces/bpicO_trace1.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_input_trace1 = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b788410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3455b03c5c6643529a749e86c4021cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# INPUT TRACE 2\n",
    "\n",
    "\n",
    "\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/input_traces/bpicO_trace13.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_input_trace2 = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93cfd5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda63e14faef479cb8f8dae58e313212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# INPUT TRACE 3\n",
    "\n",
    "\n",
    "\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/input_traces/bpicO_trace3.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_input_trace3 = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fee90d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Euclidean distance\n",
    "def euclidean_distance(arr1, arr2):\n",
    "    return np.linalg.norm(arr1 - arr2)\n",
    "\n",
    "# Prepare a list to store the results\n",
    "distance = []\n",
    "\n",
    "# Iterate through each subarray in one_hot_encoding\n",
    "for subarray in one_hot_encoding:\n",
    "    dist_to_trace1 = euclidean_distance(subarray, happy_trace1)\n",
    "    dist_to_trace2 = euclidean_distance(subarray, happy_trace2)\n",
    "    dist_to_trace3 = euclidean_distance(subarray, happy_trace3)\n",
    "    \n",
    "    distances = [dist_to_trace1, dist_to_trace2, dist_to_trace3]\n",
    "    closest_trace_index = np.argmin(distances)\n",
    "    closest_trace = f'trace_{closest_trace_index + 1}'\n",
    "    \n",
    "    distance.append({\n",
    "        'Distance to Trace 1': dist_to_trace1,\n",
    "        'Distance to Trace 2': dist_to_trace2,\n",
    "        'Distance to Trace 3': dist_to_trace3,\n",
    "        'Closest Trace': closest_trace\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "closest_distance = pd.DataFrame(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90664795",
   "metadata": {},
   "source": [
    "### b) identify deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be056044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the merged list\n",
    "aligned_input_trace = []\n",
    "\n",
    "# Iterate through each row of the fitness dataframe\n",
    "for index, row in closest_distance.iterrows():\n",
    "    closest_trace = row['Closest Trace']\n",
    "    \n",
    "    # Append the corresponding alignment to the merged list based on the closest trace\n",
    "    if closest_trace == 'trace_1':\n",
    "        aligned_input_trace.append(aligned_input_trace1[index])\n",
    "    elif closest_trace == 'trace_2':\n",
    "        aligned_input_trace.append(aligned_input_trace2[index])\n",
    "    elif closest_trace == 'trace_3':\n",
    "        aligned_input_trace.append(aligned_input_trace3[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "579bbbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract fitness values\n",
    "aligned_traces_fitness = [trace['fitness'] for trace in aligned_traces]\n",
    "aligned_input_traces_fitness = [trace['fitness'] for trace in aligned_input_trace]\n",
    "\n",
    "# Create DataFrame\n",
    "df_fitness = pd.DataFrame({\n",
    "    'ground_truth_fit': aligned_traces_fitness,\n",
    "    'predicted_fit': aligned_input_traces_fitness\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2611289",
   "metadata": {},
   "source": [
    "- The logic compares log and model moves in `aligned_traces` and `aligned_input_trace` at each corresponding outer index. It extracts moves from both traces and counts them as detected if they match in both content and presence, regardless of their inner positions within the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4128f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indices where 'predicted' column has value 1\n",
    "indices_to_keep = results[results['predicted'] == 1].index.tolist()\n",
    "\n",
    "# Filter the lists to keep only the indices where 'predicted' is 1\n",
    "aligned_input_trace = [aligned_input_trace[i] for i in indices_to_keep]\n",
    "aligned_traces = [aligned_traces[i] for i in indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3973842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Log Moves): 0.8762\n",
      "Recall (Log Moves): 0.9578\n",
      "\n",
      "Precision (Model Moves): 0.6930\n",
      "Recall (Model Moves): 0.9210\n"
     ]
    }
   ],
   "source": [
    "# Function to extract log and model moves excluding (None, >>) and (>>, None)\n",
    "def extract_moves(alignment):\n",
    "    log_moves = [move for move in alignment if move[1] == '>>' and move[0] is not None]\n",
    "    model_moves = [move for move in alignment if move[0] == '>>' and move[1] is not None]\n",
    "    return log_moves, model_moves\n",
    "\n",
    "# Initialize counts for moves\n",
    "total_log_moves = 0\n",
    "total_no_log_moves = 0\n",
    "total_model_moves = 0\n",
    "total_no_model_moves = 0\n",
    "\n",
    "# Initialize counts for TP, FP, FN, TN\n",
    "tp_log_moves = 0\n",
    "fp_log_moves = 0\n",
    "fn_log_moves = 0\n",
    "tn_log_moves = 0\n",
    "\n",
    "tp_model_moves = 0\n",
    "fp_model_moves = 0\n",
    "fn_model_moves = 0\n",
    "tn_model_moves = 0\n",
    "\n",
    "# Iterate through aligned traces and count moves\n",
    "for i, aligned_trace in enumerate(aligned_traces):\n",
    "    log_moves_gt, model_moves_gt = extract_moves(aligned_trace['alignment'])\n",
    "    total_log_moves += len(log_moves_gt)\n",
    "    total_no_log_moves += sum(1 for move in aligned_trace['alignment'] if move[1] != '>>' or move[0] is None)\n",
    "    total_model_moves += len(model_moves_gt)\n",
    "    total_no_model_moves += sum(1 for move in aligned_trace['alignment'] if move[0] != '>>' or move[1] is None)\n",
    "    \n",
    "    if i < len(aligned_input_trace):\n",
    "        log_moves_input, model_moves_input = extract_moves(aligned_input_trace[i]['alignment'])\n",
    "        \n",
    "        # Calculate TP, FP, FN, TN for log moves\n",
    "        tp_log_moves += sum(1 for move in log_moves_gt if move in log_moves_input)\n",
    "        fn_log_moves += sum(1 for move in log_moves_gt if move not in log_moves_input)\n",
    "        fp_log_moves += sum(1 for move in log_moves_input if move not in log_moves_gt)\n",
    "        tn_log_moves += sum(1 for move in aligned_trace['alignment'] if move not in log_moves_gt and move not in log_moves_input and move[1] != '>>' and move[0] != '>>')\n",
    "        \n",
    "        # Calculate TP, FP, FN, TN for model moves\n",
    "        tp_model_moves += sum(1 for move in model_moves_gt if move in model_moves_input)\n",
    "        fn_model_moves += sum(1 for move in model_moves_gt if move not in model_moves_input)\n",
    "        fp_model_moves += sum(1 for move in model_moves_input if move not in model_moves_gt)\n",
    "        tn_model_moves += sum(1 for move in aligned_trace['alignment'] if move not in model_moves_gt and move not in model_moves_input and move[1] != '>>' and move[0] != '>>')\n",
    "\n",
    "# Calculate recall, precision, F1 score for log moves\n",
    "recall_log_moves = tp_log_moves / (tp_log_moves + fn_log_moves) if (tp_log_moves + fn_log_moves) > 0 else 0\n",
    "precision_log_moves = tp_log_moves / (tp_log_moves + fp_log_moves) if (tp_log_moves + fp_log_moves) > 0 else 0\n",
    "f1_score_log_moves = 2 * (precision_log_moves * recall_log_moves) / (precision_log_moves + recall_log_moves) if (precision_log_moves + recall_log_moves) > 0 else 0\n",
    "\n",
    "# Calculate recall, precision, F1 score for model moves\n",
    "recall_model_moves = tp_model_moves / (tp_model_moves + fn_model_moves) if (tp_model_moves + fn_model_moves) > 0 else 0\n",
    "precision_model_moves = tp_model_moves / (tp_model_moves + fp_model_moves) if (tp_model_moves + fp_model_moves) > 0 else 0\n",
    "f1_score_model_moves = 2 * (precision_model_moves * recall_model_moves) / (precision_model_moves + recall_model_moves) if (precision_model_moves + recall_model_moves) > 0 else 0\n",
    "\n",
    "# Calculate dataset balance for log moves\n",
    "log_move_percentage = (total_log_moves / (total_log_moves + total_no_log_moves)) * 100 if (total_log_moves + total_no_log_moves) > 0 else 0\n",
    "no_log_move_percentage = (total_no_log_moves / (total_log_moves + total_no_log_moves)) * 100 if (total_log_moves + total_no_log_moves) > 0 else 0\n",
    "\n",
    "# Calculate dataset balance for model moves\n",
    "model_move_percentage = (total_model_moves / (total_model_moves + total_no_model_moves)) * 100 if (total_model_moves + total_no_model_moves) > 0 else 0\n",
    "no_model_move_percentage = (total_no_model_moves / (total_model_moves + total_no_model_moves)) * 100 if (total_model_moves + total_no_model_moves) > 0 else 0\n",
    "\n",
    "# Print results for log moves\n",
    "print(f\"Precision (Log Moves): {precision_log_moves:.4f}\")\n",
    "print(f\"Recall (Log Moves): {recall_log_moves:.4f}\")\n",
    "print(\"\")\n",
    "\n",
    "# Print results for model moves\n",
    "print(f\"Precision (Model Moves): {precision_model_moves:.4f}\")\n",
    "print(f\"Recall (Model Moves): {recall_model_moves:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86d7713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the other dataframe using the indices_to_keep\n",
    "df_fitness = df_fitness.loc[indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b71871db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error (MSE) is: 0.0002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(df_fitness['ground_truth_fit'], df_fitness['predicted_fit'])\n",
    "\n",
    "# Print the MSE restricted to 4 decimal places\n",
    "print(f\"The Mean Squared Error (MSE) is: {mse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
