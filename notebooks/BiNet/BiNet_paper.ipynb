{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Event Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s_/ch_w_j2d0sqf6dbdc0_224m40000gq/T/ipykernel_6115/3645535663.py:11: DeprecatedWarning: format_dataframe is deprecated as of 2.3.0 and will be removed in 3.0.0. the format_dataframe function does not need application anymore.\n",
      "  dataframe_log = pm4py.format_dataframe(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the CSV file\n",
    "    dataframe_log = pd.read_csv('../../data/logs/binet_paper_log.csv', sep=',')\n",
    "\n",
    "    # Format the dataframe\n",
    "    dataframe_log = pm4py.format_dataframe(\n",
    "        dataframe_log,\n",
    "        case_id='case:concept:name',\n",
    "        activity_key='concept:name',\n",
    "        timestamp_key='time:timestamp'\n",
    "    )\n",
    "\n",
    "    # Convert the dataframe to event log\n",
    "    log = log_converter.apply(dataframe_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>case:label</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>@@index</th>\n",
       "      <th>@@case_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Identify Problem</td>\n",
       "      <td>2010-01-01 00:00:00+00:00</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>Supervisor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Research Related Work</td>\n",
       "      <td>2010-01-01 00:14:00+00:00</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>Student</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Develop Method</td>\n",
       "      <td>2010-02-01 00:00:00+00:00</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>Main Author</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Experiment</td>\n",
       "      <td>2010-02-01 00:14:00+00:00</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>Student</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evaluate</td>\n",
       "      <td>2010-03-01 00:00:00+00:00</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>Main Author</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56809</th>\n",
       "      <td>Research Related Work</td>\n",
       "      <td>2025-07-29 00:14:00+00:00</td>\n",
       "      <td>Rework</td>\n",
       "      <td>999</td>\n",
       "      <td>Student</td>\n",
       "      <td>56809</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56810</th>\n",
       "      <td>Develop Method</td>\n",
       "      <td>2025-07-30 00:00:00+00:00</td>\n",
       "      <td>Rework</td>\n",
       "      <td>999</td>\n",
       "      <td>Author</td>\n",
       "      <td>56810</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56811</th>\n",
       "      <td>Experiment</td>\n",
       "      <td>2025-07-30 00:14:00+00:00</td>\n",
       "      <td>Rework</td>\n",
       "      <td>999</td>\n",
       "      <td>Main Author</td>\n",
       "      <td>56811</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56812</th>\n",
       "      <td>Evaluate</td>\n",
       "      <td>2025-07-31 00:00:00+00:00</td>\n",
       "      <td>Rework</td>\n",
       "      <td>999</td>\n",
       "      <td>Main Author</td>\n",
       "      <td>56812</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56813</th>\n",
       "      <td>Conclude</td>\n",
       "      <td>2025-07-31 00:14:00+00:00</td>\n",
       "      <td>Rework</td>\n",
       "      <td>999</td>\n",
       "      <td>Main Author</td>\n",
       "      <td>56813</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56814 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                concept:name            time:timestamp case:label  \\\n",
       "0           Identify Problem 2010-01-01 00:00:00+00:00     normal   \n",
       "1      Research Related Work 2010-01-01 00:14:00+00:00     normal   \n",
       "2             Develop Method 2010-02-01 00:00:00+00:00     normal   \n",
       "3                 Experiment 2010-02-01 00:14:00+00:00     normal   \n",
       "4                   Evaluate 2010-03-01 00:00:00+00:00     normal   \n",
       "...                      ...                       ...        ...   \n",
       "56809  Research Related Work 2025-07-29 00:14:00+00:00     Rework   \n",
       "56810         Develop Method 2025-07-30 00:00:00+00:00     Rework   \n",
       "56811             Experiment 2025-07-30 00:14:00+00:00     Rework   \n",
       "56812               Evaluate 2025-07-31 00:00:00+00:00     Rework   \n",
       "56813               Conclude 2025-07-31 00:14:00+00:00     Rework   \n",
       "\n",
       "      case:concept:name org:resource  @@index  @@case_index  \n",
       "0                     1   Supervisor        0             0  \n",
       "1                     1      Student        1             0  \n",
       "2                     1  Main Author        2             0  \n",
       "3                     1      Student        3             0  \n",
       "4                     1  Main Author        4             0  \n",
       "...                 ...          ...      ...           ...  \n",
       "56809               999      Student    56809          4999  \n",
       "56810               999       Author    56810          4999  \n",
       "56811               999  Main Author    56811          4999  \n",
       "56812               999  Main Author    56812          4999  \n",
       "56813               999  Main Author    56813          4999  \n",
       "\n",
       "[56814 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop unnessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_log = dataframe_log.drop(columns=['case:label'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:concept:name'])\n",
    "dataframe_log = dataframe_log.drop(columns=['@@index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>@@case_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Identify Problem</td>\n",
       "      <td>2010-01-01 00:00:00+00:00</td>\n",
       "      <td>Supervisor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Research Related Work</td>\n",
       "      <td>2010-01-01 00:14:00+00:00</td>\n",
       "      <td>Student</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Develop Method</td>\n",
       "      <td>2010-02-01 00:00:00+00:00</td>\n",
       "      <td>Main Author</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Experiment</td>\n",
       "      <td>2010-02-01 00:14:00+00:00</td>\n",
       "      <td>Student</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evaluate</td>\n",
       "      <td>2010-03-01 00:00:00+00:00</td>\n",
       "      <td>Main Author</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56809</th>\n",
       "      <td>Research Related Work</td>\n",
       "      <td>2025-07-29 00:14:00+00:00</td>\n",
       "      <td>Student</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56810</th>\n",
       "      <td>Develop Method</td>\n",
       "      <td>2025-07-30 00:00:00+00:00</td>\n",
       "      <td>Author</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56811</th>\n",
       "      <td>Experiment</td>\n",
       "      <td>2025-07-30 00:14:00+00:00</td>\n",
       "      <td>Main Author</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56812</th>\n",
       "      <td>Evaluate</td>\n",
       "      <td>2025-07-31 00:00:00+00:00</td>\n",
       "      <td>Main Author</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56813</th>\n",
       "      <td>Conclude</td>\n",
       "      <td>2025-07-31 00:14:00+00:00</td>\n",
       "      <td>Main Author</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56814 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                concept:name            time:timestamp org:resource  \\\n",
       "0           Identify Problem 2010-01-01 00:00:00+00:00   Supervisor   \n",
       "1      Research Related Work 2010-01-01 00:14:00+00:00      Student   \n",
       "2             Develop Method 2010-02-01 00:00:00+00:00  Main Author   \n",
       "3                 Experiment 2010-02-01 00:14:00+00:00      Student   \n",
       "4                   Evaluate 2010-03-01 00:00:00+00:00  Main Author   \n",
       "...                      ...                       ...          ...   \n",
       "56809  Research Related Work 2025-07-29 00:14:00+00:00      Student   \n",
       "56810         Develop Method 2025-07-30 00:00:00+00:00       Author   \n",
       "56811             Experiment 2025-07-30 00:14:00+00:00  Main Author   \n",
       "56812               Evaluate 2025-07-31 00:00:00+00:00  Main Author   \n",
       "56813               Conclude 2025-07-31 00:14:00+00:00  Main Author   \n",
       "\n",
       "       @@case_index  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "56809          4999  \n",
       "56810          4999  \n",
       "56811          4999  \n",
       "56812          4999  \n",
       "56813          4999  \n",
       "\n",
       "[56814 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Convert to datetime format\n",
    "dataframe_log['time:timestamp'] = pd.to_datetime(dataframe_log['time:timestamp'])\n",
    "\n",
    "# Calculate elapsed time since the start of each case\n",
    "dataframe_log['start_time'] = dataframe_log.groupby('@@case_index')['time:timestamp'].transform('min')\n",
    "dataframe_log['elapsed_time'] = (dataframe_log['time:timestamp'] - dataframe_log['start_time']).dt.total_seconds()\n",
    "\n",
    "# Normalize the elapsed time in minutes\n",
    "scaler = StandardScaler()\n",
    "dataframe_log['standardized_elapsed_time'] = scaler.fit_transform(dataframe_log[['elapsed_time']])\n",
    "\n",
    "dataframe_log = dataframe_log.drop(columns=['start_time'])\n",
    "dataframe_log = dataframe_log.drop(columns=['elapsed_time'])\n",
    "dataframe_log = dataframe_log.drop(columns=['time:timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept:name</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>@@case_index</th>\n",
       "      <th>standardized_elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Identify Problem</td>\n",
       "      <td>Supervisor</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.287727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Research Related Work</td>\n",
       "      <td>Student</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.287670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Develop Method</td>\n",
       "      <td>Main Author</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Experiment</td>\n",
       "      <td>Student</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evaluate</td>\n",
       "      <td>Main Author</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56809</th>\n",
       "      <td>Research Related Work</td>\n",
       "      <td>Student</td>\n",
       "      <td>4999</td>\n",
       "      <td>0.905333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56810</th>\n",
       "      <td>Develop Method</td>\n",
       "      <td>Author</td>\n",
       "      <td>4999</td>\n",
       "      <td>0.911181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56811</th>\n",
       "      <td>Experiment</td>\n",
       "      <td>Main Author</td>\n",
       "      <td>4999</td>\n",
       "      <td>0.911239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56812</th>\n",
       "      <td>Evaluate</td>\n",
       "      <td>Main Author</td>\n",
       "      <td>4999</td>\n",
       "      <td>0.917087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56813</th>\n",
       "      <td>Conclude</td>\n",
       "      <td>Main Author</td>\n",
       "      <td>4999</td>\n",
       "      <td>0.917145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56814 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                concept:name org:resource  @@case_index  \\\n",
       "0           Identify Problem   Supervisor             0   \n",
       "1      Research Related Work      Student             0   \n",
       "2             Develop Method  Main Author             0   \n",
       "3                 Experiment      Student             0   \n",
       "4                   Evaluate  Main Author             0   \n",
       "...                      ...          ...           ...   \n",
       "56809  Research Related Work      Student          4999   \n",
       "56810         Develop Method       Author          4999   \n",
       "56811             Experiment  Main Author          4999   \n",
       "56812               Evaluate  Main Author          4999   \n",
       "56813               Conclude  Main Author          4999   \n",
       "\n",
       "       standardized_elapsed_time  \n",
       "0                      -0.287727  \n",
       "1                      -0.287670  \n",
       "2                      -0.104643  \n",
       "3                      -0.104585  \n",
       "4                       0.060724  \n",
       "...                          ...  \n",
       "56809                   0.905333  \n",
       "56810                   0.911181  \n",
       "56811                   0.911239  \n",
       "56812                   0.917087  \n",
       "56813                   0.917145  \n",
       "\n",
       "[56814 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(dataframe_log['org:resource'])\n",
    "dataframe_log['org:resource'] = codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(dataframe_log['concept:name'])\n",
    "dataframe_log['concept:name'] = codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept:name</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>@@case_index</th>\n",
       "      <th>standardized_elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.287727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.287670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56809</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4999</td>\n",
       "      <td>0.905333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56810</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4999</td>\n",
       "      <td>0.911181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56811</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4999</td>\n",
       "      <td>0.911239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56812</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4999</td>\n",
       "      <td>0.917087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56813</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4999</td>\n",
       "      <td>0.917145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56814 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       concept:name  org:resource  @@case_index  standardized_elapsed_time\n",
       "0                 1             1             0                  -0.287727\n",
       "1                 2             2             0                  -0.287670\n",
       "2                 3             3             0                  -0.104643\n",
       "3                 4             2             0                  -0.104585\n",
       "4                 5             3             0                   0.060724\n",
       "...             ...           ...           ...                        ...\n",
       "56809             2             2          4999                   0.905333\n",
       "56810             3             6          4999                   0.911181\n",
       "56811             4             3          4999                   0.911239\n",
       "56812             5             3          4999                   0.917087\n",
       "56813             6             3          4999                   0.917145\n",
       "\n",
       "[56814 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activity = dataframe_log[['concept:name', '@@case_index']]\n",
    "df_resource = dataframe_log[['org:resource', '@@case_index']]\n",
    "df_timestamp = dataframe_log[['standardized_elapsed_time', '@@case_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 17:28:08.154960: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def generate_prefix_windows(df, case_id_column='@@case_index', max_len=None):\n",
    "    windows = []\n",
    "    targets = []\n",
    "    case_indices = []\n",
    "    \n",
    "    for case_id in df[case_id_column].unique():\n",
    "        case_data = df[df[case_id_column] == case_id].drop(columns=[case_id_column]).to_numpy()\n",
    "        \n",
    "        # Optional: Make sure to sort the case data if there's an implicit order (e.g., by timestamps)\n",
    "        # case_data = case_data.sort_values(by='timestamp_column').to_numpy()  # Uncomment and adjust if needed\n",
    "        \n",
    "        for i in range(1, len(case_data)):\n",
    "            window = case_data[:i]\n",
    "            target = case_data[i]\n",
    "            windows.append(window)\n",
    "            targets.append(target)\n",
    "            case_indices.append(case_id)\n",
    "    \n",
    "    if max_len is None:\n",
    "        max_len = max(len(window) for window in windows)\n",
    "    \n",
    "    # Pad sequences\n",
    "    windows_padded = pad_sequences(windows, maxlen=max_len, padding='post', dtype='float32')\n",
    "    \n",
    "    # Convert targets to numpy array\n",
    "    targets_array = np.array(targets, dtype='float32')\n",
    "    case_indices_array = np.array(case_indices)\n",
    "    \n",
    "    return windows_padded, targets_array, case_indices_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_resource, targets_resource, case_indices = generate_prefix_windows(df_resource)\n",
    "windows_activity, targets_activity, case_indices = generate_prefix_windows(df_activity)\n",
    "windows_timestamp, targets_timestamp, case_indices = generate_prefix_windows(df_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separate Inputs for Each Attribute\n",
    "- Each attribute is passed through an embedding layer\n",
    "- Each attribute has its corresponding GRU encoder\n",
    "- Selective Concatenation: After encoding, the outputs of these GRU layers are concatenated. However, this concatenation is selective, meaning it is structured in a way that prepares the data for effective synthesis without leaking information from the future (next event attributes)\n",
    "- Decoder GRUs: Integrated Decoding: Post-concatenation, the combined attributes are processed through decoder GRU layers. These layers are tasked with integrating the data from different attributes and preparing it for final prediction. This step is where BINet v3 distinguishes itself by effectively using the interdependencies between different attributes to enhance prediction accuracy.\n",
    "- Output Layer: Softmax Output for Each Attribute: For each attribute of the next event, a softmax layer predicts a probability distribution over all possible values. This allows the model to output the most likely next event and its attributes based on the learned dependencies and the history encoded by the GRUs.\n",
    "- E: maximum case length\n",
    "- We train BINet with a GRU size of 2E (two times the maximum case length)\n",
    "- on mini batches of size 500 for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the @@case_index column and count the rows in each group\n",
    "case_lengths = dataframe_log.groupby('@@case_index').size()\n",
    "\n",
    "# Find the maximum value among the case lengths\n",
    "E = case_lengths.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " activity_input (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " resource_input (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " activity_embedding (Embedd  (None, None, 50)             1300      ['activity_input[0][0]']      \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " resource_embedding (Embedd  (None, None, 50)             600       ['resource_input[0][0]']      \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " timestamp_input (InputLaye  [(None, None, 1)]            0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " activity_encoder (GRU)      (None, None, 30)             7380      ['activity_embedding[0][0]']  \n",
      "                                                                                                  \n",
      " resource_encoder (GRU)      (None, None, 30)             7380      ['resource_embedding[0][0]']  \n",
      "                                                                                                  \n",
      " timestamp_encoder (GRU)     (None, None, 30)             2970      ['timestamp_input[0][0]']     \n",
      "                                                                                                  \n",
      " bn_activity (BatchNormaliz  (None, None, 30)             120       ['activity_encoder[0][0]']    \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " bn_resource (BatchNormaliz  (None, None, 30)             120       ['resource_encoder[0][0]']    \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " bn_timestamp (BatchNormali  (None, None, 30)             120       ['timestamp_encoder[0][0]']   \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_encodings (Con  (None, None, 90)             0         ['bn_activity[0][0]',         \n",
      " catenate)                                                           'bn_resource[0][0]',         \n",
      "                                                                     'bn_timestamp[0][0]']        \n",
      "                                                                                                  \n",
      " decoder_gru (GRU)           (None, 30)                   10980     ['concatenate_encodings[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 30)                   0         ['decoder_gru[0][0]']         \n",
      "                                                                                                  \n",
      " output_activity (Dense)     (None, 26)                   806       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " output_resource (Dense)     (None, 12)                   372       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " output_timestamp (Dense)    (None, 1)                    31        ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32179 (125.70 KB)\n",
      "Trainable params: 31999 (125.00 KB)\n",
      "Non-trainable params: 180 (720.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Embedding, Dense, Dropout, Concatenate, BatchNormalization\n",
    "\n",
    "def create_binetv3(num_activities, num_resources, embedding_dim, gru_units, dropout_rate):\n",
    "    # Input layers for each attribute\n",
    "    input_activity = Input(shape=(None,), name='activity_input')\n",
    "    input_resource = Input(shape=(None,), name='resource_input')\n",
    "    input_timestamp = Input(shape=(None, 1), name='timestamp_input')\n",
    "\n",
    "    # Embedding layers for categorical attributes\n",
    "    embedding_activity = Embedding(input_dim=num_activities + 1, output_dim=embedding_dim, mask_zero=True, name='activity_embedding')(input_activity)\n",
    "    embedding_resource = Embedding(input_dim=num_resources + 1, output_dim=embedding_dim, mask_zero=True, name='resource_embedding')(input_resource)\n",
    "\n",
    "    # Encoder GRUs with Batch Normalization for categorical attributes\n",
    "    encoded_activity = GRU(units=gru_units, return_sequences=True, name='activity_encoder')(embedding_activity)\n",
    "    bn_activity = BatchNormalization(name='bn_activity')(encoded_activity)\n",
    "    encoded_resource = GRU(units=gru_units, return_sequences=True, name='resource_encoder')(embedding_resource)\n",
    "    bn_resource = BatchNormalization(name='bn_resource')(encoded_resource)\n",
    "\n",
    "    # Encoder GRU with Batch Normalization for continuous attribute\n",
    "    encoded_timestamp = GRU(units=gru_units, return_sequences=True, name='timestamp_encoder')(input_timestamp)\n",
    "    bn_timestamp = BatchNormalization(name='bn_timestamp')(encoded_timestamp)\n",
    "\n",
    "    # Concatenation of encoded outputs\n",
    "    concatenated = Concatenate(name='concatenate_encodings')([bn_activity, bn_resource, bn_timestamp])\n",
    "\n",
    "    # Decoder GRU\n",
    "    decoder_output = GRU(units=gru_units, return_sequences=False, name='decoder_gru')(concatenated)\n",
    "    dropout_layer = Dropout(rate=dropout_rate, name='dropout')(decoder_output)\n",
    "\n",
    "    # Output layers for predicting the next event's attributes\n",
    "    output_activity = Dense(num_activities + 1, activation='softmax', name='output_activity')(dropout_layer)\n",
    "    output_resource = Dense(num_resources + 1, activation='softmax', name='output_resource')(dropout_layer)\n",
    "    output_timestamp = Dense(1, activation='linear', name='output_timestamp')(dropout_layer)\n",
    "\n",
    "    # Building the model\n",
    "    model = Model(inputs=[input_activity, input_resource, input_timestamp], outputs=[output_activity, output_resource, output_timestamp])\n",
    "    model.compile(\n",
    "        optimizer='adam', \n",
    "        loss={\n",
    "            'output_activity': 'categorical_crossentropy', \n",
    "            'output_resource': 'categorical_crossentropy',\n",
    "            'output_timestamp': 'mse'\n",
    "        },\n",
    "        metrics={\n",
    "            'output_activity': ['accuracy'], \n",
    "            'output_resource': ['accuracy'],\n",
    "            'output_timestamp': ['mse']\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Parameters\n",
    "gru_units = int(2 * E) \n",
    "num_activities = dataframe_log['concept:name'].max()\n",
    "num_resources = dataframe_log['org:resource'].max()\n",
    "embedding_dim = 50\n",
    "dropout_rate = 0.2\n",
    "model = create_binetv3(num_activities, num_resources, embedding_dim, gru_units, dropout_rate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data for the resource attribute\n",
    "train_resource, test_resource, train_targets_resource, test_targets_resource = train_test_split(\n",
    "    windows_resource, targets_resource, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the data for the activity attribute\n",
    "train_activity, test_activity, train_targets_activity, test_targets_activity = train_test_split(\n",
    "    windows_activity, targets_activity, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the data for the timestamp attribute\n",
    "train_timestamp, test_timestamp, train_targets_timestamp, test_targets_timestamp = train_test_split(\n",
    "    windows_timestamp, targets_timestamp, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_targets_resource_cat = to_categorical(train_targets_resource, num_classes=num_resources + 1)\n",
    "test_targets_resource_cat = to_categorical(test_targets_resource, num_classes=num_resources + 1)\n",
    "\n",
    "train_targets_activity_cat = to_categorical(train_targets_activity, num_classes=num_activities + 1)\n",
    "test_targets_activity_cat = to_categorical(test_targets_activity, num_classes=num_activities + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "73/73 [==============================] - 22s 127ms/step - loss: 3.6940 - output_activity_loss: 2.2184 - output_resource_loss: 1.3436 - output_timestamp_loss: 0.1320 - output_activity_accuracy: 0.4576 - output_resource_accuracy: 0.6335 - output_timestamp_mse: 0.1320 - val_loss: 7.5321 - val_output_activity_loss: 2.6829 - val_output_resource_loss: 1.7138 - val_output_timestamp_loss: 3.1354 - val_output_activity_accuracy: 0.4225 - val_output_resource_accuracy: 0.5478 - val_output_timestamp_mse: 3.1354\n",
      "Epoch 2/20\n",
      "73/73 [==============================] - 5s 73ms/step - loss: 1.6827 - output_activity_loss: 0.8703 - output_resource_loss: 0.6698 - output_timestamp_loss: 0.1426 - output_activity_accuracy: 0.8447 - output_resource_accuracy: 0.8074 - output_timestamp_mse: 0.1426 - val_loss: 6.4065 - val_output_activity_loss: 2.0754 - val_output_resource_loss: 1.2360 - val_output_timestamp_loss: 3.0952 - val_output_activity_accuracy: 0.8506 - val_output_resource_accuracy: 0.5525 - val_output_timestamp_mse: 3.0952\n",
      "Epoch 3/20\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 1.2622 - output_activity_loss: 0.5694 - output_resource_loss: 0.5977 - output_timestamp_loss: 0.0950 - output_activity_accuracy: 0.8934 - output_resource_accuracy: 0.8190 - output_timestamp_mse: 0.0950 - val_loss: 5.5178 - val_output_activity_loss: 1.4749 - val_output_resource_loss: 0.9759 - val_output_timestamp_loss: 3.0670 - val_output_activity_accuracy: 0.8750 - val_output_resource_accuracy: 0.5535 - val_output_timestamp_mse: 3.0670\n",
      "Epoch 4/20\n",
      "73/73 [==============================] - 8s 109ms/step - loss: 1.1368 - output_activity_loss: 0.4985 - output_resource_loss: 0.5760 - output_timestamp_loss: 0.0624 - output_activity_accuracy: 0.8992 - output_resource_accuracy: 0.8176 - output_timestamp_mse: 0.0624 - val_loss: 4.8540 - val_output_activity_loss: 0.9988 - val_output_resource_loss: 0.8060 - val_output_timestamp_loss: 3.0491 - val_output_activity_accuracy: 0.8917 - val_output_resource_accuracy: 0.6558 - val_output_timestamp_mse: 3.0491\n",
      "Epoch 5/20\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 1.0844 - output_activity_loss: 0.4708 - output_resource_loss: 0.5652 - output_timestamp_loss: 0.0484 - output_activity_accuracy: 0.9010 - output_resource_accuracy: 0.8182 - output_timestamp_mse: 0.0484 - val_loss: 4.3495 - val_output_activity_loss: 0.6786 - val_output_resource_loss: 0.6417 - val_output_timestamp_loss: 3.0292 - val_output_activity_accuracy: 0.8971 - val_output_resource_accuracy: 0.7968 - val_output_timestamp_mse: 3.0292\n",
      "Epoch 6/20\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 1.0412 - output_activity_loss: 0.4475 - output_resource_loss: 0.5530 - output_timestamp_loss: 0.0407 - output_activity_accuracy: 0.9029 - output_resource_accuracy: 0.8209 - output_timestamp_mse: 0.0407 - val_loss: 4.1099 - val_output_activity_loss: 0.5112 - val_output_resource_loss: 0.5850 - val_output_timestamp_loss: 3.0137 - val_output_activity_accuracy: 0.9013 - val_output_resource_accuracy: 0.8019 - val_output_timestamp_mse: 3.0137\n",
      "Epoch 7/20\n",
      "73/73 [==============================] - 6s 77ms/step - loss: 1.0168 - output_activity_loss: 0.4335 - output_resource_loss: 0.5450 - output_timestamp_loss: 0.0383 - output_activity_accuracy: 0.9043 - output_resource_accuracy: 0.8213 - output_timestamp_mse: 0.0383 - val_loss: 3.9734 - val_output_activity_loss: 0.4456 - val_output_resource_loss: 0.5318 - val_output_timestamp_loss: 2.9961 - val_output_activity_accuracy: 0.8987 - val_output_resource_accuracy: 0.8216 - val_output_timestamp_mse: 2.9961\n",
      "Epoch 8/20\n",
      "73/73 [==============================] - 5s 75ms/step - loss: 0.9968 - output_activity_loss: 0.4226 - output_resource_loss: 0.5383 - output_timestamp_loss: 0.0359 - output_activity_accuracy: 0.9058 - output_resource_accuracy: 0.8220 - output_timestamp_mse: 0.0359 - val_loss: 3.9286 - val_output_activity_loss: 0.4182 - val_output_resource_loss: 0.5203 - val_output_timestamp_loss: 2.9901 - val_output_activity_accuracy: 0.9033 - val_output_resource_accuracy: 0.8252 - val_output_timestamp_mse: 2.9901\n",
      "Epoch 9/20\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.9831 - output_activity_loss: 0.4136 - output_resource_loss: 0.5348 - output_timestamp_loss: 0.0347 - output_activity_accuracy: 0.9048 - output_resource_accuracy: 0.8239 - output_timestamp_mse: 0.0347 - val_loss: 3.9018 - val_output_activity_loss: 0.4023 - val_output_resource_loss: 0.5136 - val_output_timestamp_loss: 2.9859 - val_output_activity_accuracy: 0.9047 - val_output_resource_accuracy: 0.8253 - val_output_timestamp_mse: 2.9859\n",
      "Epoch 10/20\n",
      "73/73 [==============================] - 6s 76ms/step - loss: 0.9667 - output_activity_loss: 0.4038 - output_resource_loss: 0.5299 - output_timestamp_loss: 0.0330 - output_activity_accuracy: 0.9056 - output_resource_accuracy: 0.8226 - output_timestamp_mse: 0.0330 - val_loss: 3.8935 - val_output_activity_loss: 0.3987 - val_output_resource_loss: 0.5160 - val_output_timestamp_loss: 2.9789 - val_output_activity_accuracy: 0.9045 - val_output_resource_accuracy: 0.8251 - val_output_timestamp_mse: 2.9789\n",
      "Epoch 11/20\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.9578 - output_activity_loss: 0.3967 - output_resource_loss: 0.5289 - output_timestamp_loss: 0.0321 - output_activity_accuracy: 0.9067 - output_resource_accuracy: 0.8242 - output_timestamp_mse: 0.0321 - val_loss: 3.8764 - val_output_activity_loss: 0.3911 - val_output_resource_loss: 0.5113 - val_output_timestamp_loss: 2.9740 - val_output_activity_accuracy: 0.9065 - val_output_resource_accuracy: 0.8262 - val_output_timestamp_mse: 2.9740\n",
      "Epoch 12/20\n",
      "73/73 [==============================] - 7s 99ms/step - loss: 0.9480 - output_activity_loss: 0.3909 - output_resource_loss: 0.5260 - output_timestamp_loss: 0.0311 - output_activity_accuracy: 0.9077 - output_resource_accuracy: 0.8253 - output_timestamp_mse: 0.0311 - val_loss: 3.8717 - val_output_activity_loss: 0.3911 - val_output_resource_loss: 0.5090 - val_output_timestamp_loss: 2.9716 - val_output_activity_accuracy: 0.9060 - val_output_resource_accuracy: 0.8261 - val_output_timestamp_mse: 2.9716\n",
      "Epoch 13/20\n",
      "73/73 [==============================] - 8s 109ms/step - loss: 0.9387 - output_activity_loss: 0.3852 - output_resource_loss: 0.5223 - output_timestamp_loss: 0.0312 - output_activity_accuracy: 0.9095 - output_resource_accuracy: 0.8257 - output_timestamp_mse: 0.0312 - val_loss: 3.8684 - val_output_activity_loss: 0.3841 - val_output_resource_loss: 0.5102 - val_output_timestamp_loss: 2.9740 - val_output_activity_accuracy: 0.9080 - val_output_resource_accuracy: 0.8262 - val_output_timestamp_mse: 2.9740\n",
      "Epoch 14/20\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.9318 - output_activity_loss: 0.3807 - output_resource_loss: 0.5205 - output_timestamp_loss: 0.0305 - output_activity_accuracy: 0.9087 - output_resource_accuracy: 0.8269 - output_timestamp_mse: 0.0305 - val_loss: 3.8641 - val_output_activity_loss: 0.3822 - val_output_resource_loss: 0.5078 - val_output_timestamp_loss: 2.9741 - val_output_activity_accuracy: 0.9079 - val_output_resource_accuracy: 0.8279 - val_output_timestamp_mse: 2.9741\n",
      "Epoch 15/20\n",
      "73/73 [==============================] - 6s 76ms/step - loss: 0.9219 - output_activity_loss: 0.3742 - output_resource_loss: 0.5176 - output_timestamp_loss: 0.0300 - output_activity_accuracy: 0.9114 - output_resource_accuracy: 0.8272 - output_timestamp_mse: 0.0300 - val_loss: 3.8623 - val_output_activity_loss: 0.3809 - val_output_resource_loss: 0.5102 - val_output_timestamp_loss: 2.9713 - val_output_activity_accuracy: 0.9093 - val_output_resource_accuracy: 0.8261 - val_output_timestamp_mse: 2.9713\n",
      "Epoch 16/20\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.9161 - output_activity_loss: 0.3732 - output_resource_loss: 0.5143 - output_timestamp_loss: 0.0286 - output_activity_accuracy: 0.9110 - output_resource_accuracy: 0.8276 - output_timestamp_mse: 0.0286 - val_loss: 3.8517 - val_output_activity_loss: 0.3761 - val_output_resource_loss: 0.5048 - val_output_timestamp_loss: 2.9707 - val_output_activity_accuracy: 0.9096 - val_output_resource_accuracy: 0.8283 - val_output_timestamp_mse: 2.9707\n",
      "Epoch 17/20\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.9109 - output_activity_loss: 0.3694 - output_resource_loss: 0.5127 - output_timestamp_loss: 0.0288 - output_activity_accuracy: 0.9119 - output_resource_accuracy: 0.8272 - output_timestamp_mse: 0.0288 - val_loss: 3.8720 - val_output_activity_loss: 0.3841 - val_output_resource_loss: 0.5155 - val_output_timestamp_loss: 2.9724 - val_output_activity_accuracy: 0.9067 - val_output_resource_accuracy: 0.8246 - val_output_timestamp_mse: 2.9724\n",
      "Epoch 18/20\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.9073 - output_activity_loss: 0.3651 - output_resource_loss: 0.5129 - output_timestamp_loss: 0.0292 - output_activity_accuracy: 0.9126 - output_resource_accuracy: 0.8279 - output_timestamp_mse: 0.0292 - val_loss: 3.8474 - val_output_activity_loss: 0.3709 - val_output_resource_loss: 0.5053 - val_output_timestamp_loss: 2.9711 - val_output_activity_accuracy: 0.9103 - val_output_resource_accuracy: 0.8268 - val_output_timestamp_mse: 2.9711\n",
      "Epoch 19/20\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.8948 - output_activity_loss: 0.3591 - output_resource_loss: 0.5074 - output_timestamp_loss: 0.0284 - output_activity_accuracy: 0.9141 - output_resource_accuracy: 0.8277 - output_timestamp_mse: 0.0284 - val_loss: 3.8398 - val_output_activity_loss: 0.3677 - val_output_resource_loss: 0.5006 - val_output_timestamp_loss: 2.9716 - val_output_activity_accuracy: 0.9110 - val_output_resource_accuracy: 0.8288 - val_output_timestamp_mse: 2.9716\n",
      "Epoch 20/20\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.8962 - output_activity_loss: 0.3598 - output_resource_loss: 0.5078 - output_timestamp_loss: 0.0285 - output_activity_accuracy: 0.9136 - output_resource_accuracy: 0.8302 - output_timestamp_mse: 0.0285 - val_loss: 3.8462 - val_output_activity_loss: 0.3704 - val_output_resource_loss: 0.5038 - val_output_timestamp_loss: 2.9720 - val_output_activity_accuracy: 0.9098 - val_output_resource_accuracy: 0.8270 - val_output_timestamp_mse: 2.9720\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [train_activity, train_resource, train_timestamp],\n",
    "    [train_targets_activity_cat, train_targets_resource_cat, train_targets_timestamp],\n",
    "    validation_data=([test_activity, test_resource, test_timestamp], [test_targets_activity_cat, test_targets_resource_cat, test_targets_timestamp]),\n",
    "    epochs=20,\n",
    "    batch_size=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 1s 4ms/step - loss: 3.8462 - output_activity_loss: 0.3704 - output_resource_loss: 0.5038 - output_timestamp_loss: 2.9720 - output_activity_accuracy: 0.9098 - output_resource_accuracy: 0.8270 - output_timestamp_mse: 2.9720\n",
      "Validation Loss: 3.8461644649505615, Validation Accuracy: 0.37037670612335205\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "results = model.evaluate(\n",
    "    [test_activity, test_resource, test_timestamp],\n",
    "    [test_targets_activity_cat, test_targets_resource_cat, test_targets_timestamp],\n",
    "    batch_size=64\n",
    ")\n",
    "print(f\"Validation Loss: {results[0]}, Validation Accuracy: {results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model to an H5 file\n",
    "model.save('binetv3_paper.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Score Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each event attribute, BINet's softmax layer outputs a probability distribution over possible values\n",
    "- The anomaly score for a specific attribute value v is calculated by summing all the probabilities from the softmax output that are greater than the probability assigned to v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1620/1620 [==============================] - 9s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for all inputs\n",
    "predictions = model.predict([windows_activity, windows_resource, windows_timestamp])\n",
    "\n",
    "\n",
    "# Extract predictions for categorical attributes (softmax probabilities)\n",
    "predictions_activity = predictions[0]\n",
    "predictions_resource = predictions[1]\n",
    "predictions_timestamp = predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_anomaly_scores(predictions, targets):\n",
    "    scores = []\n",
    "    # Loop through each example in the predictions\n",
    "    for i in range(predictions.shape[0]):\n",
    "        actual_prob = predictions[i, targets[i]]  # Extract the probability of the true class using target index\n",
    "        # Calculate anomaly score as sum of probabilities greater than the probability of the actual value\n",
    "        anomaly_score = np.sum(predictions[i][predictions[i] > actual_prob])\n",
    "        scores.append(anomaly_score)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate anomaly scores for each attribute type\n",
    "anomaly_scores_resource = calculate_anomaly_scores(predictions_resource, targets_resource.astype(int))\n",
    "anomaly_scores_activity = calculate_anomaly_scores(predictions_activity, targets_activity.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_anomaly_scores_continuous(predictions, actuals):\n",
    "    # Calculate absolute differences\n",
    "    differences = np.abs(predictions - actuals)\n",
    "    \n",
    "    # Normalize to [0, 1] range\n",
    "    max_diff = np.max(differences)\n",
    "    normalized_scores = differences / max_diff if max_diff != 0 else differences\n",
    "    \n",
    "    return normalized_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_scores_timestamp = compute_anomaly_scores_continuous(predictions_timestamp, targets_timestamp)\n",
    "anomaly_scores_timestamp = anomaly_scores_timestamp.flatten()\n",
    "anomaly_scores_timestamp = anomaly_scores_timestamp.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert missing scores for cases with less than 2 Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>score_resource</th>\n",
       "      <th>score_activity</th>\n",
       "      <th>score_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.436153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.648809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51809</th>\n",
       "      <td>4999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51810</th>\n",
       "      <td>4999</td>\n",
       "      <td>0.897797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51811</th>\n",
       "      <td>4999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51812</th>\n",
       "      <td>4999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51813</th>\n",
       "      <td>4999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51814 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       case  score_resource  score_activity  score_timestamp\n",
       "0         0        0.000000             0.0         0.000182\n",
       "1         0        0.436153             0.0         0.000617\n",
       "2         0        0.648809             0.0         0.000197\n",
       "3         0        0.000000             0.0         0.000520\n",
       "4         0        0.000000             0.0         0.000274\n",
       "...     ...             ...             ...              ...\n",
       "51809  4999        0.000000             0.0         0.000116\n",
       "51810  4999        0.897797             0.0         0.000061\n",
       "51811  4999        0.000000             0.0         0.000182\n",
       "51812  4999        0.000000             0.0         0.000170\n",
       "51813  4999        0.000000             0.0         0.000222\n",
       "\n",
       "[51814 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the case_indices_array corresponding to case_resource\n",
    "score = pd.DataFrame({'case': case_indices})\n",
    "score['score_resource'] = anomaly_scores_resource\n",
    "score['score_activity'] = anomaly_scores_activity\n",
    "score['score_timestamp'] = anomaly_scores_timestamp\n",
    "\n",
    "score['case'] = score['case'].astype(int)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the 'case' column contain all values between 0 and 4999? True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def contains_all_values(df, column, end):\n",
    "\n",
    "    # Generate the set of all values in the specified range\n",
    "    required_values = set(range(0, end + 1))\n",
    "    \n",
    "    # Get the unique values in the specified column\n",
    "    column_values = set(df[column].unique())\n",
    "    \n",
    "    # Find missing values\n",
    "    missing_values = required_values - column_values\n",
    "    \n",
    "    # Print missing values if any\n",
    "    if missing_values:\n",
    "        print(f\"Missing values: {sorted(missing_values)}\")\n",
    "    \n",
    "    # Check if all required values are in the column values\n",
    "    return required_values.issubset(column_values)\n",
    "\n",
    "end = 4999\n",
    "\n",
    "result = contains_all_values(score, 'case', end)\n",
    "print(f\"Does the 'case' column contain all values between 0 and {end}? {result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold (lowest plateau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_anomaly_ratio(scores, threshold):\n",
    "    \"\"\"\n",
    "    Calculate the anomaly ratio for a given threshold.\n",
    "    \"\"\"\n",
    "    return np.mean(scores > threshold)\n",
    "\n",
    "def find_plateaus(scores, epsilon=1e-4, min_plateau_length=10):\n",
    "    \"\"\"\n",
    "    Identify the lowest plateau in the anomaly ratio function and calculate the mean-centered threshold.\n",
    "    \"\"\"\n",
    "    scores = np.array(scores)  # Convert scores to a NumPy array\n",
    "    sorted_scores = np.sort(scores)\n",
    "    \n",
    "    # Remove duplicate values\n",
    "    unique_thresholds, unique_indices = np.unique(sorted_scores, return_index=True)\n",
    "    anomaly_ratios = np.array([calculate_anomaly_ratio(scores, t) for t in unique_thresholds])\n",
    "    \n",
    "    # Calculate first and second derivatives\n",
    "    first_derivatives = np.diff(anomaly_ratios) / np.diff(unique_thresholds)\n",
    "    second_derivatives = np.diff(first_derivatives) / np.diff(unique_thresholds[:-1])\n",
    "    \n",
    "    # Identify plateaus where the first derivative is close to zero\n",
    "    plateau_indices = np.where(np.abs(first_derivatives) < epsilon)[0]\n",
    "    \n",
    "    # Group consecutive indices to identify continuous plateaus\n",
    "    grouped_plateaus = np.split(plateau_indices, np.where(np.diff(plateau_indices) != 1)[0] + 1)\n",
    "    \n",
    "    # Filter plateaus based on minimum length\n",
    "    long_plateaus = [g for g in grouped_plateaus if len(g) >= min_plateau_length]\n",
    "    \n",
    "    if long_plateaus:\n",
    "        # Take the first long plateau and find the mean threshold in this plateau\n",
    "        first_plateau = long_plateaus[0]\n",
    "        plateau_thresholds = unique_thresholds[first_plateau]\n",
    "        return np.mean(plateau_thresholds)\n",
    "    else:\n",
    "        # If no plateau is found, return a default value, e.g., the 90th percentile\n",
    "        percentile_90 = np.percentile(sorted_scores, 90)\n",
    "        if percentile_90 == 1.0:\n",
    "            return 0.4\n",
    "        else:\n",
    "            return percentile_90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_resource = find_plateaus(anomaly_scores_resource)\n",
    "threshold_activity = find_plateaus(anomaly_scores_activity)\n",
    "threshold_timestamp = find_plateaus(anomaly_scores_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(anomaly_scores, threshold):\n",
    "    labels = [1 if score > threshold else 0 for score in anomaly_scores]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect anomalies based on the calculated anomaly scores and thresholds\n",
    "labels_resource = detect_anomalies(anomaly_scores_resource, threshold_resource)\n",
    "labels_activity = detect_anomalies(anomaly_scores_activity, threshold_activity)\n",
    "labels_timestamp = detect_anomalies(anomaly_scores_timestamp, threshold_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>predicted_resource</th>\n",
       "      <th>predicted_activity</th>\n",
       "      <th>predicted_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51809</th>\n",
       "      <td>4999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51810</th>\n",
       "      <td>4999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51811</th>\n",
       "      <td>4999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51812</th>\n",
       "      <td>4999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51813</th>\n",
       "      <td>4999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51814 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       case  predicted_resource  predicted_activity  predicted_timestamp\n",
       "0         0                   0                   0                    0\n",
       "1         0                   0                   0                    0\n",
       "2         0                   0                   0                    0\n",
       "3         0                   0                   0                    0\n",
       "4         0                   0                   0                    0\n",
       "...     ...                 ...                 ...                  ...\n",
       "51809  4999                   0                   0                    0\n",
       "51810  4999                   1                   0                    0\n",
       "51811  4999                   0                   0                    0\n",
       "51812  4999                   0                   0                    0\n",
       "51813  4999                   0                   0                    0\n",
       "\n",
       "[51814 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the case_indices_array corresponding to case_resource\n",
    "mapping = pd.DataFrame({'case': case_indices})\n",
    "mapping['predicted_resource'] = labels_resource\n",
    "mapping['predicted_activity'] = labels_activity\n",
    "mapping['predicted_timestamp'] = labels_timestamp\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case\n",
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "        ... \n",
       "4995    True\n",
       "4996    True\n",
       "4997    True\n",
       "4998    True\n",
       "4999    True\n",
       "Length: 5000, dtype: bool"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a boolean DataFrame where each value is True if the value is 1\n",
    "contains_one = (mapping[['predicted_resource', 'predicted_activity', 'predicted_timestamp']] == 1)\n",
    "\n",
    "# Group by 'case' and check if there's at least one 'True' in any of the columns\n",
    "case_prediction = contains_one.groupby(mapping['case']).any().any(axis=1)\n",
    "case_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case\n",
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3        True\n",
       "4       False\n",
       "        ...  \n",
       "4995     True\n",
       "4996     True\n",
       "4997     True\n",
       "4998     True\n",
       "4999     True\n",
       "Length: 5000, dtype: bool"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a boolean DataFrame where each value is True if the value is 1\n",
    "contains_one = (mapping[['predicted_activity']] == 1)\n",
    "\n",
    "# Group by 'case' and check if there's at least one 'True' in any of the columns\n",
    "case_prediction = contains_one.groupby(mapping['case']).any().any(axis=1)\n",
    "case_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking):\n",
    "    from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments\n",
    "    from pm4py.algo.conformance.alignments.petri_net import variants\n",
    "    from pm4py.objects.petri_net.utils import align_utils\n",
    "    max_events=0\n",
    "    for trace in log:\n",
    "        counter=0\n",
    "        for event in trace:\n",
    "            counter+=1\n",
    "        if counter > max_events:\n",
    "            max_events=counter\n",
    "    parameters={}\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_SYNC_COST_FUNCTION] = list(map(lambda i: .1*i, range(max_events*2)))\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_TRACE_COST_FUNCTION]=list(map(lambda i: align_utils.STD_MODEL_LOG_MOVE_COST-.1*i, range(max_events*2)))\n",
    "    aligned_traces = alignments.apply_log(log, net, initial_marking, final_marking, variant=variants.state_equation_a_star, parameters=parameters)\n",
    "    return aligned_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c2b56f3d6f4584a2379986b752405b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/model/binet_paper.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_traces = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conformance_status_by_fitness(aligned_traces):\n",
    "    conformance_status = []\n",
    "    for alignment in aligned_traces:\n",
    "        fitness = alignment['fitness']\n",
    "        # If the fitness is 1.0, the trace is conforming\n",
    "        if fitness == 1.0:\n",
    "            conformance_status.append(1)\n",
    "        else:\n",
    "            conformance_status.append(0)\n",
    "    return conformance_status\n",
    "\n",
    "# Get the conformance status list from the aligned traces\n",
    "conformance = extract_conformance_status_by_fitness(aligned_traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conformity</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      conformity  predicted\n",
       "0              1          1\n",
       "1              1          1\n",
       "2              1          1\n",
       "3              1          0\n",
       "4              0          1\n",
       "...          ...        ...\n",
       "4995           0          0\n",
       "4996           0          0\n",
       "4997           0          0\n",
       "4998           0          0\n",
       "4999           0          0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = pd.DataFrame({'conformity': conformance})\n",
    "ground_truth['predicted'] = case_prediction\n",
    "\n",
    "# Convert False to 0 and True to 1\n",
    "ground_truth['predicted'] = [int(value) for value in ground_truth['predicted']]\n",
    "ground_truth['predicted'] = 1 - ground_truth['predicted']\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating TP, TN, FP, FN\n",
    "TP = ((ground_truth['conformity'] == 1) & (ground_truth['predicted'] == 1)).sum()\n",
    "TN = ((ground_truth['conformity'] == 0) & (ground_truth['predicted'] == 0)).sum()\n",
    "FP = ((ground_truth['conformity'] == 0) & (ground_truth['predicted'] == 1)).sum()\n",
    "FN = ((ground_truth['conformity'] == 1) & (ground_truth['predicted'] == 0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.669\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.668\n"
     ]
    }
   ],
   "source": [
    "# Calculate f1\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "print(f\"F1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev (Non Conform Traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.623\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision for Dev\n",
    "precision = TN / (TN + FN)\n",
    "print(f\"Precision: {precision:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.728\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall for Dev\n",
    "recall = TN / (TN + FP)\n",
    "print(f\"Recall: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Dev (Conform Traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.725\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision for No Dev\n",
    "precision = TP / (TP + FP)\n",
    "print(f\"Precision: {precision:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.619\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall for No Dev\n",
    "recall = TP / (TP + FN)\n",
    "print(f\"Recall: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6733741000377865"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Assuming ground_truth is your DataFrame\n",
    "# Make sure 'conformity' contains actual labels (0 or 1)\n",
    "# and 'predicted' contains predicted probabilities or scores\n",
    "auc_roc = roc_auc_score(ground_truth['conformity'], ground_truth['predicted'])\n",
    "auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
