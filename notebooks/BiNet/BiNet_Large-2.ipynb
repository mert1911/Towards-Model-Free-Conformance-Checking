{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Event Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"     # Format the dataframe\\n    dataframe_log = pm4py.format_dataframe(\\n        dataframe_log,\\n        case_id='case:concept:name',\\n        activity_key='concept:name',\\n        timestamp_key='time:timestamp'\\n    )\\n\\n    # Convert the dataframe to event log\\n    log = log_converter.apply(dataframe_log) \""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the CSV file\n",
    "    dataframe_log = pd.read_csv('../../data/extra_logs/large-0.3-2.csv', sep=',')\n",
    "\n",
    "\n",
    "\"\"\"     # Format the dataframe\n",
    "    dataframe_log = pm4py.format_dataframe(\n",
    "        dataframe_log,\n",
    "        case_id='case:concept:name',\n",
    "        activity_key='concept:name',\n",
    "        timestamp_key='time:timestamp'\n",
    "    )\n",
    "\n",
    "    # Convert the dataframe to event log\n",
    "    log = log_converter.apply(dataframe_log) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>timestamp_end</th>\n",
       "      <th>anomaly</th>\n",
       "      <th>trace_id</th>\n",
       "      <th>day</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Activity A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Johnny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Activity Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Activity R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Della</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Activity S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Elisha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Activity T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Frances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51784</th>\n",
       "      <td>Activity U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>5000</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Josef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51785</th>\n",
       "      <td>Activity V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>5000</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Donald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51786</th>\n",
       "      <td>Activity X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>5000</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Johnny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51787</th>\n",
       "      <td>Activity W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>5000</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Gema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51788</th>\n",
       "      <td>Activity B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>5000</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Sharee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51789 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  timestamp  timestamp_end anomaly  trace_id        day  \\\n",
       "0      Activity A        NaN            NaN  normal         1  Wednesday   \n",
       "1      Activity Q        NaN            NaN  normal         1   Thursday   \n",
       "2      Activity R        NaN            NaN  normal         1     Friday   \n",
       "3      Activity S        NaN            NaN  normal         1     Monday   \n",
       "4      Activity T        NaN            NaN  normal         1   Thursday   \n",
       "...           ...        ...            ...     ...       ...        ...   \n",
       "51784  Activity U        NaN            NaN  normal      5000     Friday   \n",
       "51785  Activity V        NaN            NaN  normal      5000     Monday   \n",
       "51786  Activity X        NaN            NaN  normal      5000     Friday   \n",
       "51787  Activity W        NaN            NaN  normal      5000    Tuesday   \n",
       "51788  Activity B        NaN            NaN  normal      5000     Monday   \n",
       "\n",
       "          user  \n",
       "0       Johnny  \n",
       "1      Charles  \n",
       "2        Della  \n",
       "3       Elisha  \n",
       "4      Frances  \n",
       "...        ...  \n",
       "51784    Josef  \n",
       "51785   Donald  \n",
       "51786   Johnny  \n",
       "51787     Gema  \n",
       "51788   Sharee  \n",
       "\n",
       "[51789 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop unnessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_log = dataframe_log.drop(columns=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_log = dataframe_log.drop(columns=['timestamp_end'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(dataframe_log['name'])\n",
    "dataframe_log['name'] = codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(dataframe_log['day'])\n",
    "dataframe_log['day'] = codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(dataframe_log['user'])\n",
    "dataframe_log['user'] = codes + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = dataframe_log.groupby('trace_id').size().max()\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by trace_id and process each group\n",
    "def pad_trace_id(group, max_length):\n",
    "    if len(group) < max_length:\n",
    "        num_rows_to_add = max_length - len(group)\n",
    "        # Create new rows with zero values and replicate the trace_id\n",
    "        additional_rows = pd.DataFrame({col: [0] * num_rows_to_add for col in group.columns})\n",
    "        additional_rows['trace_id'] = group['trace_id'].iloc[0]\n",
    "        # Append the new rows to the original group\n",
    "        group = pd.concat([group, additional_rows], ignore_index=True)\n",
    "    return group\n",
    "\n",
    "dataframe_log = dataframe_log.groupby('trace_id').apply(pad_trace_id, max_length=max_length).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>anomaly</th>\n",
       "      <th>trace_id</th>\n",
       "      <th>day</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>SkipSequence</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11</td>\n",
       "      <td>SkipSequence</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12</td>\n",
       "      <td>SkipSequence</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13</td>\n",
       "      <td>SkipSequence</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14</td>\n",
       "      <td>SkipSequence</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name       anomaly  trace_id  day  user\n",
       "0      1        normal         1    1     1\n",
       "1      2        normal         1    2     2\n",
       "2      3        normal         1    3     3\n",
       "3      4        normal         1    4     4\n",
       "4      5        normal         1    2     5\n",
       "5      6        normal         1    1     2\n",
       "6      7        normal         1    4     6\n",
       "7      8        normal         1    3     7\n",
       "8      9        normal         1    2     8\n",
       "9     10        normal         1    2     9\n",
       "10     0             0         1    0     0\n",
       "11     0             0         1    0     0\n",
       "12     0             0         1    0     0\n",
       "13     0             0         1    0     0\n",
       "14     0             0         1    0     0\n",
       "15     1  SkipSequence         2    2    10\n",
       "16    11  SkipSequence         2    1    11\n",
       "17    12  SkipSequence         2    4    12\n",
       "18    13  SkipSequence         2    2    13\n",
       "19    14  SkipSequence         2    4    14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_log.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>anomaly</th>\n",
       "      <th>trace_id</th>\n",
       "      <th>day</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>SkipSequence</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11</td>\n",
       "      <td>SkipSequence</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12</td>\n",
       "      <td>SkipSequence</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13</td>\n",
       "      <td>SkipSequence</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14</td>\n",
       "      <td>SkipSequence</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name       anomaly  trace_id  day  user\n",
       "0      1        normal         1    1     1\n",
       "1      2        normal         1    2     2\n",
       "2      3        normal         1    3     3\n",
       "3      4        normal         1    4     4\n",
       "4      5        normal         1    2     5\n",
       "5      6        normal         1    1     2\n",
       "6      7        normal         1    4     6\n",
       "7      8        normal         1    3     7\n",
       "8      9        normal         1    2     8\n",
       "9     10        normal         1    2     9\n",
       "10     0        normal         1    0     0\n",
       "11     0        normal         1    0     0\n",
       "12     0        normal         1    0     0\n",
       "13     0        normal         1    0     0\n",
       "14     0        normal         1    0     0\n",
       "15     1  SkipSequence         2    2    10\n",
       "16    11  SkipSequence         2    1    11\n",
       "17    12  SkipSequence         2    4    12\n",
       "18    13  SkipSequence         2    2    13\n",
       "19    14  SkipSequence         2    4    14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing all zero values in the 'anomaly' column with \"normal\"\n",
    "dataframe_log['anomaly'] = dataframe_log['anomaly'].replace(0, 'normal')\n",
    "\n",
    "dataframe_log.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activity = dataframe_log[['name', 'trace_id']]\n",
    "df_day = dataframe_log[['day', 'trace_id']]\n",
    "df_user = dataframe_log[['user', 'trace_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 19:20:40.196797: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def generate_prefix_windows(df, case_id_column='trace_id', max_len=None, dtype='int32'):\n",
    "    windows = []\n",
    "    targets = []\n",
    "    case_indices = []\n",
    "\n",
    "    for case_id in df[case_id_column].unique():\n",
    "        case_data = df[df[case_id_column] == case_id].drop(columns=[case_id_column]).to_numpy()\n",
    "        \n",
    "        # Optional: Make sure to sort the case data if there's an implicit order (e.g., by timestamps)\n",
    "        # case_data = case_data.sort_values(by='timestamp_column').to_numpy()  # Uncomment and adjust if needed\n",
    "        \n",
    "        for i in range(1, len(case_data)):\n",
    "            window = case_data[:i]\n",
    "            target = case_data[i]\n",
    "            windows.append(window.flatten())  # Flatten because we no longer want one-hot encoding\n",
    "            targets.append(target[0])  # Assume that the target is the first element (activity)\n",
    "            case_indices.append(case_id)  # Store the case_id corresponding to the window\n",
    "\n",
    "    if max_len is None:\n",
    "        max_len = max(len(window) for window in windows)\n",
    "    windows_padded = pad_sequences(windows, maxlen=max_len, padding='post', dtype=dtype)\n",
    "\n",
    "    # Ensure targets and case_indices are numpy arrays\n",
    "    targets_array = np.array(targets, dtype=dtype)\n",
    "    case_indices_array = np.array(case_indices, dtype=dtype)\n",
    "\n",
    "    # Check for length consistency\n",
    "    assert len(windows_padded) == len(targets_array) == len(case_indices_array), \\\n",
    "        \"Length of windows, targets, and case indices arrays must be equal.\"\n",
    "\n",
    "    return np.array(windows_padded), targets_array, case_indices_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_activity, targets_activity, case_indices = generate_prefix_windows(df_activity)\n",
    "windows_day, targets_day, case_indices = generate_prefix_windows(df_day)\n",
    "windows_user, targets_user, case_indices = generate_prefix_windows(df_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 2, 0, ..., 0, 0, 0],\n",
       "       [1, 2, 3, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 2, 3, ..., 0, 0, 0],\n",
       "       [1, 2, 3, ..., 0, 0, 0],\n",
       "       [1, 2, 3, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4, ..., 23,  9, 10], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separate Inputs for Each Attribute\n",
    "- Each attribute is passed through an embedding layer\n",
    "- Each attribute has its corresponding GRU encoder\n",
    "- Selective Concatenation: After encoding, the outputs of these GRU layers are concatenated. However, this concatenation is selective, meaning it is structured in a way that prepares the data for effective synthesis without leaking information from the future (next event attributes)\n",
    "- Decoder GRUs: Integrated Decoding: Post-concatenation, the combined attributes are processed through decoder GRU layers. These layers are tasked with integrating the data from different attributes and preparing it for final prediction. This step is where BINet v3 distinguishes itself by effectively using the interdependencies between different attributes to enhance prediction accuracy.\n",
    "- Output Layer: Softmax Output for Each Attribute: For each attribute of the next event, a softmax layer predicts a probability distribution over all possible values. This allows the model to output the most likely next event and its attributes based on the learned dependencies and the history encoded by the GRUs.\n",
    "- E: maximum case length\n",
    "- We train BINet with a GRU size of 2E (two times the maximum case length)\n",
    "- on mini batches of size 500 for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the @@case_index column and count the rows in each group\n",
    "case_lengths = dataframe_log.groupby('trace_id').size()\n",
    "\n",
    "# Find the maximum value among the case lengths\n",
    "E = case_lengths.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " activity_input (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " day_input (InputLayer)      [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " user_input (InputLayer)     [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " activity_embedding (Embedd  (None, None, 50)             4200      ['activity_input[0][0]']      \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " day_embedding (Embedding)   (None, None, 50)             600       ['day_input[0][0]']           \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)  (None, None, 50)             7000      ['user_input[0][0]']          \n",
      "                                                                                                  \n",
      " activity_encoder (GRU)      (None, None, 30)             7380      ['activity_embedding[0][0]']  \n",
      "                                                                                                  \n",
      " day_encoder (GRU)           (None, None, 30)             7380      ['day_embedding[0][0]']       \n",
      "                                                                                                  \n",
      " user_encoder (GRU)          (None, None, 30)             7380      ['user_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " bn_activity (BatchNormaliz  (None, None, 30)             120       ['activity_encoder[0][0]']    \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " bn_day (BatchNormalization  (None, None, 30)             120       ['day_encoder[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_user (BatchNormalizatio  (None, None, 30)             120       ['user_encoder[0][0]']        \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_encodings (Con  (None, None, 90)             0         ['bn_activity[0][0]',         \n",
      " catenate)                                                           'bn_day[0][0]',              \n",
      "                                                                     'bn_user[0][0]']             \n",
      "                                                                                                  \n",
      " decoder_gru (GRU)           (None, 30)                   10980     ['concatenate_encodings[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 30)                   0         ['decoder_gru[0][0]']         \n",
      "                                                                                                  \n",
      " output_activity (Dense)     (None, 84)                   2604      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " output_day (Dense)          (None, 12)                   372       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " output_user (Dense)         (None, 140)                  4340      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 52596 (205.45 KB)\n",
      "Trainable params: 52416 (204.75 KB)\n",
      "Non-trainable params: 180 (720.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Embedding, Dense, Dropout, Concatenate, BatchNormalization\n",
    "\n",
    "def create_binetv3(num_activities, num_days, num_users, embedding_dim, gru_units, dropout_rate):\n",
    "    # Input layers for each attribute\n",
    "    input_activity = Input(shape=(None,), name='activity_input')\n",
    "    input_day = Input(shape=(None,), name='day_input')\n",
    "    input_user = Input(shape=(None,), name='user_input')\n",
    "\n",
    "    # Embedding layers for categorical attributes\n",
    "    embedding_activity = Embedding(input_dim=num_activities, output_dim=embedding_dim, name='activity_embedding')(input_activity)\n",
    "    embedding_day = Embedding(input_dim=num_days, output_dim=embedding_dim, name='day_embedding')(input_day)\n",
    "    embedding_user = Embedding(input_dim=num_users, output_dim=embedding_dim, name='user_embedding')(input_user)\n",
    "\n",
    "    # Encoder GRUs with Batch Normalization for categorical attributes\n",
    "    encoded_activity = GRU(units=gru_units, return_sequences=True, name='activity_encoder')(embedding_activity)\n",
    "    bn_activity = BatchNormalization(name='bn_activity')(encoded_activity)\n",
    "    encoded_day = GRU(units=gru_units, return_sequences=True, name='day_encoder')(embedding_day)\n",
    "    bn_day = BatchNormalization(name='bn_day')(encoded_day)\n",
    "    encoded_user = GRU(units=gru_units, return_sequences=True, name='user_encoder')(embedding_user)\n",
    "    bn_user = BatchNormalization(name='bn_user')(encoded_user)\n",
    "\n",
    "    # Concatenation of encoded outputs\n",
    "    concatenated = Concatenate(name='concatenate_encodings')([bn_activity, bn_day, bn_user])\n",
    "\n",
    "    # Decoder GRU\n",
    "    decoder_output = GRU(units=gru_units, return_sequences=False, name='decoder_gru')(concatenated)\n",
    "    dropout_layer = Dropout(rate=dropout_rate, name='dropout')(decoder_output)\n",
    "\n",
    "    # Output layers for predicting the next event's attributes\n",
    "    output_activity = Dense(num_activities, activation='softmax', name='output_activity')(dropout_layer)\n",
    "    output_day = Dense(num_days, activation='softmax', name='output_day')(dropout_layer)\n",
    "    output_user = Dense(num_users, activation='softmax', name='output_user')(dropout_layer)\n",
    "\n",
    "    # Building the model\n",
    "    model = Model(inputs=[input_activity, input_day, input_user], outputs=[output_activity, output_day, output_user])\n",
    "    model.compile(\n",
    "        optimizer='adam', \n",
    "        loss={\n",
    "            'output_activity': 'categorical_crossentropy', \n",
    "            'output_day': 'categorical_crossentropy',\n",
    "            'output_user': 'categorical_crossentropy'\n",
    "        },\n",
    "        metrics={\n",
    "            'output_activity': ['accuracy'], \n",
    "            'output_day': ['accuracy'],\n",
    "            'output_user': ['accuracy']\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Parameters\n",
    "gru_units = int(2 * E) \n",
    "num_activities = dataframe_log['name'].nunique() +1 \n",
    "num_days = dataframe_log['day'].nunique() + 1\n",
    "num_users = dataframe_log['user'].nunique() +1\n",
    "embedding_dim = 50\n",
    "dropout_rate = 0.2\n",
    "model = create_binetv3(num_activities, num_days, num_users, embedding_dim, gru_units, dropout_rate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data for the activity attribute\n",
    "train_activity, test_activity, train_targets_activity, test_targets_activity = train_test_split(\n",
    "    windows_activity, targets_activity, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the data for the day attribute\n",
    "train_day, test_day, train_targets_day, test_targets_day = train_test_split(\n",
    "    windows_day, targets_day, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the data for the user attribute\n",
    "train_user, test_user, train_targets_user, test_targets_user = train_test_split(\n",
    "    windows_user, targets_user, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert targets to categorical format\n",
    "train_targets_activity_cat = to_categorical(train_targets_activity, num_classes=num_activities)\n",
    "test_targets_activity_cat = to_categorical(test_targets_activity, num_classes=num_activities)\n",
    "\n",
    "train_targets_day_cat = to_categorical(train_targets_day, num_classes=num_days)\n",
    "test_targets_day_cat = to_categorical(test_targets_day, num_classes=num_days)\n",
    "\n",
    "train_targets_user_cat = to_categorical(train_targets_user, num_classes=num_users)\n",
    "test_targets_user_cat = to_categorical(test_targets_user, num_classes=num_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "66/66 [==============================] - 15s 97ms/step - loss: 9.5165 - output_activity_loss: 3.5948 - output_day_loss: 1.8250 - output_user_loss: 4.0967 - output_activity_accuracy: 0.1192 - output_day_accuracy: 0.2943 - output_user_accuracy: 0.1160 - val_loss: 9.3027 - val_output_activity_loss: 3.4959 - val_output_day_loss: 1.7873 - val_output_user_loss: 4.0195 - val_output_activity_accuracy: 0.1897 - val_output_day_accuracy: 0.3566 - val_output_user_accuracy: 0.1483\n",
      "Epoch 2/20\n",
      "66/66 [==============================] - 5s 81ms/step - loss: 7.4966 - output_activity_loss: 2.5674 - output_day_loss: 1.6170 - output_user_loss: 3.3122 - output_activity_accuracy: 0.3240 - output_day_accuracy: 0.3577 - output_user_accuracy: 0.1810 - val_loss: 8.0783 - val_output_activity_loss: 2.9204 - val_output_day_loss: 1.6386 - val_output_user_loss: 3.5193 - val_output_activity_accuracy: 0.2817 - val_output_day_accuracy: 0.3281 - val_output_user_accuracy: 0.1827\n",
      "Epoch 3/20\n",
      "66/66 [==============================] - 6s 85ms/step - loss: 6.2308 - output_activity_loss: 1.8385 - output_day_loss: 1.5234 - output_user_loss: 2.8688 - output_activity_accuracy: 0.6219 - output_day_accuracy: 0.4210 - output_user_accuracy: 0.2658 - val_loss: 6.8384 - val_output_activity_loss: 2.2492 - val_output_day_loss: 1.5381 - val_output_user_loss: 3.0511 - val_output_activity_accuracy: 0.5353 - val_output_day_accuracy: 0.3479 - val_output_user_accuracy: 0.1889\n",
      "Epoch 4/20\n",
      "66/66 [==============================] - 5s 77ms/step - loss: 5.1586 - output_activity_loss: 1.2663 - output_day_loss: 1.4564 - output_user_loss: 2.4359 - output_activity_accuracy: 0.7755 - output_day_accuracy: 0.4558 - output_user_accuracy: 0.3993 - val_loss: 5.6497 - val_output_activity_loss: 1.6225 - val_output_day_loss: 1.4243 - val_output_user_loss: 2.6030 - val_output_activity_accuracy: 0.7202 - val_output_day_accuracy: 0.4351 - val_output_user_accuracy: 0.3821\n",
      "Epoch 5/20\n",
      "66/66 [==============================] - 5s 77ms/step - loss: 4.5273 - output_activity_loss: 0.9676 - output_day_loss: 1.3928 - output_user_loss: 2.1669 - output_activity_accuracy: 0.8448 - output_day_accuracy: 0.4792 - output_user_accuracy: 0.4516 - val_loss: 4.5997 - val_output_activity_loss: 1.0683 - val_output_day_loss: 1.3374 - val_output_user_loss: 2.1941 - val_output_activity_accuracy: 0.8172 - val_output_day_accuracy: 0.4988 - val_output_user_accuracy: 0.4616\n",
      "Epoch 6/20\n",
      "66/66 [==============================] - 5s 78ms/step - loss: 4.1446 - output_activity_loss: 0.7947 - output_day_loss: 1.3534 - output_user_loss: 1.9965 - output_activity_accuracy: 0.8731 - output_day_accuracy: 0.4837 - output_user_accuracy: 0.4692 - val_loss: 4.0123 - val_output_activity_loss: 0.7864 - val_output_day_loss: 1.2715 - val_output_user_loss: 1.9544 - val_output_activity_accuracy: 0.8638 - val_output_day_accuracy: 0.5098 - val_output_user_accuracy: 0.4919\n",
      "Epoch 7/20\n",
      "66/66 [==============================] - 5s 80ms/step - loss: 3.8613 - output_activity_loss: 0.6743 - output_day_loss: 1.3168 - output_user_loss: 1.8701 - output_activity_accuracy: 0.8914 - output_day_accuracy: 0.4907 - output_user_accuracy: 0.4880 - val_loss: 3.6324 - val_output_activity_loss: 0.6092 - val_output_day_loss: 1.2375 - val_output_user_loss: 1.7858 - val_output_activity_accuracy: 0.9054 - val_output_day_accuracy: 0.5235 - val_output_user_accuracy: 0.5158\n",
      "Epoch 8/20\n",
      "66/66 [==============================] - 5s 79ms/step - loss: 3.6669 - output_activity_loss: 0.5941 - output_day_loss: 1.2943 - output_user_loss: 1.7785 - output_activity_accuracy: 0.9047 - output_day_accuracy: 0.4948 - output_user_accuracy: 0.4969 - val_loss: 3.4396 - val_output_activity_loss: 0.5301 - val_output_day_loss: 1.2154 - val_output_user_loss: 1.6941 - val_output_activity_accuracy: 0.9189 - val_output_day_accuracy: 0.5255 - val_output_user_accuracy: 0.5202\n",
      "Epoch 9/20\n",
      "66/66 [==============================] - 5s 80ms/step - loss: 3.5191 - output_activity_loss: 0.5353 - output_day_loss: 1.2729 - output_user_loss: 1.7108 - output_activity_accuracy: 0.9152 - output_day_accuracy: 0.4991 - output_user_accuracy: 0.5046 - val_loss: 3.2799 - val_output_activity_loss: 0.4673 - val_output_day_loss: 1.1935 - val_output_user_loss: 1.6191 - val_output_activity_accuracy: 0.9295 - val_output_day_accuracy: 0.5280 - val_output_user_accuracy: 0.5347\n",
      "Epoch 10/20\n",
      "66/66 [==============================] - 8s 116ms/step - loss: 3.3939 - output_activity_loss: 0.4887 - output_day_loss: 1.2553 - output_user_loss: 1.6499 - output_activity_accuracy: 0.9258 - output_day_accuracy: 0.5051 - output_user_accuracy: 0.5151 - val_loss: 3.1846 - val_output_activity_loss: 0.4314 - val_output_day_loss: 1.1799 - val_output_user_loss: 1.5733 - val_output_activity_accuracy: 0.9340 - val_output_day_accuracy: 0.5262 - val_output_user_accuracy: 0.5428\n",
      "Epoch 11/20\n",
      "66/66 [==============================] - 25s 388ms/step - loss: 3.3020 - output_activity_loss: 0.4546 - output_day_loss: 1.2410 - output_user_loss: 1.6064 - output_activity_accuracy: 0.9316 - output_day_accuracy: 0.5055 - output_user_accuracy: 0.5222 - val_loss: 3.1091 - val_output_activity_loss: 0.4033 - val_output_day_loss: 1.1690 - val_output_user_loss: 1.5369 - val_output_activity_accuracy: 0.9350 - val_output_day_accuracy: 0.5307 - val_output_user_accuracy: 0.5451\n",
      "Epoch 12/20\n",
      "66/66 [==============================] - 9s 140ms/step - loss: 3.2367 - output_activity_loss: 0.4287 - output_day_loss: 1.2294 - output_user_loss: 1.5787 - output_activity_accuracy: 0.9351 - output_day_accuracy: 0.5103 - output_user_accuracy: 0.5238 - val_loss: 3.0560 - val_output_activity_loss: 0.3841 - val_output_day_loss: 1.1601 - val_output_user_loss: 1.5118 - val_output_activity_accuracy: 0.9384 - val_output_day_accuracy: 0.5404 - val_output_user_accuracy: 0.5466\n",
      "Epoch 13/20\n",
      "66/66 [==============================] - 7s 103ms/step - loss: 3.1801 - output_activity_loss: 0.4102 - output_day_loss: 1.2207 - output_user_loss: 1.5493 - output_activity_accuracy: 0.9379 - output_day_accuracy: 0.5169 - output_user_accuracy: 0.5311 - val_loss: 3.0153 - val_output_activity_loss: 0.3733 - val_output_day_loss: 1.1574 - val_output_user_loss: 1.4847 - val_output_activity_accuracy: 0.9394 - val_output_day_accuracy: 0.5307 - val_output_user_accuracy: 0.5486\n",
      "Epoch 14/20\n",
      "66/66 [==============================] - 6s 97ms/step - loss: 3.1318 - output_activity_loss: 0.3911 - output_day_loss: 1.2086 - output_user_loss: 1.5322 - output_activity_accuracy: 0.9408 - output_day_accuracy: 0.5181 - output_user_accuracy: 0.5293 - val_loss: 2.9875 - val_output_activity_loss: 0.3617 - val_output_day_loss: 1.1542 - val_output_user_loss: 1.4717 - val_output_activity_accuracy: 0.9429 - val_output_day_accuracy: 0.5458 - val_output_user_accuracy: 0.5510\n",
      "Epoch 15/20\n",
      "66/66 [==============================] - 7s 102ms/step - loss: 3.1077 - output_activity_loss: 0.3817 - output_day_loss: 1.2073 - output_user_loss: 1.5188 - output_activity_accuracy: 0.9419 - output_day_accuracy: 0.5201 - output_user_accuracy: 0.5294 - val_loss: 2.9475 - val_output_activity_loss: 0.3489 - val_output_day_loss: 1.1435 - val_output_user_loss: 1.4551 - val_output_activity_accuracy: 0.9438 - val_output_day_accuracy: 0.5449 - val_output_user_accuracy: 0.5461\n",
      "Epoch 16/20\n",
      "66/66 [==============================] - 7s 104ms/step - loss: 3.0716 - output_activity_loss: 0.3684 - output_day_loss: 1.2042 - output_user_loss: 1.4991 - output_activity_accuracy: 0.9450 - output_day_accuracy: 0.5200 - output_user_accuracy: 0.5336 - val_loss: 2.9206 - val_output_activity_loss: 0.3403 - val_output_day_loss: 1.1410 - val_output_user_loss: 1.4392 - val_output_activity_accuracy: 0.9449 - val_output_day_accuracy: 0.5438 - val_output_user_accuracy: 0.5510\n",
      "Epoch 17/20\n",
      "66/66 [==============================] - 7s 107ms/step - loss: 3.0441 - output_activity_loss: 0.3603 - output_day_loss: 1.1965 - output_user_loss: 1.4874 - output_activity_accuracy: 0.9454 - output_day_accuracy: 0.5220 - output_user_accuracy: 0.5351 - val_loss: 2.9069 - val_output_activity_loss: 0.3364 - val_output_day_loss: 1.1386 - val_output_user_loss: 1.4320 - val_output_activity_accuracy: 0.9449 - val_output_day_accuracy: 0.5448 - val_output_user_accuracy: 0.5517\n",
      "Epoch 18/20\n",
      "66/66 [==============================] - 7s 101ms/step - loss: 3.0222 - output_activity_loss: 0.3544 - output_day_loss: 1.1902 - output_user_loss: 1.4776 - output_activity_accuracy: 0.9462 - output_day_accuracy: 0.5242 - output_user_accuracy: 0.5324 - val_loss: 2.8879 - val_output_activity_loss: 0.3301 - val_output_day_loss: 1.1364 - val_output_user_loss: 1.4214 - val_output_activity_accuracy: 0.9441 - val_output_day_accuracy: 0.5471 - val_output_user_accuracy: 0.5538\n",
      "Epoch 19/20\n",
      "66/66 [==============================] - 6s 96ms/step - loss: 3.0000 - output_activity_loss: 0.3460 - output_day_loss: 1.1891 - output_user_loss: 1.4649 - output_activity_accuracy: 0.9471 - output_day_accuracy: 0.5247 - output_user_accuracy: 0.5373 - val_loss: 2.8705 - val_output_activity_loss: 0.3265 - val_output_day_loss: 1.1321 - val_output_user_loss: 1.4119 - val_output_activity_accuracy: 0.9459 - val_output_day_accuracy: 0.5461 - val_output_user_accuracy: 0.5527\n",
      "Epoch 20/20\n",
      "66/66 [==============================] - 7s 108ms/step - loss: 2.9765 - output_activity_loss: 0.3395 - output_day_loss: 1.1832 - output_user_loss: 1.4538 - output_activity_accuracy: 0.9482 - output_day_accuracy: 0.5254 - output_user_accuracy: 0.5387 - val_loss: 2.8758 - val_output_activity_loss: 0.3280 - val_output_day_loss: 1.1345 - val_output_user_loss: 1.4133 - val_output_activity_accuracy: 0.9451 - val_output_day_accuracy: 0.5476 - val_output_user_accuracy: 0.5521\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [train_activity, train_day, train_user],\n",
    "    [train_targets_activity_cat, train_targets_day_cat, train_targets_user_cat],\n",
    "    validation_data=([test_activity, test_day, test_user], [test_targets_activity_cat, test_targets_day_cat, test_targets_user_cat]),\n",
    "    epochs=20,\n",
    "    batch_size=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 2s 7ms/step - loss: 2.8758 - output_activity_loss: 0.3280 - output_day_loss: 1.1345 - output_user_loss: 1.4133 - output_activity_accuracy: 0.9451 - output_day_accuracy: 0.5476 - output_user_accuracy: 0.5521\n",
      "Validation Loss: 2.8757758140563965, Validation Accuracy: 0.3280083239078522\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "results = model.evaluate(\n",
    "    [test_activity, test_day, test_user],\n",
    "    [test_targets_activity_cat, test_targets_day_cat, test_targets_user_cat],\n",
    "    batch_size=64\n",
    ")\n",
    "print(f\"Validation Loss: {results[0]}, Validation Accuracy: {results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model to an H5 file\n",
    "model.save('binetv3_Large-2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Score Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each event attribute, BINet's softmax layer outputs a probability distribution over possible values\n",
    "- The anomaly score for a specific attribute value v is calculated by summing all the probabilities from the softmax output that are greater than the probability assigned to v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1463/1463 [==============================] - 6s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for all inputs\n",
    "predictions = model.predict([windows_activity, windows_day, windows_user])\n",
    "\n",
    "\n",
    "# Extract predictions for categorical attributes (softmax probabilities)\n",
    "predictions_activity = predictions[0]\n",
    "predictions_day = predictions[1]\n",
    "predictions_user = predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46789, 14)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows_activity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46789, 84)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_anomaly_scores(predictions, targets):\n",
    "    scores = []\n",
    "    # Loop through each example in the predictions\n",
    "    for i in range(predictions.shape[0]):\n",
    "        actual_prob = predictions[i, targets[i]]  # Extract the probability of the true class using target index\n",
    "        # Calculate anomaly score as sum of probabilities greater than the probability of the actual value\n",
    "        anomaly_score = np.sum(predictions[i][predictions[i] > actual_prob])\n",
    "        scores.append(anomaly_score)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate anomaly scores for each attribute type\n",
    "anomaly_scores_activity = calculate_anomaly_scores(predictions_activity, targets_activity)\n",
    "anomaly_scores_day = calculate_anomaly_scores(predictions_day, targets_day)\n",
    "anomaly_scores_user = calculate_anomaly_scores(predictions_user, targets_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert missing scores for cases with less than 2 Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>score_day</th>\n",
       "      <th>score_activity</th>\n",
       "      <th>score_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.713142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.711792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.371880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.627100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46784</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.618314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46785</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46786</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46787</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.665545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46788</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.279027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46789 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       case  score_day  score_activity  score_user\n",
       "0         1   0.000000             0.0    0.000000\n",
       "1         1   0.000000             0.0    0.000000\n",
       "2         1   0.713142             0.0    0.711792\n",
       "3         1   0.371880             0.0    0.679226\n",
       "4         1   0.627100             0.0    0.000000\n",
       "...     ...        ...             ...         ...\n",
       "46784  5000   0.000000             0.0    0.618314\n",
       "46785  5000   0.000000             0.0    0.573869\n",
       "46786  5000   0.000000             0.0    0.000000\n",
       "46787  5000   0.665545             0.0    0.655358\n",
       "46788  5000   0.279027             0.0    0.000000\n",
       "\n",
       "[46789 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the case_indices_array corresponding to case_resource\n",
    "score = pd.DataFrame({'case': case_indices})\n",
    "score['score_day'] = anomaly_scores_day\n",
    "score['score_activity'] = anomaly_scores_activity\n",
    "score['score_user'] = anomaly_scores_user\n",
    "\n",
    "score['case'] = score['case'].astype(int)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the 'case' column contain all values between 0 and 5000? True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def contains_all_values(df, column, end):\n",
    "\n",
    "    # Generate the set of all values in the specified range\n",
    "    required_values = set(range(1, end + 1))\n",
    "    \n",
    "    # Get the unique values in the specified column\n",
    "    column_values = set(df[column].unique())\n",
    "    \n",
    "    # Find missing values\n",
    "    missing_values = required_values - column_values\n",
    "    \n",
    "    # Print missing values if any\n",
    "    if missing_values:\n",
    "        print(f\"Missing values: {sorted(missing_values)}\")\n",
    "    \n",
    "    # Check if all required values are in the column values\n",
    "    return required_values.issubset(column_values)\n",
    "\n",
    "end = 5000\n",
    "\n",
    "result = contains_all_values(score, 'case', end)\n",
    "print(f\"Does the 'case' column contain all values between 0 and {end}? {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold (lowest plateau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_anomaly_ratio(scores, threshold):\n",
    "    return np.mean(scores > threshold)\n",
    "\n",
    "def find_plateaus(scores, epsilon=1e-4, min_plateau_length=10):\n",
    "    scores = np.array(scores)  # Convert scores to a NumPy array\n",
    "    sorted_scores = np.sort(scores)\n",
    "    thresholds = sorted_scores\n",
    "    \n",
    "    # Calculate anomaly ratios for all thresholds at once\n",
    "    scores_expanded = scores[:, np.newaxis]\n",
    "    thresholds_expanded = thresholds[np.newaxis, :]\n",
    "    anomaly_ratios = np.mean(scores_expanded > thresholds_expanded, axis=0)\n",
    "    \n",
    "    # Calculate first derivatives using central difference approximation\n",
    "    first_derivatives = np.diff(anomaly_ratios) / np.diff(thresholds)\n",
    "    \n",
    "    # Calculate second derivatives using central difference\n",
    "    second_derivatives = np.diff(first_derivatives) / (thresholds[2:] - thresholds[:-2])\n",
    "    \n",
    "    # Identify plateaus where the first derivative is close to zero\n",
    "    plateau_indices = np.where(np.abs(first_derivatives) < epsilon)[0]\n",
    "    \n",
    "    # Group consecutive indices to identify continuous plateaus\n",
    "    grouped_plateaus = np.split(plateau_indices, np.where(np.diff(plateau_indices) != 1)[0] + 1)\n",
    "    \n",
    "    # Filter plateaus based on minimum length\n",
    "    long_plateaus = [g for g in grouped_plateaus if len(g) >= min_plateau_length]\n",
    "    \n",
    "    if long_plateaus:\n",
    "        # Take the first long plateau and find the mean threshold in this plateau\n",
    "        first_plateau = long_plateaus[0]\n",
    "        plateau_thresholds = thresholds[first_plateau]\n",
    "        return np.mean(plateau_thresholds)\n",
    "    else:\n",
    "        # If no plateau is found, return a default value, e.g., the 90th percentile\n",
    "        return np.percentile(sorted_scores, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s_/ch_w_j2d0sqf6dbdc0_224m40000gq/T/ipykernel_8340/207859425.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "  first_derivatives = np.diff(anomaly_ratios) / np.diff(thresholds)\n"
     ]
    }
   ],
   "source": [
    "threshold_activity = find_plateaus(anomaly_scores_activity)\n",
    "threshold_day = find_plateaus(anomaly_scores_day)\n",
    "threshold_user = find_plateaus(anomaly_scores_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7442339658737183"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7846961021423341"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(anomaly_scores, threshold):\n",
    "    labels = [1 if score > threshold else 0 for score in anomaly_scores]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect anomalies based on the calculated anomaly scores and thresholds\n",
    "labels_activity = detect_anomalies(anomaly_scores_activity, threshold_activity)\n",
    "labels_day = detect_anomalies(anomaly_scores_day, threshold_day)\n",
    "labels_user = detect_anomalies(anomaly_scores_user, threshold_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>predicted_activity</th>\n",
       "      <th>predicted_day</th>\n",
       "      <th>predicted_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46784</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46785</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46786</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46787</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46788</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46789 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       case  predicted_activity  predicted_day  predicted_user\n",
       "0         1                   0              0               0\n",
       "1         1                   0              0               0\n",
       "2         1                   0              0               0\n",
       "3         1                   0              0               0\n",
       "4         1                   0              0               0\n",
       "...     ...                 ...            ...             ...\n",
       "46784  5000                   0              0               0\n",
       "46785  5000                   0              0               0\n",
       "46786  5000                   0              0               0\n",
       "46787  5000                   0              0               0\n",
       "46788  5000                   0              0               0\n",
       "\n",
       "[46789 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the case_indices_array corresponding to case_resource\n",
    "mapping = pd.DataFrame({'case': case_indices})\n",
    "mapping['predicted_activity'] = labels_activity\n",
    "mapping['predicted_day'] = labels_day\n",
    "mapping['predicted_user'] = labels_user\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case\n",
       "1       False\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "5       False\n",
       "        ...  \n",
       "4996     True\n",
       "4997     True\n",
       "4998     True\n",
       "4999     True\n",
       "5000     True\n",
       "Length: 5000, dtype: bool"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a boolean DataFrame where each value is True if the value is 1\n",
    "contains_one = (mapping[['predicted_activity', 'predicted_user', 'predicted_day']] == 1)\n",
    "\n",
    "# Group by 'case' and check if there's at least one 'True' in any of the columns\n",
    "case_prediction = contains_one.groupby(mapping['case']).any().any(axis=1)\n",
    "case_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['normal' 'SkipSequence' 'Insert' 'Attribute' 'Early' 'Late' 'Rework']\n"
     ]
    }
   ],
   "source": [
    "unique_values = dataframe_log['anomaly'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1: conforming\n",
    "- 2: non-conforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of strings to check for anomalies\n",
    "anomaly_strings = ['SkipSequence', 'Insert', 'Early', 'Late', 'Rework']\n",
    "\n",
    "# Group by 'trace_id' and check if 'anomaly' contains any anomaly strings\n",
    "def is_anomalous(group):\n",
    "    return any(label in anomaly_strings for label in group['anomaly'])\n",
    "\n",
    "# Apply the function to each group and create a new dataframe\n",
    "anomaly_df = dataframe_log.groupby('trace_id').apply(is_anomalous).reset_index()\n",
    "anomaly_df.columns = ['trace_id', 'is_anomaly']\n",
    "\n",
    "# Convert boolean to integer (1 for anomaly, 0 for conforming)\n",
    "anomaly_df['is_anomaly'] = anomaly_df['is_anomaly'].astype(int)\n",
    "\n",
    "# Extract the conformity array\n",
    "conformity_array = anomaly_df['is_anomaly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformity_array = conformity_array.reset_index(drop=True)\n",
    "case_prediction = case_prediction.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conformity</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      conformity  predicted\n",
       "0              0      False\n",
       "1              1       True\n",
       "2              1       True\n",
       "3              0       True\n",
       "4              0      False\n",
       "...          ...        ...\n",
       "4995           0       True\n",
       "4996           1       True\n",
       "4997           0       True\n",
       "4998           1       True\n",
       "4999           0       True\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary from the lists\n",
    "data = {\n",
    "    'conformity': conformity_array,\n",
    "    'predicted': case_prediction\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "ground_truth = pd.DataFrame(data)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conformity</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      conformity  predicted\n",
       "0              0          0\n",
       "1              1          1\n",
       "2              1          1\n",
       "3              0          1\n",
       "4              0          0\n",
       "...          ...        ...\n",
       "4995           0          1\n",
       "4996           1          1\n",
       "4997           0          1\n",
       "4998           1          1\n",
       "4999           0          1\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth['predicted'] = [int(value) for value in ground_truth['predicted']]\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth['predicted'] = ground_truth['predicted'].apply(lambda x: 1 if x == 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conformity</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      conformity  predicted\n",
       "0              0          1\n",
       "1              1          0\n",
       "2              1          0\n",
       "3              0          0\n",
       "4              0          1\n",
       "...          ...        ...\n",
       "4995           0          0\n",
       "4996           1          0\n",
       "4997           0          0\n",
       "4998           1          0\n",
       "4999           0          0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating TP, TN, FP, FN\n",
    "TP = ((ground_truth['conformity'] == 1) & (ground_truth['predicted'] == 1)).sum()\n",
    "TN = ((ground_truth['conformity'] == 0) & (ground_truth['predicted'] == 0)).sum()\n",
    "FP = ((ground_truth['conformity'] == 0) & (ground_truth['predicted'] == 1)).sum()\n",
    "FN = ((ground_truth['conformity'] == 1) & (ground_truth['predicted'] == 0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.551\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.014\n"
     ]
    }
   ],
   "source": [
    "# Calculate f1\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "print(f\"F1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev (Non Conform Traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.691\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision for Dev\n",
    "precision = TN / (TN + FN)\n",
    "print(f\"Precision: {precision:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.729\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall for Dev\n",
    "recall = TN / (TN + FP)\n",
    "print(f\"Recall: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Dev (Conform Traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.982\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision for No Dev\n",
    "precision = TP / (TP + FP)\n",
    "print(f\"Precision: {precision:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.292\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall for No Dev\n",
    "recall = TP / (TP + FN)\n",
    "print(f\"Recall: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7390756348407082"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Assuming ground_truth is your DataFrame\n",
    "# Make sure 'conformity' contains actual labels (0 or 1)\n",
    "# and 'predicted' contains predicted probabilities or scores\n",
    "auc_roc = roc_auc_score(ground_truth['conformity'], ground_truth['predicted'])\n",
    "auc_roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trace2Trace Alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT TRACE 1\n",
    "\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/input_traces/large_trace1.bpmn\")\n",
    "\n",
    "net, im, fm = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "alignments = alignments_petri.apply(log, net, im, fm)\n",
    "\n",
    "fitness_trace_1 = [trace['fitness'] for trace in alignments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT TRACE 2\n",
    "\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/input_traces/large_trace2.bpmn\")\n",
    "\n",
    "net, im, fm = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "alignments = alignments_petri.apply(log, net, im, fm)\n",
    "\n",
    "fitness_trace_2 = [trace['fitness'] for trace in alignments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT TRACE 3\n",
    "\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/input_traces/large_trace3.bpmn\")\n",
    "\n",
    "net, im, fm = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "alignments = alignments_petri.apply(log, net, im, fm)\n",
    "\n",
    "fitness_trace_3 = [trace['fitness'] for trace in alignments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the lists\n",
    "data = {\n",
    "    'Trace 1': fitness_trace_1,\n",
    "    'Trace 2': fitness_trace_2,\n",
    "    'Trace 3': fitness_trace_3\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "fitness = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine the trace with the highest value\n",
    "def highest_trace(row):\n",
    "    if row['Trace 1'] == max(row):\n",
    "        return 'trace_1'\n",
    "    elif row['Trace 2'] == max(row):\n",
    "        return 'trace_2'\n",
    "    else:\n",
    "        return 'trace_3'\n",
    "\n",
    "# Add a new column using the highest_trace function\n",
    "fitness['Closest Trace'] = fitness.apply(highest_trace, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify deviation:\n",
    "# â€“ Skip: One or multiple events are skipped\n",
    "# â€“ Insert: Random events are inserted\n",
    "# â€“ Rework: Events are executed multiple times\n",
    "# â€“ Late: Events are shifted forward\n",
    "# â€“ Early: Events are shifted backward\n",
    "\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 1. Import the event log\n",
    "log = xes_importer.apply(\"../../data/logs/event_log.xes\")\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/model/large.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, im, fm = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "# 4. Perform alignment-based conformance checking\n",
    "alignments = alignments_petri.apply(log, net, im, fm)\n",
    "\n",
    "# 5. Calculate and print diagnostics\n",
    "fit_traces = sum(1 for trace in alignments if trace['fitness'] == 1.0)\n",
    "\n",
    "print(f\"Total traces: {len(log)}\")\n",
    "print(f\"Conform traces: {fit_traces}\")\n",
    "print(f\"Non-Conform traces: {len(log) - fit_traces}\")\n",
    "\n",
    "# 6. Document deviations for each trace\n",
    "deviations = []\n",
    "\n",
    "for idx, trace in enumerate(alignments):\n",
    "    trace_deviations = {\n",
    "        \"trace_index\": idx,\n",
    "        \"skip\": [],\n",
    "        \"insert\": [],\n",
    "        \"rework\": [],\n",
    "        \"late\": [],\n",
    "        \"early\": []\n",
    "    }\n",
    "    visited_activities = set()\n",
    "    alignment_steps = trace['alignment']\n",
    "    for i, step in enumerate(alignment_steps):\n",
    "        if step[0] == \">>\" and step[1] != \">>\":\n",
    "            trace_deviations[\"skip\"].append(step[1])\n",
    "        elif step[1] == \">>\" and step[0] != \">>\":\n",
    "            trace_deviations[\"insert\"].append(step[0])\n",
    "        elif step[0] == step[1]:\n",
    "            if step[0] in visited_activities:\n",
    "                trace_deviations[\"rework\"].append(step[0])\n",
    "            visited_activities.add(step[0])\n",
    "        if step[0] != \">>\" and step[1] != \">>\" and step[0] != step[1]:\n",
    "            if alignment_steps[i-1][0] == step[1] or alignment_steps[i-1][1] == step[0]:\n",
    "                trace_deviations[\"early\"].append(step[0])\n",
    "            else:\n",
    "                trace_deviations[\"late\"].append(step[0])\n",
    "    deviations.append(trace_deviations)\n",
    "\n",
    "# Print or save the deviations\n",
    "for dev in deviations:\n",
    "    print(f\"Trace {dev['trace_index']}:\")\n",
    "    print(f\"  Skipped Activities: {dev['skip']}\")\n",
    "    print(f\"  Inserted Activities: {dev['insert']}\")\n",
    "    print(f\"  Rework Activities: {dev['rework']}\")\n",
    "    print(f\"  Late Activities: {dev['late']}\")\n",
    "    print(f\"  Early Activities: {dev['early']}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
