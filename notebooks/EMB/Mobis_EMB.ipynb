{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f1af5c",
   "metadata": {},
   "source": [
    "# Import Event Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab9ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s_/ch_w_j2d0sqf6dbdc0_224m40000gq/T/ipykernel_5427/1145127291.py:15: DeprecatedWarning: format_dataframe is deprecated as of 2.3.0 and will be removed in 3.0.0. the format_dataframe function does not need application anymore.\n",
      "  dataframe = pm4py.format_dataframe(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "      <th>user</th>\n",
       "      <th>travel_start</th>\n",
       "      <th>travel_end</th>\n",
       "      <th>case</th>\n",
       "      <th>cost</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>@@index</th>\n",
       "      <th>@@case_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file travel request</td>\n",
       "      <td>2017-01-17 11:17:00+00:00</td>\n",
       "      <td>2017-01-17 11:23:00+00:00</td>\n",
       "      <td>Employee</td>\n",
       "      <td>JB8510</td>\n",
       "      <td>2017-10-01 00:00:00+00:00</td>\n",
       "      <td>2017-01-15 00:00:00+00:00</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>file travel request</td>\n",
       "      <td>2017-01-17 11:17:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>check if travel request needs preliminary pric...</td>\n",
       "      <td>2017-01-17 11:23:00+00:00</td>\n",
       "      <td>2017-01-17 11:24:00+00:00</td>\n",
       "      <td>Employee</td>\n",
       "      <td>JB8510</td>\n",
       "      <td>2017-10-01 00:00:00+00:00</td>\n",
       "      <td>2017-01-15 00:00:00+00:00</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>check if travel request needs preliminary pric...</td>\n",
       "      <td>2017-01-17 11:23:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decide on approval requirements</td>\n",
       "      <td>2017-01-17 11:24:00+00:00</td>\n",
       "      <td>2017-01-17 11:24:00+00:00</td>\n",
       "      <td>Employee</td>\n",
       "      <td>JB8510</td>\n",
       "      <td>2017-10-01 00:00:00+00:00</td>\n",
       "      <td>2017-01-15 00:00:00+00:00</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>decide on approval requirements</td>\n",
       "      <td>2017-01-17 11:24:00+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>check if booking is necessary</td>\n",
       "      <td>2017-01-17 11:24:00+00:00</td>\n",
       "      <td>2017-01-17 11:40:00+00:00</td>\n",
       "      <td>Travel Department</td>\n",
       "      <td>KS9688</td>\n",
       "      <td>2017-10-01 00:00:00+00:00</td>\n",
       "      <td>2017-01-15 00:00:00+00:00</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>check if booking is necessary</td>\n",
       "      <td>2017-01-17 11:24:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>check if expense documents exist</td>\n",
       "      <td>2017-01-18 05:59:00+00:00</td>\n",
       "      <td>2017-01-18 06:31:00+00:00</td>\n",
       "      <td>Employee</td>\n",
       "      <td>JB8510</td>\n",
       "      <td>2017-10-01 00:00:00+00:00</td>\n",
       "      <td>2017-01-15 00:00:00+00:00</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>check if expense documents exist</td>\n",
       "      <td>2017-01-18 05:59:00+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55804</th>\n",
       "      <td>confirm travel expense report</td>\n",
       "      <td>2017-11-22 06:48:00+00:00</td>\n",
       "      <td>2017-11-22 06:50:00+00:00</td>\n",
       "      <td>Employee</td>\n",
       "      <td>KI9211</td>\n",
       "      <td>2017-11-19 00:00:00+00:00</td>\n",
       "      <td>2017-11-20 00:00:00+00:00</td>\n",
       "      <td>6348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6348</td>\n",
       "      <td>confirm travel expense report</td>\n",
       "      <td>2017-11-22 06:48:00+00:00</td>\n",
       "      <td>55804</td>\n",
       "      <td>3353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55805</th>\n",
       "      <td>decide on travel expense approval</td>\n",
       "      <td>2017-11-22 12:59:00+00:00</td>\n",
       "      <td>2017-11-22 13:06:00+00:00</td>\n",
       "      <td>Manager</td>\n",
       "      <td>AK7488</td>\n",
       "      <td>2017-11-19 00:00:00+00:00</td>\n",
       "      <td>2017-11-20 00:00:00+00:00</td>\n",
       "      <td>6348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6348</td>\n",
       "      <td>decide on travel expense approval</td>\n",
       "      <td>2017-11-22 12:59:00+00:00</td>\n",
       "      <td>55805</td>\n",
       "      <td>3353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55806</th>\n",
       "      <td>send original documents to archive</td>\n",
       "      <td>2017-11-29 20:12:00+00:00</td>\n",
       "      <td>2017-11-29 20:24:00+00:00</td>\n",
       "      <td>Employee</td>\n",
       "      <td>KI9211</td>\n",
       "      <td>2017-11-19 00:00:00+00:00</td>\n",
       "      <td>2017-11-20 00:00:00+00:00</td>\n",
       "      <td>6348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6348</td>\n",
       "      <td>send original documents to archive</td>\n",
       "      <td>2017-11-29 20:12:00+00:00</td>\n",
       "      <td>55806</td>\n",
       "      <td>3353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55807</th>\n",
       "      <td>calculate payments</td>\n",
       "      <td>2017-12-08 09:32:00+00:00</td>\n",
       "      <td>2017-12-08 09:55:00+00:00</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>FQ3758</td>\n",
       "      <td>2017-11-19 00:00:00+00:00</td>\n",
       "      <td>2017-11-20 00:00:00+00:00</td>\n",
       "      <td>6348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6348</td>\n",
       "      <td>calculate payments</td>\n",
       "      <td>2017-12-08 09:32:00+00:00</td>\n",
       "      <td>55807</td>\n",
       "      <td>3353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55808</th>\n",
       "      <td>pay expenses</td>\n",
       "      <td>2017-12-18 08:39:00+00:00</td>\n",
       "      <td>2017-12-18 08:52:00+00:00</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>FQ3758</td>\n",
       "      <td>2017-11-19 00:00:00+00:00</td>\n",
       "      <td>2017-11-20 00:00:00+00:00</td>\n",
       "      <td>6348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6348</td>\n",
       "      <td>pay expenses</td>\n",
       "      <td>2017-12-18 08:39:00+00:00</td>\n",
       "      <td>55808</td>\n",
       "      <td>3353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55809 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                activity  \\\n",
       "0                                    file travel request   \n",
       "1      check if travel request needs preliminary pric...   \n",
       "2                        decide on approval requirements   \n",
       "3                          check if booking is necessary   \n",
       "4                       check if expense documents exist   \n",
       "...                                                  ...   \n",
       "55804                      confirm travel expense report   \n",
       "55805                  decide on travel expense approval   \n",
       "55806                 send original documents to archive   \n",
       "55807                                 calculate payments   \n",
       "55808                                       pay expenses   \n",
       "\n",
       "                          start                       end               type  \\\n",
       "0     2017-01-17 11:17:00+00:00 2017-01-17 11:23:00+00:00           Employee   \n",
       "1     2017-01-17 11:23:00+00:00 2017-01-17 11:24:00+00:00           Employee   \n",
       "2     2017-01-17 11:24:00+00:00 2017-01-17 11:24:00+00:00           Employee   \n",
       "3     2017-01-17 11:24:00+00:00 2017-01-17 11:40:00+00:00  Travel Department   \n",
       "4     2017-01-18 05:59:00+00:00 2017-01-18 06:31:00+00:00           Employee   \n",
       "...                         ...                       ...                ...   \n",
       "55804 2017-11-22 06:48:00+00:00 2017-11-22 06:50:00+00:00           Employee   \n",
       "55805 2017-11-22 12:59:00+00:00 2017-11-22 13:06:00+00:00            Manager   \n",
       "55806 2017-11-29 20:12:00+00:00 2017-11-29 20:24:00+00:00           Employee   \n",
       "55807 2017-12-08 09:32:00+00:00 2017-12-08 09:55:00+00:00         Accounting   \n",
       "55808 2017-12-18 08:39:00+00:00 2017-12-18 08:52:00+00:00         Accounting   \n",
       "\n",
       "         user              travel_start                travel_end  case  cost  \\\n",
       "0      JB8510 2017-10-01 00:00:00+00:00 2017-01-15 00:00:00+00:00   105   NaN   \n",
       "1      JB8510 2017-10-01 00:00:00+00:00 2017-01-15 00:00:00+00:00   105   NaN   \n",
       "2      JB8510 2017-10-01 00:00:00+00:00 2017-01-15 00:00:00+00:00   105   NaN   \n",
       "3      KS9688 2017-10-01 00:00:00+00:00 2017-01-15 00:00:00+00:00   105   NaN   \n",
       "4      JB8510 2017-10-01 00:00:00+00:00 2017-01-15 00:00:00+00:00   105   NaN   \n",
       "...       ...                       ...                       ...   ...   ...   \n",
       "55804  KI9211 2017-11-19 00:00:00+00:00 2017-11-20 00:00:00+00:00  6348   NaN   \n",
       "55805  AK7488 2017-11-19 00:00:00+00:00 2017-11-20 00:00:00+00:00  6348   NaN   \n",
       "55806  KI9211 2017-11-19 00:00:00+00:00 2017-11-20 00:00:00+00:00  6348   NaN   \n",
       "55807  FQ3758 2017-11-19 00:00:00+00:00 2017-11-20 00:00:00+00:00  6348   NaN   \n",
       "55808  FQ3758 2017-11-19 00:00:00+00:00 2017-11-20 00:00:00+00:00  6348   NaN   \n",
       "\n",
       "      case:concept:name                                       concept:name  \\\n",
       "0                   105                                file travel request   \n",
       "1                   105  check if travel request needs preliminary pric...   \n",
       "2                   105                    decide on approval requirements   \n",
       "3                   105                      check if booking is necessary   \n",
       "4                   105                   check if expense documents exist   \n",
       "...                 ...                                                ...   \n",
       "55804              6348                      confirm travel expense report   \n",
       "55805              6348                  decide on travel expense approval   \n",
       "55806              6348                 send original documents to archive   \n",
       "55807              6348                                 calculate payments   \n",
       "55808              6348                                       pay expenses   \n",
       "\n",
       "                 time:timestamp  @@index  @@case_index  \n",
       "0     2017-01-17 11:17:00+00:00        0             0  \n",
       "1     2017-01-17 11:23:00+00:00        1             0  \n",
       "2     2017-01-17 11:24:00+00:00        2             0  \n",
       "3     2017-01-17 11:24:00+00:00        3             0  \n",
       "4     2017-01-18 05:59:00+00:00        4             0  \n",
       "...                         ...      ...           ...  \n",
       "55804 2017-11-22 06:48:00+00:00    55804          3353  \n",
       "55805 2017-11-22 12:59:00+00:00    55805          3353  \n",
       "55806 2017-11-29 20:12:00+00:00    55806          3353  \n",
       "55807 2017-12-08 09:32:00+00:00    55807          3353  \n",
       "55808 2017-12-18 08:39:00+00:00    55808          3353  \n",
       "\n",
       "[55809 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the CSV file\n",
    "    dataframe = pd.read_csv('../../data/logs/mobis.csv', sep=',')  \n",
    "\n",
    "    # Drop the first column without knowing its name\n",
    "    dataframe = dataframe.drop(dataframe.columns[0], axis=1)\n",
    "\n",
    "    # Format the dataframe\n",
    "    dataframe = pm4py.format_dataframe(\n",
    "        dataframe, \n",
    "        case_id='case', \n",
    "        activity_key='activity', \n",
    "        timestamp_key='start'\n",
    "    )\n",
    "\n",
    "    # Convert the dataframe to event log\n",
    "    log = log_converter.apply(dataframe)\n",
    "    \n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba199329",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e8a99",
   "metadata": {},
   "source": [
    "## Integer Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9269f1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "      <th>user</th>\n",
       "      <th>travel_start</th>\n",
       "      <th>travel_end</th>\n",
       "      <th>case</th>\n",
       "      <th>cost</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>@@index</th>\n",
       "      <th>@@case_index</th>\n",
       "      <th>activity_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file travel request</td>\n",
       "      <td>2017-01-17 11:17:00+00:00</td>\n",
       "      <td>2017-01-17 11:23:00+00:00</td>\n",
       "      <td>Employee</td>\n",
       "      <td>JB8510</td>\n",
       "      <td>2017-10-01 00:00:00+00:00</td>\n",
       "      <td>2017-01-15 00:00:00+00:00</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>file travel request</td>\n",
       "      <td>2017-01-17 11:17:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>check if travel request needs preliminary pric...</td>\n",
       "      <td>2017-01-17 11:23:00+00:00</td>\n",
       "      <td>2017-01-17 11:24:00+00:00</td>\n",
       "      <td>Employee</td>\n",
       "      <td>JB8510</td>\n",
       "      <td>2017-10-01 00:00:00+00:00</td>\n",
       "      <td>2017-01-15 00:00:00+00:00</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>check if travel request needs preliminary pric...</td>\n",
       "      <td>2017-01-17 11:23:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decide on approval requirements</td>\n",
       "      <td>2017-01-17 11:24:00+00:00</td>\n",
       "      <td>2017-01-17 11:24:00+00:00</td>\n",
       "      <td>Employee</td>\n",
       "      <td>JB8510</td>\n",
       "      <td>2017-10-01 00:00:00+00:00</td>\n",
       "      <td>2017-01-15 00:00:00+00:00</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>decide on approval requirements</td>\n",
       "      <td>2017-01-17 11:24:00+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>check if booking is necessary</td>\n",
       "      <td>2017-01-17 11:24:00+00:00</td>\n",
       "      <td>2017-01-17 11:40:00+00:00</td>\n",
       "      <td>Travel Department</td>\n",
       "      <td>KS9688</td>\n",
       "      <td>2017-10-01 00:00:00+00:00</td>\n",
       "      <td>2017-01-15 00:00:00+00:00</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>check if booking is necessary</td>\n",
       "      <td>2017-01-17 11:24:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>check if expense documents exist</td>\n",
       "      <td>2017-01-18 05:59:00+00:00</td>\n",
       "      <td>2017-01-18 06:31:00+00:00</td>\n",
       "      <td>Employee</td>\n",
       "      <td>JB8510</td>\n",
       "      <td>2017-10-01 00:00:00+00:00</td>\n",
       "      <td>2017-01-15 00:00:00+00:00</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>check if expense documents exist</td>\n",
       "      <td>2017-01-18 05:59:00+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55804</th>\n",
       "      <td>confirm travel expense report</td>\n",
       "      <td>2017-11-22 06:48:00+00:00</td>\n",
       "      <td>2017-11-22 06:50:00+00:00</td>\n",
       "      <td>Employee</td>\n",
       "      <td>KI9211</td>\n",
       "      <td>2017-11-19 00:00:00+00:00</td>\n",
       "      <td>2017-11-20 00:00:00+00:00</td>\n",
       "      <td>6348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6348</td>\n",
       "      <td>confirm travel expense report</td>\n",
       "      <td>2017-11-22 06:48:00+00:00</td>\n",
       "      <td>55804</td>\n",
       "      <td>3353</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55805</th>\n",
       "      <td>decide on travel expense approval</td>\n",
       "      <td>2017-11-22 12:59:00+00:00</td>\n",
       "      <td>2017-11-22 13:06:00+00:00</td>\n",
       "      <td>Manager</td>\n",
       "      <td>AK7488</td>\n",
       "      <td>2017-11-19 00:00:00+00:00</td>\n",
       "      <td>2017-11-20 00:00:00+00:00</td>\n",
       "      <td>6348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6348</td>\n",
       "      <td>decide on travel expense approval</td>\n",
       "      <td>2017-11-22 12:59:00+00:00</td>\n",
       "      <td>55805</td>\n",
       "      <td>3353</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55806</th>\n",
       "      <td>send original documents to archive</td>\n",
       "      <td>2017-11-29 20:12:00+00:00</td>\n",
       "      <td>2017-11-29 20:24:00+00:00</td>\n",
       "      <td>Employee</td>\n",
       "      <td>KI9211</td>\n",
       "      <td>2017-11-19 00:00:00+00:00</td>\n",
       "      <td>2017-11-20 00:00:00+00:00</td>\n",
       "      <td>6348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6348</td>\n",
       "      <td>send original documents to archive</td>\n",
       "      <td>2017-11-29 20:12:00+00:00</td>\n",
       "      <td>55806</td>\n",
       "      <td>3353</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55807</th>\n",
       "      <td>calculate payments</td>\n",
       "      <td>2017-12-08 09:32:00+00:00</td>\n",
       "      <td>2017-12-08 09:55:00+00:00</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>FQ3758</td>\n",
       "      <td>2017-11-19 00:00:00+00:00</td>\n",
       "      <td>2017-11-20 00:00:00+00:00</td>\n",
       "      <td>6348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6348</td>\n",
       "      <td>calculate payments</td>\n",
       "      <td>2017-12-08 09:32:00+00:00</td>\n",
       "      <td>55807</td>\n",
       "      <td>3353</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55808</th>\n",
       "      <td>pay expenses</td>\n",
       "      <td>2017-12-18 08:39:00+00:00</td>\n",
       "      <td>2017-12-18 08:52:00+00:00</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>FQ3758</td>\n",
       "      <td>2017-11-19 00:00:00+00:00</td>\n",
       "      <td>2017-11-20 00:00:00+00:00</td>\n",
       "      <td>6348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6348</td>\n",
       "      <td>pay expenses</td>\n",
       "      <td>2017-12-18 08:39:00+00:00</td>\n",
       "      <td>55808</td>\n",
       "      <td>3353</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55809 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                activity  \\\n",
       "0                                    file travel request   \n",
       "1      check if travel request needs preliminary pric...   \n",
       "2                        decide on approval requirements   \n",
       "3                          check if booking is necessary   \n",
       "4                       check if expense documents exist   \n",
       "...                                                  ...   \n",
       "55804                      confirm travel expense report   \n",
       "55805                  decide on travel expense approval   \n",
       "55806                 send original documents to archive   \n",
       "55807                                 calculate payments   \n",
       "55808                                       pay expenses   \n",
       "\n",
       "                          start                       end               type  \\\n",
       "0     2017-01-17 11:17:00+00:00 2017-01-17 11:23:00+00:00           Employee   \n",
       "1     2017-01-17 11:23:00+00:00 2017-01-17 11:24:00+00:00           Employee   \n",
       "2     2017-01-17 11:24:00+00:00 2017-01-17 11:24:00+00:00           Employee   \n",
       "3     2017-01-17 11:24:00+00:00 2017-01-17 11:40:00+00:00  Travel Department   \n",
       "4     2017-01-18 05:59:00+00:00 2017-01-18 06:31:00+00:00           Employee   \n",
       "...                         ...                       ...                ...   \n",
       "55804 2017-11-22 06:48:00+00:00 2017-11-22 06:50:00+00:00           Employee   \n",
       "55805 2017-11-22 12:59:00+00:00 2017-11-22 13:06:00+00:00            Manager   \n",
       "55806 2017-11-29 20:12:00+00:00 2017-11-29 20:24:00+00:00           Employee   \n",
       "55807 2017-12-08 09:32:00+00:00 2017-12-08 09:55:00+00:00         Accounting   \n",
       "55808 2017-12-18 08:39:00+00:00 2017-12-18 08:52:00+00:00         Accounting   \n",
       "\n",
       "         user              travel_start                travel_end  case  cost  \\\n",
       "0      JB8510 2017-10-01 00:00:00+00:00 2017-01-15 00:00:00+00:00   105   NaN   \n",
       "1      JB8510 2017-10-01 00:00:00+00:00 2017-01-15 00:00:00+00:00   105   NaN   \n",
       "2      JB8510 2017-10-01 00:00:00+00:00 2017-01-15 00:00:00+00:00   105   NaN   \n",
       "3      KS9688 2017-10-01 00:00:00+00:00 2017-01-15 00:00:00+00:00   105   NaN   \n",
       "4      JB8510 2017-10-01 00:00:00+00:00 2017-01-15 00:00:00+00:00   105   NaN   \n",
       "...       ...                       ...                       ...   ...   ...   \n",
       "55804  KI9211 2017-11-19 00:00:00+00:00 2017-11-20 00:00:00+00:00  6348   NaN   \n",
       "55805  AK7488 2017-11-19 00:00:00+00:00 2017-11-20 00:00:00+00:00  6348   NaN   \n",
       "55806  KI9211 2017-11-19 00:00:00+00:00 2017-11-20 00:00:00+00:00  6348   NaN   \n",
       "55807  FQ3758 2017-11-19 00:00:00+00:00 2017-11-20 00:00:00+00:00  6348   NaN   \n",
       "55808  FQ3758 2017-11-19 00:00:00+00:00 2017-11-20 00:00:00+00:00  6348   NaN   \n",
       "\n",
       "      case:concept:name                                       concept:name  \\\n",
       "0                   105                                file travel request   \n",
       "1                   105  check if travel request needs preliminary pric...   \n",
       "2                   105                    decide on approval requirements   \n",
       "3                   105                      check if booking is necessary   \n",
       "4                   105                   check if expense documents exist   \n",
       "...                 ...                                                ...   \n",
       "55804              6348                      confirm travel expense report   \n",
       "55805              6348                  decide on travel expense approval   \n",
       "55806              6348                 send original documents to archive   \n",
       "55807              6348                                 calculate payments   \n",
       "55808              6348                                       pay expenses   \n",
       "\n",
       "                 time:timestamp  @@index  @@case_index  activity_encoded  \n",
       "0     2017-01-17 11:17:00+00:00        0             0                15  \n",
       "1     2017-01-17 11:23:00+00:00        1             0                 7  \n",
       "2     2017-01-17 11:24:00+00:00        2             0                11  \n",
       "3     2017-01-17 11:24:00+00:00        3             0                 3  \n",
       "4     2017-01-18 05:59:00+00:00        4             0                 4  \n",
       "...                         ...      ...           ...               ...  \n",
       "55804 2017-11-22 06:48:00+00:00    55804          3353                 8  \n",
       "55805 2017-11-22 12:59:00+00:00    55805          3353                13  \n",
       "55806 2017-11-29 20:12:00+00:00    55806          3353                21  \n",
       "55807 2017-12-08 09:32:00+00:00    55807          3353                 1  \n",
       "55808 2017-12-18 08:39:00+00:00    55808          3353                17  \n",
       "\n",
       "[55809 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit label encoder and return encoded labels\n",
    "dataframe['activity_encoded'] = label_encoder.fit_transform(dataframe['concept:name'])\n",
    "\n",
    "# Now the 'dataframe' has a new column 'activity_encoded' with integer encoded values of the 'activity' column\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548730de",
   "metadata": {},
   "source": [
    "# Build Input X and output Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c7b0ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 19:42:27.154899: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def generate_prefix_windows(df, case_id_column='@@case_index', max_len=None):\n",
    "    windows = []\n",
    "    targets = []\n",
    "    \n",
    "    for case_id in df[case_id_column].unique():\n",
    "        case_data = df[df[case_id_column] == case_id].drop(columns=[case_id_column]).to_numpy()\n",
    "        \n",
    "        # Optional: Make sure to sort the case data if there's an implicit order (e.g., by timestamps)\n",
    "        # case_data = case_data.sort_values(by='timestamp_column').to_numpy()  # Uncomment and adjust if needed\n",
    "        \n",
    "        for i in range(1, len(case_data)):\n",
    "            window = case_data[:i]\n",
    "            target = case_data[i]\n",
    "            windows.append(window)\n",
    "            targets.append(target)\n",
    "    \n",
    "    if max_len is None:\n",
    "        max_len = max(len(window) for window in windows)\n",
    "    \n",
    "    # Pad sequences\n",
    "    windows_padded = pad_sequences(windows, maxlen=max_len, padding='post', dtype='float32')\n",
    "    \n",
    "    # Convert targets to numpy array\n",
    "    targets_array = np.array(targets, dtype='float32')\n",
    "    \n",
    "    return windows_padded, targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40b22a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = dataframe[['activity_encoded', '@@case_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2903a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = generate_prefix_windows(activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a83570",
   "metadata": {},
   "source": [
    "# LSTM Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8eb173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 26)          676       \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, None, 100),       50800     \n",
      "                              (None, 100),                       \n",
      "                              (None, 100)]                       \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 100)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 26)                2626      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54102 (211.34 KB)\n",
      "Trainable params: 54102 (211.34 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Lambda\n",
    "\n",
    "# Define parameters\n",
    "input_dim = dataframe['concept:name'].nunique()  # Number of unique activities\n",
    "embedding_dim = len(dataframe['concept:name'].unique())  # Embedding dimension\n",
    "lstm_units = 100  # Number of units in the LSTM layer\n",
    "dropout_rate = 0.2  # Dropout rate to prevent overfitting\n",
    "output_dim = input_dim  # Output dimension (number of activities)\n",
    "\n",
    "# Define the input layer\n",
    "inputs = Input(shape=(None,))\n",
    "\n",
    "# Embedding layer\n",
    "embedding = Embedding(input_dim=input_dim, output_dim=embedding_dim)(inputs)\n",
    "\n",
    "# LSTM layer with return_sequences=True to get hidden states at each time step\n",
    "lstm_output, lstm_state_h, lstm_state_c = LSTM(units=lstm_units, return_sequences=True, return_state=True)(embedding)\n",
    "\n",
    "# Apply a Lambda layer to extract the last hidden state\n",
    "last_hidden_state = Lambda(lambda x: x[:, -1, :])(lstm_output)\n",
    "\n",
    "# Dropout layer\n",
    "dropout = Dropout(rate=dropout_rate)(last_hidden_state)\n",
    "\n",
    "# Dense output layer for next activity prediction\n",
    "outputs = Dense(units=output_dim, activation='softmax')(dropout)\n",
    "\n",
    "# Build the model for training (only outputs the prediction)\n",
    "training_model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the training model\n",
    "training_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model for inference (outputs both predictions and hidden states)\n",
    "inference_model = Model(inputs=inputs, outputs=[outputs, lstm_output])\n",
    "\n",
    "# Display the model architecture\n",
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66982278",
   "metadata": {},
   "source": [
    "# LSTM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24a8c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y = to_categorical(Y, num_classes=input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daa90533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "105/105 [==============================] - 21s 180ms/step - loss: 3.0009 - accuracy: 0.0791\n",
      "Epoch 2/25\n",
      "105/105 [==============================] - 28s 269ms/step - loss: 2.4616 - accuracy: 0.2146\n",
      "Epoch 3/25\n",
      "105/105 [==============================] - 26s 244ms/step - loss: 1.3435 - accuracy: 0.5141\n",
      "Epoch 4/25\n",
      "105/105 [==============================] - 29s 281ms/step - loss: 0.8806 - accuracy: 0.6679\n",
      "Epoch 5/25\n",
      "105/105 [==============================] - 27s 255ms/step - loss: 0.7221 - accuracy: 0.7284\n",
      "Epoch 6/25\n",
      "105/105 [==============================] - 22s 211ms/step - loss: 0.5771 - accuracy: 0.7833\n",
      "Epoch 7/25\n",
      "105/105 [==============================] - 28s 268ms/step - loss: 0.6577 - accuracy: 0.7506\n",
      "Epoch 8/25\n",
      "105/105 [==============================] - 31s 293ms/step - loss: 0.4939 - accuracy: 0.8108\n",
      "Epoch 9/25\n",
      "105/105 [==============================] - 30s 285ms/step - loss: 0.4477 - accuracy: 0.8223\n",
      "Epoch 10/25\n",
      "105/105 [==============================] - 31s 300ms/step - loss: 0.4282 - accuracy: 0.8260\n",
      "Epoch 11/25\n",
      "105/105 [==============================] - 28s 262ms/step - loss: 0.6277 - accuracy: 0.7704\n",
      "Epoch 12/25\n",
      "105/105 [==============================] - 27s 258ms/step - loss: 0.4208 - accuracy: 0.8251\n",
      "Epoch 13/25\n",
      "105/105 [==============================] - 23s 218ms/step - loss: 0.5912 - accuracy: 0.7763\n",
      "Epoch 14/25\n",
      "105/105 [==============================] - 25s 239ms/step - loss: 0.4575 - accuracy: 0.8132\n",
      "Epoch 15/25\n",
      "105/105 [==============================] - 22s 211ms/step - loss: 0.5331 - accuracy: 0.7974\n",
      "Epoch 16/25\n",
      "105/105 [==============================] - 22s 213ms/step - loss: 0.4265 - accuracy: 0.8209\n",
      "Epoch 17/25\n",
      "105/105 [==============================] - 20s 195ms/step - loss: 0.3913 - accuracy: 0.8312\n",
      "Epoch 18/25\n",
      "105/105 [==============================] - 21s 204ms/step - loss: 0.7134 - accuracy: 0.7515\n",
      "Epoch 19/25\n",
      "105/105 [==============================] - 26s 247ms/step - loss: 0.4819 - accuracy: 0.8072\n",
      "Epoch 20/25\n",
      "105/105 [==============================] - 21s 201ms/step - loss: 0.3801 - accuracy: 0.8424\n",
      "Epoch 21/25\n",
      "105/105 [==============================] - 27s 254ms/step - loss: 0.6971 - accuracy: 0.7556\n",
      "Epoch 22/25\n",
      "105/105 [==============================] - 28s 262ms/step - loss: 0.4058 - accuracy: 0.8350\n",
      "Epoch 23/25\n",
      "105/105 [==============================] - 23s 219ms/step - loss: 0.3736 - accuracy: 0.8426\n",
      "Epoch 24/25\n",
      "105/105 [==============================] - 22s 206ms/step - loss: 0.3679 - accuracy: 0.8452\n",
      "Epoch 25/25\n",
      "105/105 [==============================] - 27s 255ms/step - loss: 0.6719 - accuracy: 0.7564\n"
     ]
    }
   ],
   "source": [
    "history = training_model.fit(X, Y, epochs=25, batch_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df3b50f",
   "metadata": {},
   "source": [
    "# Extract Trace Representations Using LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e76f391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1640/1640 [==============================] - 14s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions, hidden_states = inference_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f445c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@@case_index\n",
       "0       [file travel request, check if travel request ...\n",
       "1       [file travel request, check if travel request ...\n",
       "2       [file travel request, check if travel request ...\n",
       "3       [file travel request, check if travel request ...\n",
       "4       [file travel request, check if travel request ...\n",
       "                              ...                        \n",
       "3349    [file travel request, check if travel request ...\n",
       "3350    [file travel request, check if travel request ...\n",
       "3351    [file travel request, check if travel request ...\n",
       "3352    [file travel request, check if travel request ...\n",
       "3353    [file travel request, check if travel request ...\n",
       "Name: concept:name, Length: 3354, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by case index to get individual traces\n",
    "traces = dataframe.groupby('@@case_index')['concept:name'].apply(list)\n",
    "traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e58c33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 23, 15, ..., 13, 13, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state_pos = traces.apply(len).values\n",
    "hidden_state_pos = hidden_state_pos - 1\n",
    "hidden_state_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8934670f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3354"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_representations = [hidden_states[i-1] for i in hidden_state_pos]\n",
    "trace_representations = np.array(trace_representations)\n",
    "len(trace_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a35e592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3354, 48, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419acf27",
   "metadata": {},
   "source": [
    "# Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8791f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking):\n",
    "    from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments\n",
    "    from pm4py.algo.conformance.alignments.petri_net import variants\n",
    "    from pm4py.objects.petri_net.utils import align_utils\n",
    "    max_events=0\n",
    "    for trace in log:\n",
    "        counter=0\n",
    "        for event in trace:\n",
    "            counter+=1\n",
    "        if counter > max_events:\n",
    "            max_events=counter\n",
    "    parameters={}\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_SYNC_COST_FUNCTION] = list(map(lambda i: .1*i, range(max_events*2)))\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_TRACE_COST_FUNCTION]=list(map(lambda i: align_utils.STD_MODEL_LOG_MOVE_COST-.1*i, range(max_events*2)))\n",
    "    aligned_traces = alignments.apply_log(log, net, initial_marking, final_marking, variant=variants.state_equation_a_star, parameters=parameters)\n",
    "    return aligned_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40c9a48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ebbcdcd2fc40dca1408113a0c643d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/295 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/model/MobisToBe.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_traces = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1b508ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conformance_status_by_fitness(aligned_traces):\n",
    "    conformance_status = []\n",
    "    for alignment in aligned_traces:\n",
    "        fitness = alignment['fitness']\n",
    "        # If the fitness is 1.0, the trace is conforming\n",
    "        if fitness == 1.0:\n",
    "            conformance_status.append(0)\n",
    "        else:\n",
    "            conformance_status.append(1)\n",
    "    return conformance_status\n",
    "\n",
    "# Get the conformance status list from the aligned traces\n",
    "conformance = extract_conformance_status_by_fitness(aligned_traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "326adc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = pd.DataFrame(conformance, columns=['actual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2171bf1e",
   "metadata": {},
   "source": [
    "# Input Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c038061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = ['file travel request', 'check if travel request needs preliminary price inquiry', 'decide on approval requirements', 'check if booking is necessary', 'check if expense documents exist', 'upload travel expense documents', 'file travel expense report', 'confirm travel expense report', 'decide on travel expense approval', 'send original documents to archive', 'calculate payments', 'pay expenses']\n",
    "trace2 = ['file travel request', 'check if travel request needs preliminary price inquiry', 'decide on approval requirements', 'check if booking is necessary', 'check if expense documents exist', 'file travel expense report', 'confirm travel expense report', 'decide on travel expense approval', 'send original documents to archive', 'calculate payments', 'pay expenses']\n",
    "trace3 = ['file travel request', 'check if travel request needs preliminary price inquiry', 'decide on approval requirements', 'forward request to approver', 'decide on request', 'check if booking is necessary', 'check if expense documents exist', 'upload travel expense documents', 'file travel expense report', 'confirm travel expense report', 'decide on travel expense approval', 'send original documents to archive', 'calculate payments', 'pay expenses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee60b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = dataframe.groupby('@@case_index')['concept:name'].apply(list).reset_index(name='trace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3fc4290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_happy_trace(row_trace):\n",
    "    predefined_traces = [trace1, trace2, trace3]\n",
    "    for trace in predefined_traces:\n",
    "        if row_trace == trace:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e286ba1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@@case_index</th>\n",
       "      <th>trace</th>\n",
       "      <th>happy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[file travel request, check if travel request ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[file travel request, check if travel request ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[file travel request, check if travel request ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[file travel request, check if travel request ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[file travel request, check if travel request ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>3349</td>\n",
       "      <td>[file travel request, check if travel request ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350</th>\n",
       "      <td>3350</td>\n",
       "      <td>[file travel request, check if travel request ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3351</th>\n",
       "      <td>3351</td>\n",
       "      <td>[file travel request, check if travel request ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352</th>\n",
       "      <td>3352</td>\n",
       "      <td>[file travel request, check if travel request ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3353</th>\n",
       "      <td>3353</td>\n",
       "      <td>[file travel request, check if travel request ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3354 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      @@case_index                                              trace  happy\n",
       "0                0  [file travel request, check if travel request ...      1\n",
       "1                1  [file travel request, check if travel request ...      0\n",
       "2                2  [file travel request, check if travel request ...      0\n",
       "3                3  [file travel request, check if travel request ...      0\n",
       "4                4  [file travel request, check if travel request ...      0\n",
       "...            ...                                                ...    ...\n",
       "3349          3349  [file travel request, check if travel request ...      1\n",
       "3350          3350  [file travel request, check if travel request ...      0\n",
       "3351          3351  [file travel request, check if travel request ...      1\n",
       "3352          3352  [file travel request, check if travel request ...      1\n",
       "3353          3353  [file travel request, check if travel request ...      1\n",
       "\n",
       "[3354 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped['happy'] = grouped['trace'].apply(is_happy_trace)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9521ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of the happy traces in the results dataframe\n",
    "happy_trace_indices = grouped[grouped['happy'] == 1].index.tolist()\n",
    "\n",
    "# Extract the corresponding coordinates from the trace_representations array\n",
    "happy_trace_coordinates = trace_representations[happy_trace_indices]\n",
    "\n",
    "# Extract unique coordinates\n",
    "unique_happy_trace_coordinates = np.unique(happy_trace_coordinates, axis=0)\n",
    "\n",
    "# Assuming the size of unique_happy_trace_coordinates is 3\n",
    "#happy_trace1, happy_trace2, happy_trace3 = unique_happy_trace_coordinates\n",
    "happy_trace1, happy_trace2, happy_trace3 = unique_happy_trace_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb704ff",
   "metadata": {},
   "source": [
    "# Distance Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ee5f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten each trace representation (7, 100) into a 1D vector of size 700\n",
    "trace_representations = trace_representations.reshape(trace_representations.shape[0], -1)\n",
    "\n",
    "# Now flattened_trace_representations will have shape (13087, 700)\n",
    "happy_trace1 = happy_trace1.flatten()\n",
    "happy_trace2 = happy_trace2.flatten()\n",
    "happy_trace3 = happy_trace3.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cd15eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_trace1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71645897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_representations[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce6f9e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Calculate the distances to each of the happy traces for every trace representation\n",
    "distances_to_happy_traces = []\n",
    "\n",
    "for trace_representation in trace_representations:\n",
    "    distances = [\n",
    "        euclidean(trace_representation, happy_trace1),\n",
    "        euclidean(trace_representation, happy_trace2),\n",
    "        euclidean(trace_representation, happy_trace3)\n",
    "    ]\n",
    "    distances_to_happy_traces.append(distances)\n",
    "\n",
    "# Calculate the average distance to the happy traces for each trace representation\n",
    "avg_distances = [np.mean(distances) for distances in distances_to_happy_traces]\n",
    "\n",
    "# Save the distances in a variable\n",
    "avg_distances_var = np.array(avg_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5910444",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification['distance'] = avg_distances_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba7067",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "364bd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine Threshold\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Filter the DataFrame into conforming and non-conforming subsets\n",
    "conforming_distances = classification[classification['actual'] == 0]['distance']\n",
    "non_conforming_distances = classification[classification['actual'] == 1]['distance']\n",
    "\n",
    "# Determine common bin edges\n",
    "min_distance = min(classification['distance'])\n",
    "max_distance = max(classification['distance'])\n",
    "bin_edges = np.linspace(min_distance, max_distance, num=30)\n",
    "\n",
    "# Combine the data and reshape for k-means\n",
    "all_distances = avg_distances_var\n",
    "all_distances = np.array(all_distances)\n",
    "all_distances_reshaped = all_distances.reshape(-1, 1)\n",
    "\n",
    "# Apply k-means clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(all_distances_reshaped)\n",
    "kmeans_labels = kmeans.labels_\n",
    "\n",
    "# Find the threshold as the average of the two cluster centers\n",
    "threshold_value = np.mean(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2052aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'classification' is a DataFrame and 'threshold_value' is already defined\n",
    "classification['predicted'] = classification['distance'].apply(lambda x: 1 if x > threshold_value else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fd070e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating TP, TN, FP, FN\n",
    "TP = ((classification['actual'] == 1) & (classification['predicted'] == 1)).sum()\n",
    "TN = ((classification['actual'] == 0) & (classification['predicted'] == 0)).sum()\n",
    "FP = ((classification['actual'] == 0) & (classification['predicted'] == 1)).sum()\n",
    "FN = ((classification['actual'] == 1) & (classification['predicted'] == 0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd3f905e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Dev: 0.69\n"
     ]
    }
   ],
   "source": [
    "precision_dev = TP / (TP + FP)\n",
    "print(f\"Precision Dev: {precision_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ff76d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Dev: 0.91\n"
     ]
    }
   ],
   "source": [
    "recall_dev = TP / (TP + FN)\n",
    "print(f\"Recall Dev: {recall_dev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2be910ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision No Dev: 0.87\n"
     ]
    }
   ],
   "source": [
    "precision_no_d = TN / (TN + FN)\n",
    "print(f\"Precision No Dev: {precision_no_d:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e20e5e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall No Dev: 0.59\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall\n",
    "recall_no_d = TN / (TN + FP)\n",
    "print(f\"Recall No Dev: {recall_no_d:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f80181a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_roc = roc_auc_score(classification['actual'], classification['predicted'])\n",
    "print(f\"AUC-ROC: {auc_roc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bfe70c",
   "metadata": {},
   "source": [
    "# Deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79372a48",
   "metadata": {},
   "source": [
    "### a) identify closest trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b71b0f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09a35f72e214e4e966f5d46f3d3d231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/295 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# INPUT TRACE 1\n",
    "\n",
    "\n",
    "\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/input_traces/mobis_trace1.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_input_trace1 = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bef8e8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289ce396f6194092afb9c0a085f35fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/295 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# INPUT TRACE 2\n",
    "\n",
    "\n",
    "\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/input_traces/mobis_trace2.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_input_trace2 = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41e779f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8488a02ee6934e9a939bd0097d98c5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/295 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# INPUT TRACE 3\n",
    "\n",
    "\n",
    "\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/input_traces/mobis_trace3.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_input_trace3 = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51efe467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Euclidean distance\n",
    "def euclidean_distance(arr1, arr2):\n",
    "    return np.linalg.norm(arr1 - arr2)\n",
    "\n",
    "# Prepare a list to store the results\n",
    "distance = []\n",
    "\n",
    "# Iterate through each subarray in one_hot_encoding\n",
    "for subarray in trace_representations:\n",
    "    dist_to_trace1 = euclidean_distance(subarray, happy_trace1)\n",
    "    \n",
    "    distances = [dist_to_trace1]\n",
    "    closest_trace_index = np.argmin(distances)\n",
    "    closest_trace = f'trace_{closest_trace_index + 1}'\n",
    "    \n",
    "    distance.append({\n",
    "        'Distance to Trace 1': dist_to_trace1,\n",
    "        'Closest Trace': closest_trace\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "closest_distance = pd.DataFrame(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c1f415",
   "metadata": {},
   "source": [
    "### b) identify deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "524d8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the merged list\n",
    "aligned_input_trace = []\n",
    "\n",
    "# Iterate through each row of the fitness dataframe\n",
    "for index, row in closest_distance.iterrows():\n",
    "    closest_trace = row['Closest Trace']\n",
    "    \n",
    "    # Append the corresponding alignment to the merged list based on the closest trace\n",
    "    if closest_trace == 'trace_1':\n",
    "        aligned_input_trace.append(aligned_input_trace1[index])\n",
    "    elif closest_trace == 'trace_2':\n",
    "        aligned_input_trace.append(aligned_input_trace2[index])\n",
    "    elif closest_trace == 'trace_3':\n",
    "        aligned_input_trace.append(aligned_input_trace3[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3be04c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract fitness values\n",
    "aligned_traces_fitness = [trace['fitness'] for trace in aligned_traces]\n",
    "aligned_input_traces_fitness = [trace['fitness'] for trace in aligned_input_trace]\n",
    "\n",
    "# Create DataFrame\n",
    "df_fitness = pd.DataFrame({\n",
    "    'ground_truth_fit': aligned_traces_fitness,\n",
    "    'predicted_fit': aligned_input_traces_fitness\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa000d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indices where 'predicted' column has value 1\n",
    "indices_to_keep = classification[classification['actual'] == 1].index.tolist()\n",
    "\n",
    "# Filter the lists to keep only the indices where 'predicted' is 1\n",
    "aligned_input_trace = [aligned_input_trace[i] for i in indices_to_keep]\n",
    "aligned_traces = [aligned_traces[i] for i in indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "380d3013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Log Moves): 0.22\n",
      "Recall (Log Moves): 1.00\n",
      "\n",
      "Precision (Model Moves): 0.1147\n",
      "Recall (Model Moves): 0.0393\n"
     ]
    }
   ],
   "source": [
    "# Function to extract log and model moves excluding (None, >>) and (>>, None)\n",
    "def extract_moves(alignment):\n",
    "    log_moves = [move for move in alignment if move[1] == '>>' and move[0] is not None]\n",
    "    model_moves = [move for move in alignment if move[0] == '>>' and move[1] is not None]\n",
    "    return log_moves, model_moves\n",
    "\n",
    "# Initialize counts for moves\n",
    "total_log_moves = 0\n",
    "total_no_log_moves = 0\n",
    "total_model_moves = 0\n",
    "total_no_model_moves = 0\n",
    "\n",
    "# Initialize counts for TP, FP, FN, TN\n",
    "tp_log_moves = 0\n",
    "fp_log_moves = 0\n",
    "fn_log_moves = 0\n",
    "tn_log_moves = 0\n",
    "\n",
    "tp_model_moves = 0\n",
    "fp_model_moves = 0\n",
    "fn_model_moves = 0\n",
    "tn_model_moves = 0\n",
    "\n",
    "# Iterate through aligned traces and count moves\n",
    "for i, aligned_trace in enumerate(aligned_traces):\n",
    "    log_moves_gt, model_moves_gt = extract_moves(aligned_trace['alignment'])\n",
    "    total_log_moves += len(log_moves_gt)\n",
    "    total_no_log_moves += sum(1 for move in aligned_trace['alignment'] if move[1] != '>>' or move[0] is None)\n",
    "    total_model_moves += len(model_moves_gt)\n",
    "    total_no_model_moves += sum(1 for move in aligned_trace['alignment'] if move[0] != '>>' or move[1] is None)\n",
    "    \n",
    "    if i < len(aligned_input_trace):\n",
    "        log_moves_input, model_moves_input = extract_moves(aligned_input_trace[i]['alignment'])\n",
    "        \n",
    "        # Calculate TP, FP, FN, TN for log moves\n",
    "        tp_log_moves += sum(1 for move in log_moves_gt if move in log_moves_input)\n",
    "        fn_log_moves += sum(1 for move in log_moves_gt if move not in log_moves_input)\n",
    "        fp_log_moves += sum(1 for move in log_moves_input if move not in log_moves_gt)\n",
    "        tn_log_moves += sum(1 for move in aligned_trace['alignment'] if move not in log_moves_gt and move not in log_moves_input and move[1] != '>>' and move[0] != '>>')\n",
    "        \n",
    "        # Calculate TP, FP, FN, TN for model moves\n",
    "        tp_model_moves += sum(1 for move in model_moves_gt if move in model_moves_input)\n",
    "        fn_model_moves += sum(1 for move in model_moves_gt if move not in model_moves_input)\n",
    "        fp_model_moves += sum(1 for move in model_moves_input if move not in model_moves_gt)\n",
    "        tn_model_moves += sum(1 for move in aligned_trace['alignment'] if move not in model_moves_gt and move not in model_moves_input and move[1] != '>>' and move[0] != '>>')\n",
    "\n",
    "# Calculate recall, precision, F1 score for log moves\n",
    "recall_log_moves = tp_log_moves / (tp_log_moves + fn_log_moves) if (tp_log_moves + fn_log_moves) > 0 else 0\n",
    "precision_log_moves = tp_log_moves / (tp_log_moves + fp_log_moves) if (tp_log_moves + fp_log_moves) > 0 else 0\n",
    "f1_score_log_moves = 2 * (precision_log_moves * recall_log_moves) / (precision_log_moves + recall_log_moves) if (precision_log_moves + recall_log_moves) > 0 else 0\n",
    "\n",
    "# Calculate recall, precision, F1 score for model moves\n",
    "recall_model_moves = tp_model_moves / (tp_model_moves + fn_model_moves) if (tp_model_moves + fn_model_moves) > 0 else 0\n",
    "precision_model_moves = tp_model_moves / (tp_model_moves + fp_model_moves) if (tp_model_moves + fp_model_moves) > 0 else 0\n",
    "f1_score_model_moves = 2 * (precision_model_moves * recall_model_moves) / (precision_model_moves + recall_model_moves) if (precision_model_moves + recall_model_moves) > 0 else 0\n",
    "\n",
    "# Calculate dataset balance for log moves\n",
    "log_move_percentage = (total_log_moves / (total_log_moves + total_no_log_moves)) * 100 if (total_log_moves + total_no_log_moves) > 0 else 0\n",
    "no_log_move_percentage = (total_no_log_moves / (total_log_moves + total_no_log_moves)) * 100 if (total_log_moves + total_no_log_moves) > 0 else 0\n",
    "\n",
    "# Calculate dataset balance for model moves\n",
    "model_move_percentage = (total_model_moves / (total_model_moves + total_no_model_moves)) * 100 if (total_model_moves + total_no_model_moves) > 0 else 0\n",
    "no_model_move_percentage = (total_no_model_moves / (total_model_moves + total_no_model_moves)) * 100 if (total_model_moves + total_no_model_moves) > 0 else 0\n",
    "\n",
    "# Print results for log moves\n",
    "print(f\"Precision (Log Moves): {precision_log_moves:.2f}\")\n",
    "print(f\"Recall (Log Moves): {recall_log_moves:.2f}\")\n",
    "print(\"\")\n",
    "\n",
    "# Print results for model moves\n",
    "print(f\"Precision (Model Moves): {precision_model_moves:.4f}\")\n",
    "print(f\"Recall (Model Moves): {recall_model_moves:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8cc7afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the other dataframe using the indices_to_keep\n",
    "df_fitness = df_fitness.loc[indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e645b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error (MSE) is: 0.0033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(df_fitness['ground_truth_fit'], df_fitness['predicted_fit'])\n",
    "\n",
    "# Print the MSE restricted to 4 decimal places\n",
    "print(f\"The Mean Squared Error (MSE) is: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9bb1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
