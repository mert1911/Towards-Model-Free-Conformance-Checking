{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f1af5c",
   "metadata": {},
   "source": [
    "## Import Event Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab9ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s_/ch_w_j2d0sqf6dbdc0_224m40000gq/T/ipykernel_8891/4001343475.py:14: DeprecatedWarning: format_dataframe is deprecated as of 2.3.0 and will be removed in 3.0.0. the format_dataframe function does not need application anymore.\n",
      "  dataframe_log = pm4py.format_dataframe(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the CSV file\n",
    "    dataframe_log = pd.read_csv('../../data/logs/model_A.csv', sep=',')\n",
    "\n",
    "    # Drop the first column without knowing its name\n",
    "    dataframe_log = dataframe_log.drop(dataframe_log.columns[0], axis=1)\n",
    "\n",
    "    # Format the dataframe\n",
    "    dataframe_log = pm4py.format_dataframe(\n",
    "        dataframe_log,\n",
    "        case_id='case:concept:name',\n",
    "        activity_key='concept:name',\n",
    "        timestamp_key='time:timestamp'\n",
    "    )\n",
    "\n",
    "    # Convert the dataframe to event log\n",
    "    log = log_converter.apply(dataframe_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439d11f9",
   "metadata": {},
   "source": [
    "## Ground Truth Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b2d90dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking):\n",
    "    from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments\n",
    "    from pm4py.algo.conformance.alignments.petri_net import variants\n",
    "    from pm4py.objects.petri_net.utils import align_utils\n",
    "    max_events=0\n",
    "    for trace in log:\n",
    "        counter=0\n",
    "        for event in trace:\n",
    "            counter+=1\n",
    "        if counter > max_events:\n",
    "            max_events=counter\n",
    "    parameters={}\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_SYNC_COST_FUNCTION] = list(map(lambda i: .1*i, range(max_events*2)))\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_TRACE_COST_FUNCTION]=list(map(lambda i: align_utils.STD_MODEL_LOG_MOVE_COST-.1*i, range(max_events*2)))\n",
    "    aligned_traces = alignments.apply_log(log, net, initial_marking, final_marking, variant=variants.state_equation_a_star, parameters=parameters)\n",
    "    return aligned_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fda2573c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599cbf79710b48ea893072bd2478505c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/model/Model_A_corrected.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_traces = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526d9461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conform: 0\n",
    "# deviating: 1\n",
    "\n",
    "def extract_conformance_status_by_fitness(aligned_traces):\n",
    "    conformance_status = []\n",
    "    for alignment in aligned_traces:\n",
    "        fitness = alignment['fitness']\n",
    "        # If the fitness is 1.0, the trace is conforming\n",
    "        if fitness == 1.0:\n",
    "            conformance_status.append(0)\n",
    "        else:\n",
    "            conformance_status.append(1)\n",
    "    return conformance_status\n",
    "\n",
    "# Get the conformance status list from the aligned traces\n",
    "conformance = extract_conformance_status_by_fitness(aligned_traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "917fca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = pd.DataFrame(conformance, columns=['actual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba199329",
   "metadata": {},
   "source": [
    "## 1. Encoding (OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "157dbb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Step 1: One-Hot Encoding of Activities\n",
    "mlb = MultiLabelBinarizer()\n",
    "traces = dataframe_log.groupby('@@case_index')['concept:name'].apply(list)\n",
    "one_hot_encoded = mlb.fit_transform(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f0daa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding = np.array(one_hot_encoded.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2171bf1e",
   "metadata": {},
   "source": [
    "## 2. Binary Conformance Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ed5c10",
   "metadata": {},
   "source": [
    "### 2.1 Get Encodings of Input Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0029315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Group by case_index and concatenate the activities to form traces\n",
    "dataframe_log['trace'] = dataframe_log.groupby('@@case_index')['concept:name'].transform(lambda x: ', '.join(x))\n",
    "\n",
    "# Step 3: Count occurrences of each unique trace\n",
    "trace_counts = dataframe_log['trace'].value_counts()\n",
    "\n",
    "# Step 4: Convert to DataFrame and sort by occurrences\n",
    "trace_counts_df = trace_counts.reset_index()\n",
    "trace_counts_df.columns = ['Trace', 'Count']\n",
    "trace_counts_df = trace_counts_df.sort_values(by='Count', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebc5346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = ['A_SUBMITTED', 'A_PARTLYSUBMITTED', 'A_DECLINED']\n",
    "trace2 = ['A_SUBMITTED', 'A_PARTLYSUBMITTED', 'A_PREACCEPTED', 'A_ACCEPTED', 'A_FINALIZED', 'A_CANCELLED']\n",
    "trace3 = ['A_SUBMITTED', 'A_PARTLYSUBMITTED', 'A_PREACCEPTED', 'A_CANCELLED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee60b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = dataframe_log.groupby('@@case_index')['concept:name'].apply(list).reset_index(name='trace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3fc4290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_happy_trace(row_trace):\n",
    "    predefined_traces = [trace1, trace2, trace3]\n",
    "    for trace in predefined_traces:\n",
    "        if row_trace == trace:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e286ba1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@@case_index</th>\n",
       "      <th>trace</th>\n",
       "      <th>happy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[A_SUBMITTED, A_PARTLYSUBMITTED, A_PREACCEPTED...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[A_SUBMITTED, A_PARTLYSUBMITTED, A_PREACCEPTED...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[A_SUBMITTED, A_PARTLYSUBMITTED, A_PREACCEPTED...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[A_SUBMITTED, A_PARTLYSUBMITTED, A_DECLINED]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[A_SUBMITTED, A_PARTLYSUBMITTED, A_DECLINED]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13082</th>\n",
       "      <td>13082</td>\n",
       "      <td>[A_SUBMITTED, A_PARTLYSUBMITTED, A_PREACCEPTED...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13083</th>\n",
       "      <td>13083</td>\n",
       "      <td>[A_SUBMITTED, A_PARTLYSUBMITTED, A_DECLINED]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13084</th>\n",
       "      <td>13084</td>\n",
       "      <td>[A_SUBMITTED, A_PARTLYSUBMITTED, A_DECLINED]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13085</th>\n",
       "      <td>13085</td>\n",
       "      <td>[A_SUBMITTED, A_PARTLYSUBMITTED, A_PREACCEPTED...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13086</th>\n",
       "      <td>13086</td>\n",
       "      <td>[A_SUBMITTED, A_PARTLYSUBMITTED, A_DECLINED]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13087 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       @@case_index                                              trace  happy\n",
       "0                 0  [A_SUBMITTED, A_PARTLYSUBMITTED, A_PREACCEPTED...      0\n",
       "1                 1  [A_SUBMITTED, A_PARTLYSUBMITTED, A_PREACCEPTED...      0\n",
       "2                 2  [A_SUBMITTED, A_PARTLYSUBMITTED, A_PREACCEPTED...      0\n",
       "3                 3       [A_SUBMITTED, A_PARTLYSUBMITTED, A_DECLINED]      1\n",
       "4                 4       [A_SUBMITTED, A_PARTLYSUBMITTED, A_DECLINED]      1\n",
       "...             ...                                                ...    ...\n",
       "13082         13082  [A_SUBMITTED, A_PARTLYSUBMITTED, A_PREACCEPTED...      0\n",
       "13083         13083       [A_SUBMITTED, A_PARTLYSUBMITTED, A_DECLINED]      1\n",
       "13084         13084       [A_SUBMITTED, A_PARTLYSUBMITTED, A_DECLINED]      1\n",
       "13085         13085  [A_SUBMITTED, A_PARTLYSUBMITTED, A_PREACCEPTED...      0\n",
       "13086         13086       [A_SUBMITTED, A_PARTLYSUBMITTED, A_DECLINED]      1\n",
       "\n",
       "[13087 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped['happy'] = grouped['trace'].apply(is_happy_trace)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9521ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of the happy traces in the results dataframe\n",
    "happy_trace_indices = grouped[grouped['happy'] == 1].index.tolist()\n",
    "\n",
    "# Extract the corresponding coordinates from the trace_representations array\n",
    "happy_trace_coordinates = one_hot_encoding[happy_trace_indices]\n",
    "\n",
    "# Extract unique coordinates\n",
    "unique_happy_trace_coordinates = np.unique(happy_trace_coordinates, axis=0)\n",
    "\n",
    "# Assuming the size of unique_happy_trace_coordinates is 3\n",
    "#happy_trace1, happy_trace2, happy_trace3 = unique_happy_trace_coordinates\n",
    "happy_trace1, happy_trace2, happy_trace3 = unique_happy_trace_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb704ff",
   "metadata": {},
   "source": [
    "### 2.2 Distance Measurement (between Event Log Traces and Input Traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce6f9e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Calculate the distances to each of the happy traces for every trace representation\n",
    "distances_to_happy_traces = []\n",
    "\n",
    "for trace_representation in one_hot_encoding:\n",
    "    distances = [\n",
    "        euclidean(trace_representation, happy_trace1),\n",
    "        euclidean(trace_representation, happy_trace2),\n",
    "        euclidean(trace_representation, happy_trace3)\n",
    "    ]\n",
    "    distances_to_happy_traces.append(distances)\n",
    "\n",
    "# Calculate the average distance to the happy traces for each trace representation\n",
    "avg_distances = [np.mean(distances) for distances in distances_to_happy_traces]\n",
    "\n",
    "# Save the distances in a variable\n",
    "avg_distances_var = np.array(avg_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09e1452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification['distance'] = avg_distances_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba7067",
   "metadata": {},
   "source": [
    "### 2.3 Trace Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "364bd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine Threshold\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Filter the DataFrame into conforming and non-conforming subsets\n",
    "conforming_distances = classification[classification['actual'] == 0]['distance']\n",
    "non_conforming_distances = classification[classification['actual'] == 1]['distance']\n",
    "\n",
    "# Determine common bin edges\n",
    "min_distance = min(classification['distance'])\n",
    "max_distance = max(classification['distance'])\n",
    "bin_edges = np.linspace(min_distance, max_distance, num=30)\n",
    "\n",
    "# Combine the data and reshape for k-means\n",
    "all_distances = avg_distances_var\n",
    "all_distances = np.array(all_distances)\n",
    "all_distances_reshaped = all_distances.reshape(-1, 1)\n",
    "\n",
    "# Apply k-means clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(all_distances_reshaped)\n",
    "kmeans_labels = kmeans.labels_\n",
    "\n",
    "# Find the threshold as the average of the two cluster centers\n",
    "threshold_value = np.mean(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "577be216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'classification' is a DataFrame and 'threshold_value' is already defined\n",
    "classification['predicted'] = classification['distance'].apply(lambda x: 1 if x > threshold_value else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7f7ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating TP, TN, FP, FN\n",
    "TP = ((classification['actual'] == 1) & (classification['predicted'] == 1)).sum()\n",
    "TN = ((classification['actual'] == 0) & (classification['predicted'] == 0)).sum()\n",
    "FP = ((classification['actual'] == 0) & (classification['predicted'] == 1)).sum()\n",
    "FN = ((classification['actual'] == 1) & (classification['predicted'] == 0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6a26da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Dev: 0.53\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "print(f\"Precision Dev: {precision:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21fb8ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Dev: 0.75\n"
     ]
    }
   ],
   "source": [
    "recall = TP / (TP + FN)\n",
    "print(f\"Recall Dev: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c67c73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision No Dev: 0.96\n"
     ]
    }
   ],
   "source": [
    "precision = TN / (TN + FN)\n",
    "print(f\"Precision No Dev: {precision:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bae990e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall No Dev: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall\n",
    "recall = TN / (TN + FP)\n",
    "print(f\"Recall No Dev: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35567dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_roc = roc_auc_score(classification['actual'], classification['predicted'])\n",
    "print(f\"AUC-ROC: {auc_roc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938800f4",
   "metadata": {},
   "source": [
    "## 3. Conformance Diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b45d08",
   "metadata": {},
   "source": [
    "### 3.1 identify closest input trace for each event log trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d91e4ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c8ef00b05a414ab29f898566811800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# INPUT TRACE 1\n",
    "\n",
    "\n",
    "\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/input_traces/bpic12_trace1.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_input_trace1 = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b788410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ed394b2cba462a9c7c3b0c5e409af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# INPUT TRACE 2\n",
    "\n",
    "\n",
    "\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/input_traces/bpic12_trace2.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_input_trace2 = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93cfd5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cac2e2321d4a9fae9828352afef244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# INPUT TRACE 3\n",
    "\n",
    "\n",
    "\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/input_traces/bpic12_trace3.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_input_trace3 = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fee90d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Euclidean distance\n",
    "def euclidean_distance(arr1, arr2):\n",
    "    return np.linalg.norm(arr1 - arr2)\n",
    "\n",
    "# Prepare a list to store the results\n",
    "distance = []\n",
    "\n",
    "# Iterate through each subarray in one_hot_encoding\n",
    "for subarray in one_hot_encoding:\n",
    "    dist_to_trace1 = euclidean_distance(subarray, happy_trace1)\n",
    "    dist_to_trace2 = euclidean_distance(subarray, happy_trace2)\n",
    "    dist_to_trace3 = euclidean_distance(subarray, happy_trace3)\n",
    "    \n",
    "    distances = [dist_to_trace1, dist_to_trace2, dist_to_trace3]\n",
    "    closest_trace_index = np.argmin(distances)\n",
    "    closest_trace = f'trace_{closest_trace_index + 1}'\n",
    "    \n",
    "    distance.append({\n",
    "        'Distance to Trace 1': dist_to_trace1,\n",
    "        'Distance to Trace 2': dist_to_trace2,\n",
    "        'Distance to Trace 3': dist_to_trace3,\n",
    "        'Closest Trace': closest_trace\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "closest_distance = pd.DataFrame(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90664795",
   "metadata": {},
   "source": [
    "### 3.2 Generate alignments based on closest input traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be056044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the merged list\n",
    "aligned_input_trace = []\n",
    "\n",
    "# Iterate through each row of the fitness dataframe\n",
    "for index, row in closest_distance.iterrows():\n",
    "    closest_trace = row['Closest Trace']\n",
    "    \n",
    "    # Append the corresponding alignment to the merged list based on the closest trace\n",
    "    if closest_trace == 'trace_1':\n",
    "        aligned_input_trace.append(aligned_input_trace1[index])\n",
    "    elif closest_trace == 'trace_2':\n",
    "        aligned_input_trace.append(aligned_input_trace2[index])\n",
    "    elif closest_trace == 'trace_3':\n",
    "        aligned_input_trace.append(aligned_input_trace3[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "412d02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exlude Alignments where fitness = 1\n",
    "\n",
    "# Extract fitness values\n",
    "aligned_traces_fitness = [trace['fitness'] for trace in aligned_traces]\n",
    "aligned_input_traces_fitness = [trace['fitness'] for trace in aligned_input_trace]\n",
    "\n",
    "# Create DataFrame\n",
    "df_fitness = pd.DataFrame({\n",
    "    'ground_truth_fit': aligned_traces_fitness,\n",
    "    'predicted_fit': aligned_input_traces_fitness\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "262ad599",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_keep = classification[classification['predicted'] == 1].index.tolist()\n",
    "\n",
    "# Filter the lists to keep only the indices where 'predicted' is 1\n",
    "aligned_input_trace = [aligned_input_trace[i] for i in indices_to_keep]\n",
    "aligned_traces = [aligned_traces[i] for i in indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5d2f816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Log Moves): 0.11\n",
      "Recall (Log Moves): 1.00\n",
      "\n",
      "Precision (Model Moves): 0.0000\n",
      "Recall (Model Moves): 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Function to extract log and model moves excluding (None, >>) and (>>, None)\n",
    "def extract_moves(alignment):\n",
    "    log_moves = [move for move in alignment if move[1] == '>>' and move[0] is not None]\n",
    "    model_moves = [move for move in alignment if move[0] == '>>' and move[1] is not None]\n",
    "    return log_moves, model_moves\n",
    "\n",
    "# Initialize counts for moves\n",
    "total_log_moves = 0\n",
    "total_no_log_moves = 0\n",
    "total_model_moves = 0\n",
    "total_no_model_moves = 0\n",
    "\n",
    "# Initialize counts for TP, FP, FN, TN\n",
    "tp_log_moves = 0\n",
    "fp_log_moves = 0\n",
    "fn_log_moves = 0\n",
    "tn_log_moves = 0\n",
    "\n",
    "tp_model_moves = 0\n",
    "fp_model_moves = 0\n",
    "fn_model_moves = 0\n",
    "tn_model_moves = 0\n",
    "\n",
    "# Iterate through aligned traces and count moves\n",
    "for i, aligned_trace in enumerate(aligned_traces):\n",
    "    log_moves_gt, model_moves_gt = extract_moves(aligned_trace['alignment'])\n",
    "    total_log_moves += len(log_moves_gt)\n",
    "    total_no_log_moves += sum(1 for move in aligned_trace['alignment'] if move[1] != '>>' or move[0] is None)\n",
    "    total_model_moves += len(model_moves_gt)\n",
    "    total_no_model_moves += sum(1 for move in aligned_trace['alignment'] if move[0] != '>>' or move[1] is None)\n",
    "    \n",
    "    if i < len(aligned_input_trace):\n",
    "        log_moves_input, model_moves_input = extract_moves(aligned_input_trace[i]['alignment'])\n",
    "        \n",
    "        # Calculate TP, FP, FN, TN for log moves\n",
    "        tp_log_moves += sum(1 for move in log_moves_gt if move in log_moves_input)\n",
    "        fn_log_moves += sum(1 for move in log_moves_gt if move not in log_moves_input)\n",
    "        fp_log_moves += sum(1 for move in log_moves_input if move not in log_moves_gt)\n",
    "        tn_log_moves += sum(1 for move in aligned_trace['alignment'] if move not in log_moves_gt and move not in log_moves_input and move[1] != '>>' and move[0] != '>>')\n",
    "        \n",
    "        # Calculate TP, FP, FN, TN for model moves\n",
    "        tp_model_moves += sum(1 for move in model_moves_gt if move in model_moves_input)\n",
    "        fn_model_moves += sum(1 for move in model_moves_gt if move not in model_moves_input)\n",
    "        fp_model_moves += sum(1 for move in model_moves_input if move not in model_moves_gt)\n",
    "        tn_model_moves += sum(1 for move in aligned_trace['alignment'] if move not in model_moves_gt and move not in model_moves_input and move[1] != '>>' and move[0] != '>>')\n",
    "\n",
    "# Calculate recall, precision, F1 score for log moves\n",
    "recall_log_moves = tp_log_moves / (tp_log_moves + fn_log_moves) if (tp_log_moves + fn_log_moves) > 0 else 0\n",
    "precision_log_moves = tp_log_moves / (tp_log_moves + fp_log_moves) if (tp_log_moves + fp_log_moves) > 0 else 0\n",
    "f1_score_log_moves = 2 * (precision_log_moves * recall_log_moves) / (precision_log_moves + recall_log_moves) if (precision_log_moves + recall_log_moves) > 0 else 0\n",
    "\n",
    "# Calculate recall, precision, F1 score for model moves\n",
    "recall_model_moves = tp_model_moves / (tp_model_moves + fn_model_moves) if (tp_model_moves + fn_model_moves) > 0 else 0\n",
    "precision_model_moves = tp_model_moves / (tp_model_moves + fp_model_moves) if (tp_model_moves + fp_model_moves) > 0 else 0\n",
    "f1_score_model_moves = 2 * (precision_model_moves * recall_model_moves) / (precision_model_moves + recall_model_moves) if (precision_model_moves + recall_model_moves) > 0 else 0\n",
    "\n",
    "# Calculate dataset balance for log moves\n",
    "log_move_percentage = (total_log_moves / (total_log_moves + total_no_log_moves)) * 100 if (total_log_moves + total_no_log_moves) > 0 else 0\n",
    "no_log_move_percentage = (total_no_log_moves / (total_log_moves + total_no_log_moves)) * 100 if (total_log_moves + total_no_log_moves) > 0 else 0\n",
    "\n",
    "# Calculate dataset balance for model moves\n",
    "model_move_percentage = (total_model_moves / (total_model_moves + total_no_model_moves)) * 100 if (total_model_moves + total_no_model_moves) > 0 else 0\n",
    "no_model_move_percentage = (total_no_model_moves / (total_model_moves + total_no_model_moves)) * 100 if (total_model_moves + total_no_model_moves) > 0 else 0\n",
    "\n",
    "# Print results for log moves\n",
    "print(f\"Precision (Log Moves): {precision_log_moves:.2f}\")\n",
    "print(f\"Recall (Log Moves): {recall_log_moves:.2f}\")\n",
    "print(\"\")\n",
    "\n",
    "# Print results for model moves\n",
    "print(f\"Precision (Model Moves): {precision_model_moves:.4f}\")\n",
    "print(f\"Recall (Model Moves): {recall_model_moves:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d942ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the other dataframe using the indices_to_keep\n",
    "df_fitness = df_fitness.loc[indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45335b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error (MSE) is: 0.0448\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(df_fitness['ground_truth_fit'], df_fitness['predicted_fit'])\n",
    "\n",
    "# Print the MSE restricted to 4 decimal places\n",
    "print(f\"The Mean Squared Error (MSE) is: {mse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
