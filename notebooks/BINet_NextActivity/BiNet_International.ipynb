{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Event Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pm4py/util/dt_parsing/parser.py:76: UserWarning: ISO8601 strings are not fully supported with strpfromiso for Python versions below 3.11\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc08d4aea276426da5c63d1b370f57e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>org:role</th>\n",
       "      <th>case:Permit travel permit number</th>\n",
       "      <th>case:DeclarationNumber</th>\n",
       "      <th>case:Amount</th>\n",
       "      <th>case:RequestedAmount</th>\n",
       "      <th>case:Permit TaskNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>case:Permit OrganizationalEntity</th>\n",
       "      <th>case:travel permit number</th>\n",
       "      <th>case:Permit RequestedBudget</th>\n",
       "      <th>case:id</th>\n",
       "      <th>case:Permit ID</th>\n",
       "      <th>case:Permit id</th>\n",
       "      <th>case:BudgetNumber</th>\n",
       "      <th>case:Permit ActivityNumber</th>\n",
       "      <th>case:AdjustedAmount</th>\n",
       "      <th>@@case_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rv_travel permit 76455_6</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Start trip</td>\n",
       "      <td>2016-10-04 22:00:00+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>travel permit number 76456</td>\n",
       "      <td>declaration number 76458</td>\n",
       "      <td>39.664561</td>\n",
       "      <td>39.664561</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>organizational unit 65458</td>\n",
       "      <td>travel permit number 76456</td>\n",
       "      <td>41.613445</td>\n",
       "      <td>declaration 76457</td>\n",
       "      <td>travel permit 76455</td>\n",
       "      <td>travel permit 76455</td>\n",
       "      <td>budget 144133</td>\n",
       "      <td>activity 46005</td>\n",
       "      <td>39.664561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rv_travel permit 76455_7</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>End trip</td>\n",
       "      <td>2016-10-04 22:00:00+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>travel permit number 76456</td>\n",
       "      <td>declaration number 76458</td>\n",
       "      <td>39.664561</td>\n",
       "      <td>39.664561</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>organizational unit 65458</td>\n",
       "      <td>travel permit number 76456</td>\n",
       "      <td>41.613445</td>\n",
       "      <td>declaration 76457</td>\n",
       "      <td>travel permit 76455</td>\n",
       "      <td>travel permit 76455</td>\n",
       "      <td>budget 144133</td>\n",
       "      <td>activity 46005</td>\n",
       "      <td>39.664561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>st_step 76459_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Permit SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2017-04-06 11:32:10+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>travel permit number 76456</td>\n",
       "      <td>declaration number 76458</td>\n",
       "      <td>39.664561</td>\n",
       "      <td>39.664561</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>organizational unit 65458</td>\n",
       "      <td>travel permit number 76456</td>\n",
       "      <td>41.613445</td>\n",
       "      <td>declaration 76457</td>\n",
       "      <td>travel permit 76455</td>\n",
       "      <td>travel permit 76455</td>\n",
       "      <td>budget 144133</td>\n",
       "      <td>activity 46005</td>\n",
       "      <td>39.664561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>st_step 76460_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Permit FINAL_APPROVED by SUPERVISOR</td>\n",
       "      <td>2017-04-06 11:32:28+00:00</td>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>travel permit number 76456</td>\n",
       "      <td>declaration number 76458</td>\n",
       "      <td>39.664561</td>\n",
       "      <td>39.664561</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>organizational unit 65458</td>\n",
       "      <td>travel permit number 76456</td>\n",
       "      <td>41.613445</td>\n",
       "      <td>declaration 76457</td>\n",
       "      <td>travel permit 76455</td>\n",
       "      <td>travel permit 76455</td>\n",
       "      <td>budget 144133</td>\n",
       "      <td>activity 46005</td>\n",
       "      <td>39.664561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>st_step 76461_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2017-04-07 11:38:14+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>travel permit number 76456</td>\n",
       "      <td>declaration number 76458</td>\n",
       "      <td>39.664561</td>\n",
       "      <td>39.664561</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>organizational unit 65458</td>\n",
       "      <td>travel permit number 76456</td>\n",
       "      <td>41.613445</td>\n",
       "      <td>declaration 76457</td>\n",
       "      <td>travel permit 76455</td>\n",
       "      <td>travel permit 76455</td>\n",
       "      <td>budget 144133</td>\n",
       "      <td>activity 46005</td>\n",
       "      <td>39.664561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72146</th>\n",
       "      <td>st_step 13239_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration SUBMITTED by EMPLOYEE</td>\n",
       "      <td>2018-12-18 14:06:50+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>travel permit number 13227</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>task 427</td>\n",
       "      <td>...</td>\n",
       "      <td>organizational unit 65455</td>\n",
       "      <td>travel permit number 13227</td>\n",
       "      <td>1727.559756</td>\n",
       "      <td>declaration 13232</td>\n",
       "      <td>travel permit 13226</td>\n",
       "      <td>travel permit 13226</td>\n",
       "      <td>budget 147449</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72147</th>\n",
       "      <td>st_step 13241_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration REJECTED by ADMINISTRATION</td>\n",
       "      <td>2018-12-18 14:06:57+00:00</td>\n",
       "      <td>ADMINISTRATION</td>\n",
       "      <td>travel permit number 13227</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>task 427</td>\n",
       "      <td>...</td>\n",
       "      <td>organizational unit 65455</td>\n",
       "      <td>travel permit number 13227</td>\n",
       "      <td>1727.559756</td>\n",
       "      <td>declaration 13232</td>\n",
       "      <td>travel permit 13226</td>\n",
       "      <td>travel permit 13226</td>\n",
       "      <td>budget 147449</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72148</th>\n",
       "      <td>st_step 13240_0</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Declaration REJECTED by EMPLOYEE</td>\n",
       "      <td>2018-12-19 13:05:36+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>travel permit number 13227</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>task 427</td>\n",
       "      <td>...</td>\n",
       "      <td>organizational unit 65455</td>\n",
       "      <td>travel permit number 13227</td>\n",
       "      <td>1727.559756</td>\n",
       "      <td>declaration 13232</td>\n",
       "      <td>travel permit 13226</td>\n",
       "      <td>travel permit 13226</td>\n",
       "      <td>budget 147449</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72149</th>\n",
       "      <td>rv_travel permit 13226_6</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>Start trip</td>\n",
       "      <td>2019-02-18 23:00:00+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>travel permit number 13227</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>task 427</td>\n",
       "      <td>...</td>\n",
       "      <td>organizational unit 65455</td>\n",
       "      <td>travel permit number 13227</td>\n",
       "      <td>1727.559756</td>\n",
       "      <td>declaration 13232</td>\n",
       "      <td>travel permit 13226</td>\n",
       "      <td>travel permit 13226</td>\n",
       "      <td>budget 147449</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72150</th>\n",
       "      <td>rv_travel permit 13226_7</td>\n",
       "      <td>STAFF MEMBER</td>\n",
       "      <td>End trip</td>\n",
       "      <td>2019-02-23 23:00:00+00:00</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>travel permit number 13227</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>task 427</td>\n",
       "      <td>...</td>\n",
       "      <td>organizational unit 65455</td>\n",
       "      <td>travel permit number 13227</td>\n",
       "      <td>1727.559756</td>\n",
       "      <td>declaration 13232</td>\n",
       "      <td>travel permit 13226</td>\n",
       "      <td>travel permit 13226</td>\n",
       "      <td>budget 147449</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72151 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id  org:resource  \\\n",
       "0      rv_travel permit 76455_6  STAFF MEMBER   \n",
       "1      rv_travel permit 76455_7  STAFF MEMBER   \n",
       "2               st_step 76459_0  STAFF MEMBER   \n",
       "3               st_step 76460_0  STAFF MEMBER   \n",
       "4               st_step 76461_0  STAFF MEMBER   \n",
       "...                         ...           ...   \n",
       "72146           st_step 13239_0  STAFF MEMBER   \n",
       "72147           st_step 13241_0  STAFF MEMBER   \n",
       "72148           st_step 13240_0  STAFF MEMBER   \n",
       "72149  rv_travel permit 13226_6  STAFF MEMBER   \n",
       "72150  rv_travel permit 13226_7  STAFF MEMBER   \n",
       "\n",
       "                                 concept:name            time:timestamp  \\\n",
       "0                                  Start trip 2016-10-04 22:00:00+00:00   \n",
       "1                                    End trip 2016-10-04 22:00:00+00:00   \n",
       "2                Permit SUBMITTED by EMPLOYEE 2017-04-06 11:32:10+00:00   \n",
       "3         Permit FINAL_APPROVED by SUPERVISOR 2017-04-06 11:32:28+00:00   \n",
       "4           Declaration SUBMITTED by EMPLOYEE 2017-04-07 11:38:14+00:00   \n",
       "...                                       ...                       ...   \n",
       "72146       Declaration SUBMITTED by EMPLOYEE 2018-12-18 14:06:50+00:00   \n",
       "72147  Declaration REJECTED by ADMINISTRATION 2018-12-18 14:06:57+00:00   \n",
       "72148        Declaration REJECTED by EMPLOYEE 2018-12-19 13:05:36+00:00   \n",
       "72149                              Start trip 2019-02-18 23:00:00+00:00   \n",
       "72150                                End trip 2019-02-23 23:00:00+00:00   \n",
       "\n",
       "             org:role case:Permit travel permit number  \\\n",
       "0            EMPLOYEE       travel permit number 76456   \n",
       "1            EMPLOYEE       travel permit number 76456   \n",
       "2            EMPLOYEE       travel permit number 76456   \n",
       "3          SUPERVISOR       travel permit number 76456   \n",
       "4            EMPLOYEE       travel permit number 76456   \n",
       "...               ...                              ...   \n",
       "72146        EMPLOYEE       travel permit number 13227   \n",
       "72147  ADMINISTRATION       travel permit number 13227   \n",
       "72148        EMPLOYEE       travel permit number 13227   \n",
       "72149        EMPLOYEE       travel permit number 13227   \n",
       "72150        EMPLOYEE       travel permit number 13227   \n",
       "\n",
       "         case:DeclarationNumber  case:Amount  case:RequestedAmount  \\\n",
       "0      declaration number 76458    39.664561             39.664561   \n",
       "1      declaration number 76458    39.664561             39.664561   \n",
       "2      declaration number 76458    39.664561             39.664561   \n",
       "3      declaration number 76458    39.664561             39.664561   \n",
       "4      declaration number 76458    39.664561             39.664561   \n",
       "...                         ...          ...                   ...   \n",
       "72146                   UNKNOWN     0.000000              0.000000   \n",
       "72147                   UNKNOWN     0.000000              0.000000   \n",
       "72148                   UNKNOWN     0.000000              0.000000   \n",
       "72149                   UNKNOWN     0.000000              0.000000   \n",
       "72150                   UNKNOWN     0.000000              0.000000   \n",
       "\n",
       "      case:Permit TaskNumber  ... case:Permit OrganizationalEntity  \\\n",
       "0                    UNKNOWN  ...        organizational unit 65458   \n",
       "1                    UNKNOWN  ...        organizational unit 65458   \n",
       "2                    UNKNOWN  ...        organizational unit 65458   \n",
       "3                    UNKNOWN  ...        organizational unit 65458   \n",
       "4                    UNKNOWN  ...        organizational unit 65458   \n",
       "...                      ...  ...                              ...   \n",
       "72146               task 427  ...        organizational unit 65455   \n",
       "72147               task 427  ...        organizational unit 65455   \n",
       "72148               task 427  ...        organizational unit 65455   \n",
       "72149               task 427  ...        organizational unit 65455   \n",
       "72150               task 427  ...        organizational unit 65455   \n",
       "\n",
       "        case:travel permit number case:Permit RequestedBudget  \\\n",
       "0      travel permit number 76456                   41.613445   \n",
       "1      travel permit number 76456                   41.613445   \n",
       "2      travel permit number 76456                   41.613445   \n",
       "3      travel permit number 76456                   41.613445   \n",
       "4      travel permit number 76456                   41.613445   \n",
       "...                           ...                         ...   \n",
       "72146  travel permit number 13227                 1727.559756   \n",
       "72147  travel permit number 13227                 1727.559756   \n",
       "72148  travel permit number 13227                 1727.559756   \n",
       "72149  travel permit number 13227                 1727.559756   \n",
       "72150  travel permit number 13227                 1727.559756   \n",
       "\n",
       "                 case:id       case:Permit ID       case:Permit id  \\\n",
       "0      declaration 76457  travel permit 76455  travel permit 76455   \n",
       "1      declaration 76457  travel permit 76455  travel permit 76455   \n",
       "2      declaration 76457  travel permit 76455  travel permit 76455   \n",
       "3      declaration 76457  travel permit 76455  travel permit 76455   \n",
       "4      declaration 76457  travel permit 76455  travel permit 76455   \n",
       "...                  ...                  ...                  ...   \n",
       "72146  declaration 13232  travel permit 13226  travel permit 13226   \n",
       "72147  declaration 13232  travel permit 13226  travel permit 13226   \n",
       "72148  declaration 13232  travel permit 13226  travel permit 13226   \n",
       "72149  declaration 13232  travel permit 13226  travel permit 13226   \n",
       "72150  declaration 13232  travel permit 13226  travel permit 13226   \n",
       "\n",
       "       case:BudgetNumber case:Permit ActivityNumber case:AdjustedAmount  \\\n",
       "0          budget 144133             activity 46005           39.664561   \n",
       "1          budget 144133             activity 46005           39.664561   \n",
       "2          budget 144133             activity 46005           39.664561   \n",
       "3          budget 144133             activity 46005           39.664561   \n",
       "4          budget 144133             activity 46005           39.664561   \n",
       "...                  ...                        ...                 ...   \n",
       "72146      budget 147449                    UNKNOWN            0.000000   \n",
       "72147      budget 147449                    UNKNOWN            0.000000   \n",
       "72148      budget 147449                    UNKNOWN            0.000000   \n",
       "72149      budget 147449                    UNKNOWN            0.000000   \n",
       "72150      budget 147449                    UNKNOWN            0.000000   \n",
       "\n",
       "      @@case_index  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "72146         6448  \n",
       "72147         6448  \n",
       "72148         6448  \n",
       "72149         6448  \n",
       "72150         6448  \n",
       "\n",
       "[72151 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the XES file\n",
    "    dataframe_log = pm4py.read_xes('../../data/logs/InternationalDeclarations.xes')\n",
    "\n",
    "    # If 'log' is already a DataFrame, add the @@case_index column directly\n",
    "    case_indices = {case_id: idx for idx, case_id in enumerate(dataframe_log['case:concept:name'].unique())}\n",
    "    dataframe_log['@@case_index'] = dataframe_log['case:concept:name'].map(case_indices)\n",
    "    \n",
    "     # Convert the dataframe to event log\n",
    "    log = log_converter.apply(dataframe_log)\n",
    "    \n",
    "dataframe_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop unnessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_log = dataframe_log.drop(columns=['case:Permit ActivityNumber'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:BudgetNumber'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:Permit ID'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:id'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:travel permit number'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:concept:name'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:Permit ProjectNumber'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:Permit TaskNumber'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:DeclarationNumber'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:Permit travel permit number'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:Amount'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:OriginalAmount'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:AdjustedAmount'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:Permit id'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:Permit RequestedBudget'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:Permit OrganizationalEntity'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:Permit BudgetNumber'])\n",
    "dataframe_log = dataframe_log.drop(columns=['case:RequestedAmount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Convert to datetime format\n",
    "dataframe_log['time:timestamp'] = pd.to_datetime(dataframe_log['time:timestamp'])\n",
    "\n",
    "# Calculate elapsed time since the start of each case\n",
    "dataframe_log['start_time'] = dataframe_log.groupby('@@case_index')['time:timestamp'].transform('min')\n",
    "dataframe_log['elapsed_time'] = (dataframe_log['time:timestamp'] - dataframe_log['start_time']).dt.total_seconds()\n",
    "\n",
    "# Normalize the elapsed time in minutes\n",
    "scaler = StandardScaler()\n",
    "dataframe_log['standardized_elapsed_time'] = scaler.fit_transform(dataframe_log[['elapsed_time']])\n",
    "\n",
    "dataframe_log = dataframe_log.drop(columns=['start_time'])\n",
    "dataframe_log = dataframe_log.drop(columns=['elapsed_time'])\n",
    "dataframe_log = dataframe_log.drop(columns=['time:timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(dataframe_log['id'])\n",
    "dataframe_log['id'] = codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(dataframe_log['org:resource'])\n",
    "dataframe_log['org:resource'] = codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(dataframe_log['concept:name'])\n",
    "dataframe_log['concept:name'] = codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(dataframe_log['org:role'])\n",
    "dataframe_log['org:role'] = codes + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = dataframe_log[['id', '@@case_index']]\n",
    "df_resource = dataframe_log[['org:resource', '@@case_index']]\n",
    "df_activity = dataframe_log[['concept:name', '@@case_index']]\n",
    "df_role = dataframe_log[['org:role', '@@case_index']]\n",
    "df_timestamp = dataframe_log[['standardized_elapsed_time', '@@case_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 16:34:32.706114: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def generate_prefix_windows(df, case_id_column='@@case_index', max_len=None):\n",
    "    windows = []\n",
    "    targets = []\n",
    "    case_indices = []\n",
    "    \n",
    "    for case_id in df[case_id_column].unique():\n",
    "        case_data = df[df[case_id_column] == case_id].drop(columns=[case_id_column]).to_numpy()\n",
    "        \n",
    "        # Optional: Make sure to sort the case data if there's an implicit order (e.g., by timestamps)\n",
    "        # case_data = case_data.sort_values(by='timestamp_column').to_numpy()  # Uncomment and adjust if needed\n",
    "        \n",
    "        for i in range(1, len(case_data)):\n",
    "            window = case_data[:i]\n",
    "            target = case_data[i]\n",
    "            windows.append(window)\n",
    "            targets.append(target)\n",
    "            case_indices.append(case_id)\n",
    "    \n",
    "    if max_len is None:\n",
    "        max_len = max(len(window) for window in windows)\n",
    "    \n",
    "    # Pad sequences\n",
    "    windows_padded = pad_sequences(windows, maxlen=max_len, padding='post', dtype='float32')\n",
    "    \n",
    "    # Convert targets to numpy array\n",
    "    targets_array = np.array(targets, dtype='float32')\n",
    "    case_indices_array = np.array(case_indices)\n",
    "    \n",
    "    return windows_padded, targets_array, case_indices_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_id, targets_id, case_indices = generate_prefix_windows(df_id)\n",
    "windows_resource, targets_resource, case_indices = generate_prefix_windows(df_resource)\n",
    "windows_activity, targets_activity, case_indices = generate_prefix_windows(df_activity)\n",
    "windows_role, targets_role, case_indices = generate_prefix_windows(df_role)\n",
    "windows_timestamp, targets_timestamp, case_indices = generate_prefix_windows(df_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separate Inputs for Each Attribute\n",
    "- Each attribute is passed through an embedding layer\n",
    "- Each attribute has its corresponding GRU encoder\n",
    "- Selective Concatenation: After encoding, the outputs of these GRU layers are concatenated. However, this concatenation is selective, meaning it is structured in a way that prepares the data for effective synthesis without leaking information from the future (next event attributes)\n",
    "- Decoder GRUs: Integrated Decoding: Post-concatenation, the combined attributes are processed through decoder GRU layers. These layers are tasked with integrating the data from different attributes and preparing it for final prediction. This step is where BINet v3 distinguishes itself by effectively using the interdependencies between different attributes to enhance prediction accuracy.\n",
    "- Output Layer: Softmax Output for Each Attribute: For each attribute of the next event, a softmax layer predicts a probability distribution over all possible values. This allows the model to output the most likely next event and its attributes based on the learned dependencies and the history encoded by the GRUs.\n",
    "- E: maximum case length\n",
    "- We train BINet with a GRU size of 2E (two times the maximum case length)\n",
    "- on mini batches of size 500 for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the @@case_index column and count the rows in each group\n",
    "case_lengths = dataframe_log.groupby('@@case_index').size()\n",
    "\n",
    "# Find the maximum value among the case lengths\n",
    "E = case_lengths.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " id_input (InputLayer)       [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " resource_input (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " activity_input (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " role_input (InputLayer)     [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " id_embedding (Embedding)    (None, None, 50)             3453700   ['id_input[0][0]']            \n",
      "                                                                                                  \n",
      " resource_embedding (Embedd  (None, None, 50)             150       ['resource_input[0][0]']      \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " activity_embedding (Embedd  (None, None, 50)             1750      ['activity_input[0][0]']      \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " role_embedding (Embedding)  (None, None, 50)             450       ['role_input[0][0]']          \n",
      "                                                                                                  \n",
      " timestamp_input (InputLaye  [(None, None, 1)]            0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " id_encoder (GRU)            (None, None, 54)             17172     ['id_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " resource_encoder (GRU)      (None, None, 54)             17172     ['resource_embedding[0][0]']  \n",
      "                                                                                                  \n",
      " activity_encoder (GRU)      (None, None, 54)             17172     ['activity_embedding[0][0]']  \n",
      "                                                                                                  \n",
      " role_encoder (GRU)          (None, None, 54)             17172     ['role_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " timestamp_encoder (GRU)     (None, None, 54)             9234      ['timestamp_input[0][0]']     \n",
      "                                                                                                  \n",
      " bn_id (BatchNormalization)  (None, None, 54)             216       ['id_encoder[0][0]']          \n",
      "                                                                                                  \n",
      " bn_resource (BatchNormaliz  (None, None, 54)             216       ['resource_encoder[0][0]']    \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " bn_activity (BatchNormaliz  (None, None, 54)             216       ['activity_encoder[0][0]']    \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " bn_role (BatchNormalizatio  (None, None, 54)             216       ['role_encoder[0][0]']        \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " bn_timestamp (BatchNormali  (None, None, 54)             216       ['timestamp_encoder[0][0]']   \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_encodings (Con  (None, None, 270)            0         ['bn_id[0][0]',               \n",
      " catenate)                                                           'bn_resource[0][0]',         \n",
      "                                                                     'bn_activity[0][0]',         \n",
      "                                                                     'bn_role[0][0]',             \n",
      "                                                                     'bn_timestamp[0][0]']        \n",
      "                                                                                                  \n",
      " decoder_gru (GRU)           (None, 54)                   52812     ['concatenate_encodings[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 54)                   0         ['decoder_gru[0][0]']         \n",
      "                                                                                                  \n",
      " output_id (Dense)           (None, 69074)                3799070   ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " output_resource (Dense)     (None, 3)                    165       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " output_activity (Dense)     (None, 35)                   1925      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " output_role (Dense)         (None, 9)                    495       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " output_timestamp (Dense)    (None, 1)                    55        ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7389574 (28.19 MB)\n",
      "Trainable params: 7389034 (28.19 MB)\n",
      "Non-trainable params: 540 (2.11 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Embedding, Dense, Dropout, Concatenate, BatchNormalization\n",
    "\n",
    "def create_binetv3(num_ids, num_resources, num_activities, num_roles, embedding_dim, gru_units, dropout_rate):\n",
    "    # Input layers for each attribute\n",
    "    input_id = Input(shape=(None,), name='id_input')\n",
    "    input_resource = Input(shape=(None,), name='resource_input')\n",
    "    input_activity = Input(shape=(None,), name='activity_input')\n",
    "    input_role = Input(shape=(None,), name='role_input')\n",
    "    input_timestamp = Input(shape=(None, 1), name='timestamp_input')\n",
    "\n",
    "    # Embedding layers for categorical attributes\n",
    "    embedding_id = Embedding(input_dim=num_ids + 1, output_dim=embedding_dim, mask_zero=True, name='id_embedding')(input_id)\n",
    "    embedding_resource = Embedding(input_dim=num_resources + 1, output_dim=embedding_dim, mask_zero=True, name='resource_embedding')(input_resource)\n",
    "    embedding_activity = Embedding(input_dim=num_activities + 1, output_dim=embedding_dim, mask_zero=True, name='activity_embedding')(input_activity)\n",
    "    embedding_role = Embedding(input_dim=num_roles + 1, output_dim=embedding_dim, mask_zero=True, name='role_embedding')(input_role)\n",
    "\n",
    "    # Encoder GRUs with Batch Normalization for categorical attributes\n",
    "    encoded_id = GRU(units=gru_units, return_sequences=True, name='id_encoder')(embedding_id)\n",
    "    bn_id = BatchNormalization(name='bn_id')(encoded_id)\n",
    "    encoded_resource = GRU(units=gru_units, return_sequences=True, name='resource_encoder')(embedding_resource)\n",
    "    bn_resource = BatchNormalization(name='bn_resource')(encoded_resource)\n",
    "    encoded_activity = GRU(units=gru_units, return_sequences=True, name='activity_encoder')(embedding_activity)\n",
    "    bn_activity = BatchNormalization(name='bn_activity')(encoded_activity)\n",
    "    encoded_role = GRU(units=gru_units, return_sequences=True, name='role_encoder')(embedding_role)\n",
    "    bn_role = BatchNormalization(name='bn_role')(encoded_role)\n",
    "\n",
    "    # Encoder GRU with Batch Normalization for continuous attribute\n",
    "    encoded_timestamp = GRU(units=gru_units, return_sequences=True, name='timestamp_encoder')(input_timestamp)\n",
    "    bn_timestamp = BatchNormalization(name='bn_timestamp')(encoded_timestamp)\n",
    "\n",
    "    # Concatenation of encoded outputs\n",
    "    concatenated = Concatenate(name='concatenate_encodings')([bn_id, bn_resource, bn_activity, bn_role, bn_timestamp])\n",
    "\n",
    "    # Decoder GRU\n",
    "    decoder_output = GRU(units=gru_units, return_sequences=False, name='decoder_gru')(concatenated)\n",
    "    dropout_layer = Dropout(rate=dropout_rate, name='dropout')(decoder_output)\n",
    "\n",
    "    # Output layers for predicting the next event's attributes\n",
    "    output_id = Dense(num_ids + 1, activation='softmax', name='output_id')(dropout_layer)\n",
    "    output_resource = Dense(num_resources + 1, activation='softmax', name='output_resource')(dropout_layer)\n",
    "    output_activity = Dense(num_activities + 1, activation='softmax', name='output_activity')(dropout_layer)\n",
    "    output_role = Dense(num_roles + 1, activation='softmax', name='output_role')(dropout_layer)\n",
    "    output_timestamp = Dense(1, activation='linear', name='output_timestamp')(dropout_layer)\n",
    "\n",
    "    # Building the model\n",
    "    model = Model(inputs=[input_id, input_resource, input_activity, input_role, input_timestamp], outputs=[output_id, output_resource, output_activity, output_role, output_timestamp])\n",
    "    model.compile(\n",
    "        optimizer='adam', \n",
    "        loss={\n",
    "            'output_id': 'categorical_crossentropy',\n",
    "            'output_resource': 'categorical_crossentropy', \n",
    "            'output_activity': 'categorical_crossentropy',\n",
    "            'output_role': 'categorical_crossentropy',\n",
    "            'output_timestamp': 'mse'\n",
    "        },\n",
    "        metrics={\n",
    "            'output_id': ['accuracy'],\n",
    "            'output_resource': ['accuracy'], \n",
    "            'output_activity': ['accuracy'],\n",
    "            'output_role': ['accuracy'],\n",
    "            'output_timestamp': ['mse']\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Parameters\n",
    "gru_units = int(2 * E) \n",
    "num_ids = dataframe_log['id'].max()\n",
    "num_resources = dataframe_log['org:resource'].max()\n",
    "num_activities = dataframe_log['concept:name'].max()\n",
    "num_roles = dataframe_log['org:role'].max()\n",
    "embedding_dim = 50\n",
    "dropout_rate = 0.2\n",
    "model = create_binetv3(num_ids, num_resources, num_activities, num_roles, embedding_dim, gru_units, dropout_rate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " resource_input (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " activity_input (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " role_input (InputLayer)     [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " resource_embedding (Embedd  (None, None, 50)             150       ['resource_input[0][0]']      \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " activity_embedding (Embedd  (None, None, 50)             1750      ['activity_input[0][0]']      \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " role_embedding (Embedding)  (None, None, 50)             450       ['role_input[0][0]']          \n",
      "                                                                                                  \n",
      " timestamp_input (InputLaye  [(None, None, 1)]            0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " resource_encoder (GRU)      (None, None, 54)             17172     ['resource_embedding[0][0]']  \n",
      "                                                                                                  \n",
      " activity_encoder (GRU)      (None, None, 54)             17172     ['activity_embedding[0][0]']  \n",
      "                                                                                                  \n",
      " role_encoder (GRU)          (None, None, 54)             17172     ['role_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " timestamp_encoder (GRU)     (None, None, 54)             9234      ['timestamp_input[0][0]']     \n",
      "                                                                                                  \n",
      " bn_resource (BatchNormaliz  (None, None, 54)             216       ['resource_encoder[0][0]']    \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " bn_activity (BatchNormaliz  (None, None, 54)             216       ['activity_encoder[0][0]']    \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " bn_role (BatchNormalizatio  (None, None, 54)             216       ['role_encoder[0][0]']        \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " bn_timestamp (BatchNormali  (None, None, 54)             216       ['timestamp_encoder[0][0]']   \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_encodings (Con  (None, None, 216)            0         ['bn_resource[0][0]',         \n",
      " catenate)                                                           'bn_activity[0][0]',         \n",
      "                                                                     'bn_role[0][0]',             \n",
      "                                                                     'bn_timestamp[0][0]']        \n",
      "                                                                                                  \n",
      " decoder_gru (GRU)           (None, 54)                   44064     ['concatenate_encodings[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 54)                   0         ['decoder_gru[0][0]']         \n",
      "                                                                                                  \n",
      " output_resource (Dense)     (None, 3)                    165       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " output_activity (Dense)     (None, 35)                   1925      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " output_role (Dense)         (None, 9)                    495       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " output_timestamp (Dense)    (None, 1)                    55        ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 110668 (432.30 KB)\n",
      "Trainable params: 110236 (430.61 KB)\n",
      "Non-trainable params: 432 (1.69 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Embedding, Dense, Dropout, Concatenate, BatchNormalization\n",
    "\n",
    "def create_binetv3(num_resources, num_activities, num_roles, embedding_dim, gru_units, dropout_rate):\n",
    "    # Input layers for each attribute\n",
    "    input_resource = Input(shape=(None,), name='resource_input')\n",
    "    input_activity = Input(shape=(None,), name='activity_input')\n",
    "    input_role = Input(shape=(None,), name='role_input')\n",
    "    input_timestamp = Input(shape=(None, 1), name='timestamp_input')\n",
    "\n",
    "    # Embedding layers for categorical attributes\n",
    "    embedding_resource = Embedding(input_dim=num_resources + 1, output_dim=embedding_dim, mask_zero=True, name='resource_embedding')(input_resource)\n",
    "    embedding_activity = Embedding(input_dim=num_activities + 1, output_dim=embedding_dim, mask_zero=True, name='activity_embedding')(input_activity)\n",
    "    embedding_role = Embedding(input_dim=num_roles + 1, output_dim=embedding_dim, mask_zero=True, name='role_embedding')(input_role)\n",
    "\n",
    "    # Encoder GRUs with Batch Normalization for categorical attributes\n",
    "    encoded_resource = GRU(units=gru_units, return_sequences=True, name='resource_encoder')(embedding_resource)\n",
    "    bn_resource = BatchNormalization(name='bn_resource')(encoded_resource)\n",
    "    encoded_activity = GRU(units=gru_units, return_sequences=True, name='activity_encoder')(embedding_activity)\n",
    "    bn_activity = BatchNormalization(name='bn_activity')(encoded_activity)\n",
    "    encoded_role = GRU(units=gru_units, return_sequences=True, name='role_encoder')(embedding_role)\n",
    "    bn_role = BatchNormalization(name='bn_role')(encoded_role)\n",
    "\n",
    "    # Encoder GRU with Batch Normalization for continuous attribute\n",
    "    encoded_timestamp = GRU(units=gru_units, return_sequences=True, name='timestamp_encoder')(input_timestamp)\n",
    "    bn_timestamp = BatchNormalization(name='bn_timestamp')(encoded_timestamp)\n",
    "\n",
    "    # Concatenation of encoded outputs\n",
    "    concatenated = Concatenate(name='concatenate_encodings')([bn_resource, bn_activity, bn_role, bn_timestamp])\n",
    "\n",
    "    # Decoder GRU\n",
    "    decoder_output = GRU(units=gru_units, return_sequences=False, name='decoder_gru')(concatenated)\n",
    "    dropout_layer = Dropout(rate=dropout_rate, name='dropout')(decoder_output)\n",
    "\n",
    "    # Output layers for predicting the next event's attributes\n",
    "    output_resource = Dense(num_resources + 1, activation='softmax', name='output_resource')(dropout_layer)\n",
    "    output_activity = Dense(num_activities + 1, activation='softmax', name='output_activity')(dropout_layer)\n",
    "    output_role = Dense(num_roles + 1, activation='softmax', name='output_role')(dropout_layer)\n",
    "    output_timestamp = Dense(1, activation='linear', name='output_timestamp')(dropout_layer)\n",
    "\n",
    "    # Building the model\n",
    "    model = Model(inputs=[input_resource, input_activity, input_role, input_timestamp], outputs=[output_resource, output_activity, output_role, output_timestamp])\n",
    "    model.compile(\n",
    "        optimizer='adam', \n",
    "        loss={\n",
    "            'output_resource': 'categorical_crossentropy', \n",
    "            'output_activity': 'categorical_crossentropy',\n",
    "            'output_role': 'categorical_crossentropy',\n",
    "            'output_timestamp': 'mse'\n",
    "        },\n",
    "        metrics={\n",
    "            'output_resource': ['accuracy'], \n",
    "            'output_activity': ['accuracy'],\n",
    "            'output_role': ['accuracy'],\n",
    "            'output_timestamp': ['mse']\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Parameters\n",
    "gru_units = int(2 * E) \n",
    "num_resources = dataframe_log['org:resource'].max()\n",
    "num_activities = dataframe_log['concept:name'].max()\n",
    "num_roles = dataframe_log['org:role'].max()\n",
    "embedding_dim = 50\n",
    "dropout_rate = 0.2\n",
    "model = create_binetv3(num_resources, num_activities, num_roles, embedding_dim, gru_units, dropout_rate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_id, test_id, train_targets_id, test_targets_id = train_test_split(\n",
    "    windows_id, targets_id, test_size=0.3, random_state=42)\n",
    "\n",
    "train_resource, test_resource, train_targets_resource, test_targets_resource = train_test_split(\n",
    "    windows_resource, targets_resource, test_size=0.3, random_state=42)\n",
    "\n",
    "train_activity, test_activity, train_targets_activity, test_targets_activity = train_test_split(\n",
    "    windows_activity, targets_activity, test_size=0.3, random_state=42)\n",
    "\n",
    "train_role, test_role, train_targets_role, test_targets_role = train_test_split(\n",
    "    windows_role, targets_role, test_size=0.3, random_state=42)\n",
    "\n",
    "train_timestamp, test_timestamp, train_targets_timestamp, test_targets_timestamp = train_test_split(\n",
    "    windows_timestamp, targets_timestamp, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_targets_resource_cat = to_categorical(train_targets_resource, num_classes=num_resources + 1)\n",
    "test_targets_resource_cat = to_categorical(test_targets_resource, num_classes=num_resources + 1)\n",
    "\n",
    "train_targets_activity_cat = to_categorical(train_targets_activity, num_classes=num_activities + 1)\n",
    "test_targets_activity_cat = to_categorical(test_targets_activity, num_classes=num_activities + 1)\n",
    "\n",
    "train_targets_role_cat = to_categorical(train_targets_role, num_classes=num_roles + 1)\n",
    "test_targets_role_cat = to_categorical(test_targets_role, num_classes=num_roles + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "92/92 [==============================] - 53s 383ms/step - loss: 3.3379 - output_resource_loss: 0.2358 - output_activity_loss: 1.8371 - output_role_loss: 0.9139 - output_timestamp_loss: 0.3511 - output_resource_accuracy: 0.9390 - output_activity_accuracy: 0.5693 - output_role_accuracy: 0.7284 - output_timestamp_mse: 0.3511 - val_loss: 6.0401 - val_output_resource_loss: 0.6100 - val_output_activity_loss: 2.9180 - val_output_role_loss: 1.6509 - val_output_timestamp_loss: 0.8612 - val_output_resource_accuracy: 0.9030 - val_output_activity_accuracy: 0.4799 - val_output_role_accuracy: 0.8313 - val_output_timestamp_mse: 0.8612\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 32s 347ms/step - loss: 1.4200 - output_resource_loss: 0.0682 - output_activity_loss: 0.7318 - output_role_loss: 0.3572 - output_timestamp_loss: 0.2628 - output_resource_accuracy: 0.9904 - output_activity_accuracy: 0.8184 - output_role_accuracy: 0.8877 - output_timestamp_mse: 0.2628 - val_loss: 4.3008 - val_output_resource_loss: 0.3006 - val_output_activity_loss: 2.1939 - val_output_role_loss: 1.0890 - val_output_timestamp_loss: 0.7172 - val_output_resource_accuracy: 0.9672 - val_output_activity_accuracy: 0.7767 - val_output_role_accuracy: 0.8680 - val_output_timestamp_mse: 0.7172\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 29s 317ms/step - loss: 1.1179 - output_resource_loss: 0.0546 - output_activity_loss: 0.5619 - output_role_loss: 0.2866 - output_timestamp_loss: 0.2148 - output_resource_accuracy: 0.9904 - output_activity_accuracy: 0.8509 - output_role_accuracy: 0.9100 - output_timestamp_mse: 0.2148 - val_loss: 2.5549 - val_output_resource_loss: 0.1198 - val_output_activity_loss: 1.3104 - val_output_role_loss: 0.5902 - val_output_timestamp_loss: 0.5343 - val_output_resource_accuracy: 0.9767 - val_output_activity_accuracy: 0.8437 - val_output_role_accuracy: 0.8860 - val_output_timestamp_mse: 0.5343\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 28s 305ms/step - loss: 1.0143 - output_resource_loss: 0.0495 - output_activity_loss: 0.5038 - output_role_loss: 0.2689 - output_timestamp_loss: 0.1921 - output_resource_accuracy: 0.9904 - output_activity_accuracy: 0.8576 - output_role_accuracy: 0.9124 - output_timestamp_mse: 0.1921 - val_loss: 1.5347 - val_output_resource_loss: 0.0608 - val_output_activity_loss: 0.7393 - val_output_role_loss: 0.3533 - val_output_timestamp_loss: 0.3814 - val_output_resource_accuracy: 0.9864 - val_output_activity_accuracy: 0.8590 - val_output_role_accuracy: 0.9083 - val_output_timestamp_mse: 0.3814\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 29s 311ms/step - loss: 0.9615 - output_resource_loss: 0.0465 - output_activity_loss: 0.4774 - output_role_loss: 0.2578 - output_timestamp_loss: 0.1798 - output_resource_accuracy: 0.9906 - output_activity_accuracy: 0.8603 - output_role_accuracy: 0.9146 - output_timestamp_mse: 0.1798 - val_loss: 1.1015 - val_output_resource_loss: 0.0488 - val_output_activity_loss: 0.5211 - val_output_role_loss: 0.2682 - val_output_timestamp_loss: 0.2635 - val_output_resource_accuracy: 0.9885 - val_output_activity_accuracy: 0.8650 - val_output_role_accuracy: 0.9163 - val_output_timestamp_mse: 0.2635\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 29s 320ms/step - loss: 0.9320 - output_resource_loss: 0.0449 - output_activity_loss: 0.4625 - output_role_loss: 0.2534 - output_timestamp_loss: 0.1712 - output_resource_accuracy: 0.9906 - output_activity_accuracy: 0.8608 - output_role_accuracy: 0.9146 - output_timestamp_mse: 0.1712 - val_loss: 0.9264 - val_output_resource_loss: 0.0464 - val_output_activity_loss: 0.4488 - val_output_role_loss: 0.2420 - val_output_timestamp_loss: 0.1891 - val_output_resource_accuracy: 0.9904 - val_output_activity_accuracy: 0.8686 - val_output_role_accuracy: 0.9194 - val_output_timestamp_mse: 0.1891\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 26s 288ms/step - loss: 0.9075 - output_resource_loss: 0.0440 - output_activity_loss: 0.4509 - output_role_loss: 0.2494 - output_timestamp_loss: 0.1631 - output_resource_accuracy: 0.9904 - output_activity_accuracy: 0.8620 - output_role_accuracy: 0.9149 - output_timestamp_mse: 0.1631 - val_loss: 0.8370 - val_output_resource_loss: 0.0377 - val_output_activity_loss: 0.4230 - val_output_role_loss: 0.2334 - val_output_timestamp_loss: 0.1429 - val_output_resource_accuracy: 0.9905 - val_output_activity_accuracy: 0.8686 - val_output_role_accuracy: 0.9162 - val_output_timestamp_mse: 0.1429\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 28s 304ms/step - loss: 0.8899 - output_resource_loss: 0.0432 - output_activity_loss: 0.4432 - output_role_loss: 0.2456 - output_timestamp_loss: 0.1579 - output_resource_accuracy: 0.9904 - output_activity_accuracy: 0.8632 - output_role_accuracy: 0.9173 - output_timestamp_mse: 0.1579 - val_loss: 0.7987 - val_output_resource_loss: 0.0375 - val_output_activity_loss: 0.4153 - val_output_role_loss: 0.2315 - val_output_timestamp_loss: 0.1143 - val_output_resource_accuracy: 0.9905 - val_output_activity_accuracy: 0.8694 - val_output_role_accuracy: 0.9190 - val_output_timestamp_mse: 0.1143\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 28s 307ms/step - loss: 0.8746 - output_resource_loss: 0.0430 - output_activity_loss: 0.4373 - output_role_loss: 0.2429 - output_timestamp_loss: 0.1514 - output_resource_accuracy: 0.9904 - output_activity_accuracy: 0.8644 - output_role_accuracy: 0.9161 - output_timestamp_mse: 0.1514 - val_loss: 0.7900 - val_output_resource_loss: 0.0370 - val_output_activity_loss: 0.4101 - val_output_role_loss: 0.2290 - val_output_timestamp_loss: 0.1140 - val_output_resource_accuracy: 0.9902 - val_output_activity_accuracy: 0.8689 - val_output_role_accuracy: 0.9168 - val_output_timestamp_mse: 0.1140\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 28s 302ms/step - loss: 0.8619 - output_resource_loss: 0.0418 - output_activity_loss: 0.4330 - output_role_loss: 0.2408 - output_timestamp_loss: 0.1463 - output_resource_accuracy: 0.9905 - output_activity_accuracy: 0.8641 - output_role_accuracy: 0.9171 - output_timestamp_mse: 0.1463 - val_loss: 0.7940 - val_output_resource_loss: 0.0408 - val_output_activity_loss: 0.4099 - val_output_role_loss: 0.2330 - val_output_timestamp_loss: 0.1103 - val_output_resource_accuracy: 0.9892 - val_output_activity_accuracy: 0.8690 - val_output_role_accuracy: 0.9198 - val_output_timestamp_mse: 0.1103\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 28s 308ms/step - loss: 0.8497 - output_resource_loss: 0.0407 - output_activity_loss: 0.4280 - output_role_loss: 0.2397 - output_timestamp_loss: 0.1414 - output_resource_accuracy: 0.9904 - output_activity_accuracy: 0.8651 - output_role_accuracy: 0.9162 - output_timestamp_mse: 0.1414 - val_loss: 0.7776 - val_output_resource_loss: 0.0361 - val_output_activity_loss: 0.4067 - val_output_role_loss: 0.2307 - val_output_timestamp_loss: 0.1041 - val_output_resource_accuracy: 0.9905 - val_output_activity_accuracy: 0.8696 - val_output_role_accuracy: 0.9198 - val_output_timestamp_mse: 0.1041\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 27s 298ms/step - loss: 0.8411 - output_resource_loss: 0.0409 - output_activity_loss: 0.4250 - output_role_loss: 0.2388 - output_timestamp_loss: 0.1365 - output_resource_accuracy: 0.9904 - output_activity_accuracy: 0.8650 - output_role_accuracy: 0.9161 - output_timestamp_mse: 0.1365 - val_loss: 0.7784 - val_output_resource_loss: 0.0376 - val_output_activity_loss: 0.4041 - val_output_role_loss: 0.2284 - val_output_timestamp_loss: 0.1084 - val_output_resource_accuracy: 0.9905 - val_output_activity_accuracy: 0.8684 - val_output_role_accuracy: 0.9199 - val_output_timestamp_mse: 0.1084\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 28s 301ms/step - loss: 0.8310 - output_resource_loss: 0.0391 - output_activity_loss: 0.4205 - output_role_loss: 0.2352 - output_timestamp_loss: 0.1362 - output_resource_accuracy: 0.9903 - output_activity_accuracy: 0.8662 - output_role_accuracy: 0.9181 - output_timestamp_mse: 0.1362 - val_loss: 0.7747 - val_output_resource_loss: 0.0369 - val_output_activity_loss: 0.4049 - val_output_role_loss: 0.2289 - val_output_timestamp_loss: 0.1040 - val_output_resource_accuracy: 0.9903 - val_output_activity_accuracy: 0.8701 - val_output_role_accuracy: 0.9201 - val_output_timestamp_mse: 0.1040\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 28s 302ms/step - loss: 0.8259 - output_resource_loss: 0.0398 - output_activity_loss: 0.4195 - output_role_loss: 0.2348 - output_timestamp_loss: 0.1319 - output_resource_accuracy: 0.9903 - output_activity_accuracy: 0.8656 - output_role_accuracy: 0.9176 - output_timestamp_mse: 0.1319 - val_loss: 0.7722 - val_output_resource_loss: 0.0387 - val_output_activity_loss: 0.4007 - val_output_role_loss: 0.2284 - val_output_timestamp_loss: 0.1044 - val_output_resource_accuracy: 0.9905 - val_output_activity_accuracy: 0.8696 - val_output_role_accuracy: 0.9207 - val_output_timestamp_mse: 0.1044\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 28s 309ms/step - loss: 0.8250 - output_resource_loss: 0.0396 - output_activity_loss: 0.4192 - output_role_loss: 0.2357 - output_timestamp_loss: 0.1305 - output_resource_accuracy: 0.9905 - output_activity_accuracy: 0.8659 - output_role_accuracy: 0.9175 - output_timestamp_mse: 0.1305 - val_loss: 0.7698 - val_output_resource_loss: 0.0366 - val_output_activity_loss: 0.3996 - val_output_role_loss: 0.2256 - val_output_timestamp_loss: 0.1080 - val_output_resource_accuracy: 0.9905 - val_output_activity_accuracy: 0.8699 - val_output_role_accuracy: 0.9197 - val_output_timestamp_mse: 0.1080\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 27s 295ms/step - loss: 0.8163 - output_resource_loss: 0.0389 - output_activity_loss: 0.4166 - output_role_loss: 0.2329 - output_timestamp_loss: 0.1279 - output_resource_accuracy: 0.9904 - output_activity_accuracy: 0.8666 - output_role_accuracy: 0.9179 - output_timestamp_mse: 0.1279 - val_loss: 0.7609 - val_output_resource_loss: 0.0359 - val_output_activity_loss: 0.3988 - val_output_role_loss: 0.2272 - val_output_timestamp_loss: 0.0989 - val_output_resource_accuracy: 0.9901 - val_output_activity_accuracy: 0.8704 - val_output_role_accuracy: 0.9200 - val_output_timestamp_mse: 0.0989\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 28s 308ms/step - loss: 0.8114 - output_resource_loss: 0.0388 - output_activity_loss: 0.4137 - output_role_loss: 0.2325 - output_timestamp_loss: 0.1264 - output_resource_accuracy: 0.9903 - output_activity_accuracy: 0.8656 - output_role_accuracy: 0.9181 - output_timestamp_mse: 0.1264 - val_loss: 0.7520 - val_output_resource_loss: 0.0351 - val_output_activity_loss: 0.3966 - val_output_role_loss: 0.2234 - val_output_timestamp_loss: 0.0969 - val_output_resource_accuracy: 0.9905 - val_output_activity_accuracy: 0.8699 - val_output_role_accuracy: 0.9201 - val_output_timestamp_mse: 0.0969\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 26s 285ms/step - loss: 0.8100 - output_resource_loss: 0.0381 - output_activity_loss: 0.4123 - output_role_loss: 0.2330 - output_timestamp_loss: 0.1266 - output_resource_accuracy: 0.9904 - output_activity_accuracy: 0.8660 - output_role_accuracy: 0.9177 - output_timestamp_mse: 0.1266 - val_loss: 0.7588 - val_output_resource_loss: 0.0363 - val_output_activity_loss: 0.3977 - val_output_role_loss: 0.2257 - val_output_timestamp_loss: 0.0991 - val_output_resource_accuracy: 0.9906 - val_output_activity_accuracy: 0.8700 - val_output_role_accuracy: 0.9189 - val_output_timestamp_mse: 0.0991\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 27s 293ms/step - loss: 0.8122 - output_resource_loss: 0.0386 - output_activity_loss: 0.4136 - output_role_loss: 0.2332 - output_timestamp_loss: 0.1268 - output_resource_accuracy: 0.9905 - output_activity_accuracy: 0.8668 - output_role_accuracy: 0.9178 - output_timestamp_mse: 0.1268 - val_loss: 0.7492 - val_output_resource_loss: 0.0346 - val_output_activity_loss: 0.3952 - val_output_role_loss: 0.2237 - val_output_timestamp_loss: 0.0957 - val_output_resource_accuracy: 0.9906 - val_output_activity_accuracy: 0.8701 - val_output_role_accuracy: 0.9204 - val_output_timestamp_mse: 0.0957\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 29s 313ms/step - loss: 0.7993 - output_resource_loss: 0.0368 - output_activity_loss: 0.4094 - output_role_loss: 0.2293 - output_timestamp_loss: 0.1238 - output_resource_accuracy: 0.9905 - output_activity_accuracy: 0.8668 - output_role_accuracy: 0.9188 - output_timestamp_mse: 0.1238 - val_loss: 0.7544 - val_output_resource_loss: 0.0358 - val_output_activity_loss: 0.3941 - val_output_role_loss: 0.2254 - val_output_timestamp_loss: 0.0991 - val_output_resource_accuracy: 0.9904 - val_output_activity_accuracy: 0.8700 - val_output_role_accuracy: 0.9198 - val_output_timestamp_mse: 0.0991\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the properly shaped targets\n",
    "history = model.fit(\n",
    "    [train_resource, train_activity, train_role, train_timestamp],\n",
    "    [train_targets_resource_cat, train_targets_activity_cat, train_targets_role_cat, train_targets_timestamp],\n",
    "    validation_data=(\n",
    "        [test_resource, test_activity, test_role, test_timestamp], \n",
    "        [test_targets_resource_cat, test_targets_activity_cat, test_targets_role_cat, test_targets_timestamp]\n",
    "    ),\n",
    "    epochs=20,\n",
    "    batch_size=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 5s 16ms/step - loss: 0.7544 - output_resource_loss: 0.0358 - output_activity_loss: 0.3941 - output_role_loss: 0.2254 - output_timestamp_loss: 0.0991 - output_resource_accuracy: 0.9904 - output_activity_accuracy: 0.8700 - output_role_accuracy: 0.9198 - output_timestamp_mse: 0.0991\n",
      "Validation Loss: 0.7543678283691406, Validation Accuracy: 0.03581743314862251\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "results = model.evaluate(\n",
    "    [test_resource, test_activity, test_role, test_timestamp],\n",
    "    [test_targets_resource_cat, test_targets_activity_cat, test_targets_role_cat, test_targets_timestamp],\n",
    "    batch_size=64\n",
    ")\n",
    "print(f\"Validation Loss: {results[0]}, Validation Accuracy: {results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model to an H5 file\n",
    "model.save('binetv3_International.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Score Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each event attribute, BINet's softmax layer outputs a probability distribution over possible values\n",
    "- The anomaly score for a specific attribute value v is calculated by summing all the probabilities from the softmax output that are greater than the probability assigned to v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2054/2054 [==============================] - 20s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for all inputs\n",
    "predictions = model.predict([windows_resource, windows_activity, windows_role, windows_timestamp])\n",
    "\n",
    "\n",
    "# Assuming your model is set to predict resource, activity, and role categories\n",
    "# Extract predictions for categorical attributes (softmax probabilities)\n",
    "predictions_activity = predictions[1]  # Resource predictions\n",
    "predictions_resource = predictions[0]  # Activity predictions\n",
    "predictions_role = predictions[2]      # Role predictions\n",
    "\n",
    "# If you had added 'amount' as a target to be predicted, you would extract its predictions like so:\n",
    "predictions_timestamp = predictions[3]  # Assuming 'amount' is a regression target and the model is adjusted accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_anomaly_scores(predictions, targets):\n",
    "    scores = []\n",
    "    # Loop through each example in the predictions\n",
    "    for i in range(predictions.shape[0]):\n",
    "        actual_prob = predictions[i, targets[i]]  # Extract the probability of the true class using target index\n",
    "        # Calculate anomaly score as sum of probabilities greater than the probability of the actual value\n",
    "        anomaly_score = np.sum(predictions[i][predictions[i] > actual_prob])\n",
    "        scores.append(anomaly_score)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_scores_resource = calculate_anomaly_scores(predictions_resource, targets_resource.astype(int))\n",
    "anomaly_scores_role = calculate_anomaly_scores(predictions_role, targets_role.astype(int))\n",
    "anomaly_scores_activity = calculate_anomaly_scores(predictions_activity, targets_activity.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_anomaly_scores_continuous(predictions, actuals):\n",
    "    # Calculate absolute differences\n",
    "    differences = np.abs(predictions - actuals)\n",
    "    \n",
    "    # Normalize to [0, 1] range\n",
    "    max_diff = np.max(differences)\n",
    "    normalized_scores = differences / max_diff if max_diff != 0 else differences\n",
    "    \n",
    "    return normalized_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_scores_timestamp = compute_anomaly_scores_continuous(predictions_timestamp, targets_timestamp)\n",
    "anomaly_scores_timestamp = anomaly_scores_timestamp.flatten()\n",
    "anomaly_scores_timestamp = anomaly_scores_timestamp.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert missing scores for cases with less than 2 Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>score_resource</th>\n",
       "      <th>score_activity</th>\n",
       "      <th>score_role</th>\n",
       "      <th>score_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907237</td>\n",
       "      <td>0.980585</td>\n",
       "      <td>0.019324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467840</td>\n",
       "      <td>0.004057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65697</th>\n",
       "      <td>6448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.973908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65698</th>\n",
       "      <td>6448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65699</th>\n",
       "      <td>6448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65700</th>\n",
       "      <td>6448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65701</th>\n",
       "      <td>6448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65702 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       case  score_resource  score_activity  score_role  score_timestamp\n",
       "0         0             0.0        0.000000    0.000000         0.030477\n",
       "1         0             0.0        0.000000    0.000000         0.334193\n",
       "2         0             0.0        0.907237    0.980585         0.019324\n",
       "3         0             0.0        0.000000    0.000000         0.058585\n",
       "4         0             0.0        0.000000    0.467840         0.004057\n",
       "...     ...             ...             ...         ...              ...\n",
       "65697  6448             0.0        0.973908    0.000000         0.082034\n",
       "65698  6448             0.0        0.564090    0.000000         0.047946\n",
       "65699  6448             0.0        0.000000    0.000000         0.046291\n",
       "65700  6448             0.0        0.000000    0.000000         0.062173\n",
       "65701  6448             0.0        0.000000    0.000000         0.007040\n",
       "\n",
       "[65702 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the case_indices_array corresponding to case_resource\n",
    "score = pd.DataFrame({'case': case_indices})\n",
    "score['score_resource'] = anomaly_scores_resource\n",
    "score['score_activity'] = anomaly_scores_activity\n",
    "score['score_role'] = anomaly_scores_role\n",
    "score['score_timestamp'] = anomaly_scores_timestamp\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the 'case' column contain all values between 0 and 6448? True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def contains_all_values(df, column, end):\n",
    "\n",
    "    # Generate the set of all values in the specified range\n",
    "    required_values = set(range(0, end + 1))\n",
    "    \n",
    "    # Get the unique values in the specified column\n",
    "    column_values = set(df[column].unique())\n",
    "    \n",
    "    # Find missing values\n",
    "    missing_values = required_values - column_values\n",
    "    \n",
    "    # Print missing values if any\n",
    "    if missing_values:\n",
    "        print(f\"Missing values: {sorted(missing_values)}\")\n",
    "    \n",
    "    # Check if all required values are in the column values\n",
    "    return required_values.issubset(column_values)\n",
    "\n",
    "end = 6448\n",
    "\n",
    "result = contains_all_values(score, 'case', end)\n",
    "print(f\"Does the 'case' column contain all values between 0 and {end}? {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold (lowest plateau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_anomaly_ratio(scores, threshold):\n",
    "    \"\"\"\n",
    "    Calculate the anomaly ratio for a given threshold.\n",
    "    \"\"\"\n",
    "    return np.mean(scores > threshold)\n",
    "\n",
    "def find_plateaus(scores, epsilon=1e-4, min_plateau_length=10):\n",
    "    \"\"\"\n",
    "    Identify the lowest plateau in the anomaly ratio function and calculate the mean-centered threshold.\n",
    "    \"\"\"\n",
    "    scores = np.array(scores)  # Convert scores to a NumPy array\n",
    "    sorted_scores = np.sort(scores)\n",
    "    \n",
    "    # Remove duplicate values\n",
    "    unique_thresholds, unique_indices = np.unique(sorted_scores, return_index=True)\n",
    "    anomaly_ratios = np.array([calculate_anomaly_ratio(scores, t) for t in unique_thresholds])\n",
    "    \n",
    "    # Calculate first and second derivatives\n",
    "    first_derivatives = np.diff(anomaly_ratios) / np.diff(unique_thresholds)\n",
    "    second_derivatives = np.diff(first_derivatives) / np.diff(unique_thresholds[:-1])\n",
    "    \n",
    "    # Identify plateaus where the first derivative is close to zero\n",
    "    plateau_indices = np.where(np.abs(first_derivatives) < epsilon)[0]\n",
    "    \n",
    "    # Group consecutive indices to identify continuous plateaus\n",
    "    grouped_plateaus = np.split(plateau_indices, np.where(np.diff(plateau_indices) != 1)[0] + 1)\n",
    "    \n",
    "    # Filter plateaus based on minimum length\n",
    "    long_plateaus = [g for g in grouped_plateaus if len(g) >= min_plateau_length]\n",
    "    \n",
    "    if long_plateaus:\n",
    "        # Take the first long plateau and find the mean threshold in this plateau\n",
    "        first_plateau = long_plateaus[0]\n",
    "        plateau_thresholds = unique_thresholds[first_plateau]\n",
    "        return np.mean(plateau_thresholds)\n",
    "    else:\n",
    "        # If no plateau is found, return a default value, e.g., the 90th percentile\n",
    "        percentile_90 = np.percentile(sorted_scores, 90)\n",
    "        if percentile_90 == 1.0:\n",
    "            return 0.4\n",
    "        else:\n",
    "            return percentile_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_resource = find_plateaus(anomaly_scores_resource)\n",
    "threshold_role = find_plateaus(anomaly_scores_role)\n",
    "threshold_activity = find_plateaus(anomaly_scores_activity)\n",
    "threshold_timestamp = find_plateaus(anomaly_scores_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(anomaly_scores, threshold):\n",
    "    labels = [1 if score > threshold else 0 for score in anomaly_scores]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect anomalies based on the calculated anomaly scores and thresholds\n",
    "labels_resource = detect_anomalies(anomaly_scores_resource, threshold_resource)\n",
    "labels_activity = detect_anomalies(anomaly_scores_activity, threshold_activity)\n",
    "labels_role = detect_anomalies(anomaly_scores_role, threshold_role)\n",
    "labels_timestamp = detect_anomalies(anomaly_scores_timestamp, threshold_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>predicted_resource</th>\n",
       "      <th>predicted_activity</th>\n",
       "      <th>predicted_role</th>\n",
       "      <th>predicted_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65697</th>\n",
       "      <td>6448</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65698</th>\n",
       "      <td>6448</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65699</th>\n",
       "      <td>6448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65700</th>\n",
       "      <td>6448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65701</th>\n",
       "      <td>6448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65702 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       case  predicted_resource  predicted_activity  predicted_role  \\\n",
       "0         0                   0                   0               0   \n",
       "1         0                   0                   0               0   \n",
       "2         0                   0                   1               1   \n",
       "3         0                   0                   0               0   \n",
       "4         0                   0                   0               1   \n",
       "...     ...                 ...                 ...             ...   \n",
       "65697  6448                   0                   1               0   \n",
       "65698  6448                   0                   1               0   \n",
       "65699  6448                   0                   0               0   \n",
       "65700  6448                   0                   0               0   \n",
       "65701  6448                   0                   0               0   \n",
       "\n",
       "       predicted_timestamp  \n",
       "0                        0  \n",
       "1                        1  \n",
       "2                        0  \n",
       "3                        1  \n",
       "4                        0  \n",
       "...                    ...  \n",
       "65697                    1  \n",
       "65698                    1  \n",
       "65699                    1  \n",
       "65700                    1  \n",
       "65701                    0  \n",
       "\n",
       "[65702 rows x 5 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the case_indices_array corresponding to case_resource\n",
    "mapping = pd.DataFrame({'case': case_indices})\n",
    "mapping['predicted_resource'] = labels_resource\n",
    "mapping['predicted_activity'] = labels_activity\n",
    "mapping['predicted_role'] = labels_role\n",
    "mapping['predicted_timestamp'] = labels_timestamp\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case\n",
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "        ... \n",
       "6444    True\n",
       "6445    True\n",
       "6446    True\n",
       "6447    True\n",
       "6448    True\n",
       "Length: 6449, dtype: bool"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a boolean DataFrame where each value is True if the value is 1\n",
    "contains_one = (mapping[['predicted_resource', 'predicted_activity', 'predicted_role', 'predicted_timestamp']] == 1)\n",
    "\n",
    "# Group by 'case' and check if there's at least one 'True' in any of the columns\n",
    "case_prediction = contains_one.groupby(mapping['case']).any().any(axis=1)\n",
    "case_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case\n",
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "        ...  \n",
       "6444    False\n",
       "6445     True\n",
       "6446    False\n",
       "6447     True\n",
       "6448     True\n",
       "Length: 6449, dtype: bool"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a boolean DataFrame where each value is True if the value is 1\n",
    "contains_one = (mapping[['predicted_activity']] == 1)\n",
    "\n",
    "# Group by 'case' and check if there's at least one 'True' in any of the columns\n",
    "case_prediction = contains_one.groupby(mapping['case']).any().any(axis=1)\n",
    "case_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking):\n",
    "    from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments\n",
    "    from pm4py.algo.conformance.alignments.petri_net import variants\n",
    "    from pm4py.objects.petri_net.utils import align_utils\n",
    "    max_events=0\n",
    "    for trace in log:\n",
    "        counter=0\n",
    "        for event in trace:\n",
    "            counter+=1\n",
    "        if counter > max_events:\n",
    "            max_events=counter\n",
    "    parameters={}\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_SYNC_COST_FUNCTION] = list(map(lambda i: .1*i, range(max_events*2)))\n",
    "    parameters[alignments.Variants.VERSION_STATE_EQUATION_A_STAR.value.Parameters.PARAM_TRACE_COST_FUNCTION]=list(map(lambda i: align_utils.STD_MODEL_LOG_MOVE_COST-.1*i, range(max_events*2)))\n",
    "    aligned_traces = alignments.apply_log(log, net, initial_marking, final_marking, variant=variants.state_equation_a_star, parameters=parameters)\n",
    "    return aligned_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ade43210d04e9c89c2baa5c7f5ba13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"../../data/model/Model_InternationalDeclarations.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, initial_marking, final_marking = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "aligned_traces = generate_alignments_adjusted_tracecost_pkl(log, net, initial_marking, final_marking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conformance_status_by_fitness(aligned_traces):\n",
    "    conformance_status = []\n",
    "    for alignment in aligned_traces:\n",
    "        fitness = alignment['fitness']\n",
    "        # If the fitness is 1.0, the trace is conforming\n",
    "        if fitness == 1.0:\n",
    "            conformance_status.append(1)\n",
    "        else:\n",
    "            conformance_status.append(0)\n",
    "    return conformance_status\n",
    "\n",
    "# Get the conformance status list from the aligned traces\n",
    "conformance = extract_conformance_status_by_fitness(aligned_traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conformity</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6444</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6445</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6446</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6447</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6448</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6449 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      conformity  predicted\n",
       "0              0          0\n",
       "1              0          0\n",
       "2              0          0\n",
       "3              0          0\n",
       "4              0          0\n",
       "...          ...        ...\n",
       "6444           1          1\n",
       "6445           0          0\n",
       "6446           1          1\n",
       "6447           0          0\n",
       "6448           0          0\n",
       "\n",
       "[6449 rows x 2 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = pd.DataFrame({'conformity': conformance})\n",
    "ground_truth['predicted'] = case_prediction\n",
    "\n",
    "# Convert False to 0 and True to 1\n",
    "ground_truth['predicted'] = [int(value) for value in ground_truth['predicted']]\n",
    "ground_truth['predicted'] = 1 - ground_truth['predicted']\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating TP, TN, FP, FN\n",
    "TP = ((ground_truth['conformity'] == 1) & (ground_truth['predicted'] == 1)).sum()\n",
    "TN = ((ground_truth['conformity'] == 0) & (ground_truth['predicted'] == 0)).sum()\n",
    "FP = ((ground_truth['conformity'] == 0) & (ground_truth['predicted'] == 1)).sum()\n",
    "FN = ((ground_truth['conformity'] == 1) & (ground_truth['predicted'] == 0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.864\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.820\n"
     ]
    }
   ],
   "source": [
    "# Calculate f1\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "print(f\"F1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev (Non Conform Traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.873\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision for Dev\n",
    "precision = TN / (TN + FN)\n",
    "print(f\"Precision: {precision:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.909\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall for Dev\n",
    "recall = TN / (TN + FP)\n",
    "print(f\"Recall: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Dev (Conform Traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.848\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision for No Dev\n",
    "precision = TP / (TP + FP)\n",
    "print(f\"Precision: {precision:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.793\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall for No Dev\n",
    "recall = TP / (TP + FN)\n",
    "print(f\"Recall: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85135676919443"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Assuming ground_truth is your DataFrame\n",
    "# Make sure 'conformity' contains actual labels (0 or 1)\n",
    "# and 'predicted' contains predicted probabilities or scores\n",
    "auc_roc = roc_auc_score(ground_truth['conformity'], ground_truth['predicted'])\n",
    "auc_roc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
